@inproceedings{10.1145/3078971.3079038,
  title = {Generative Adversarial Networks for Multimodal Representation Learning in Video Hyperlinking},
  booktitle = {Proceedings of the 2017 {{ACM}} on International Conference on Multimedia Retrieval},
  author = {Vukotić, Vedran and Raymond, Christian and Gravier, Guillaume},
  date = {2017},
  series = {{{ICMR}} '17},
  pages = {416--419},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3078971.3079038},
  url = {https://doi.org/10.1145/3078971.3079038},
  abstract = {Continuous multimodal representations suitable for multimodal information retrieval are usually obtained with methods that heavily rely on multimodal autoencoders. In video hyperlinking, a task that aims at retrieving video segments, the state of the art is a variation of two interlocked networks working in opposing directions. These systems provide good multimodal embeddings and are also capable of translating from one representation space to the other. Operating on representation spaces, these networks lack the ability to operate in the original spaces (text or image), which makes it difficult to visualize the crossmodal function, and do not generalize well to unseen data. Recently, generative adversarial networks have gained popularity and have been used for generating realistic synthetic data and for obtaining high-level, single-modal latent representation spaces. In this work, we evaluate the feasibility of using GANs to obtain multimodal representations. We show that GANs can be used for multimodal representation learning and that they provide multimodal representations that are superior to representations obtained with multimodal autoencoders. Additionally, we illustrate the ability of visualizing crossmodal translations that can provide human-interpretable insights on learned GAN-based video hyperlinking models.},
  isbn = {978-1-4503-4701-3},
  pagetotal = {4},
  keywords = {generative adversarial networks,multimedia retrieval,multimodal autoencoders,multimodal embedding,neural networks,representation learning,unsupervised learning,video hyperlinking}
}

@inproceedings{10.1145/3133956.3138823,
  title = {{{POSTER}}: {{A}} Unified Framework of Differentially Private Synthetic Data Release with Generative Adversarial Network},
  booktitle = {Proceedings of the 2017 {{ACM SIGSAC}} Conference on Computer and Communications Security},
  author = {Lu, Pei-Hsuan and Yu, Chia-Mu},
  date = {2017},
  series = {{{CCS}} '17},
  pages = {2547--2549},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3133956.3138823},
  url = {https://doi.org/10.1145/3133956.3138823},
  abstract = {Many differentially private data release solutions have been proposed for different types of data with the sacrifice of inherent correlation structure. Here, we propose a unified framework of releasing differentially private data. In particular, our proposed generative adversarial network (GAN)-based framework learns the input distribution, irrespective of tabular data and graphs, and generates synthetic data in a differentially private manner. Our preliminary results show the acceptable utility of the synthetic dataset.},
  isbn = {978-1-4503-4946-8},
  pagetotal = {3},
  keywords = {02,anonymization,differential privacy,dp,gan,private data release,social network,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\YPD8BNV9\\Lu_Yu_2017_POSTER.pdf}
}

@inproceedings{10.1145/3359115.3359124,
  title = {Assessing Privacy and Quality of Synthetic Health Data},
  booktitle = {Proceedings of the Conference on Artificial Intelligence for Data Discovery and Reuse},
  author = {Yale, Andrew and Dash, Saloni and Dutta, Ritik and Guyon, Isabelle and Pavao, Adrien and Bennett, Kristin P.},
  date = {2019},
  series = {{{AIDR}} '19},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3359115.3359124},
  url = {https://doi.org/10.1145/3359115.3359124},
  abstract = {This paper builds on the results of the ESANN 2019 conference paper "Privacy Preserving Synthetic Health Data" [16], which develops metrics for assessing privacy and utility of synthetic data and models. The metrics laid out in the initial paper show that utility can still be achieved in synthetic data while maintaining both privacy of the model and the data being generated. Specifically, we focused on the success of the Wasserstein GAN method, renamed HealthGAN, in comparison to other data generating methods.In this paper, we provide additional novel metrics to quantify the susceptibility of these generative models to membership inference attacks [14]. We also introduce Discriminator Testing, a new method of determining whether the different generators overfit on the training data, potentially resulting in privacy losses.These privacy issues are of high importance as we prepare a final workflow for generating synthetic data based on real data in a secure environment. The results of these tests complement the initial tests as they show that the Parzen windows method, while having a low privacy loss in adversarial accuracy metrics, fails to preserve privacy in the membership inference attack. Only HealthGAN shows both an optimal value for privacy loss and the membership inference attack. The discriminator testing adds to the confidence as HealthGAN retains resemblance to the training data, without reproducing the training data.},
  articleno = {8},
  isbn = {978-1-4503-7184-1},
  pagetotal = {4},
  keywords = {✔️,03,gan,HealthGAN,privacy},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\6ZKDJED9\\Yale et al_2019_Assessing privacy and quality of synthetic health data.pdf}
}

@inproceedings{10.1145/3442188.3445879,
  title = {Can You Fake It until You Make It? {{Impacts}} of Differentially Private Synthetic Data on Downstream Classification Fairness},
  booktitle = {Proceedings of the 2021 {{ACM}} Conference on Fairness, Accountability, and Transparency},
  author = {Cheng, Victoria and Suriyakumar, Vinith M. and Dullerud, Natalie and Joshi, Shalmali and Ghassemi, Marzyeh},
  date = {2021},
  series = {{{FAccT}} '21},
  pages = {149--160},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3442188.3445879},
  url = {https://doi.org/10.1145/3442188.3445879},
  abstract = {The recent adoption of machine learning models in high-risk settings such as medicine has increased demand for developments in privacy and fairness. Rebalancing skewed datasets using synthetic data created by generative adversarial networks (GANs) has shown potential to mitigate disparate impact on minoritized subgroups. However, such generative models are subject to privacy attacks that can expose sensitive data from the training dataset. Differential privacy (DP) is the current leading solution for privacy-preserving machine learning. Differentially private GANs (DP GANs) are often considered a potential solution for improving model fairness while maintaining privacy of sensitive training data. We investigate the impact of using synthetic images from DP GANs on downstream classification model utility and fairness. We demonstrate that existing DP GANs cannot simultaneously maintain model utility, privacy, and fairness. The images generated from GAN models trained with DP exhibit extreme decreases in image quality and utility which leads to poor downstream classification model performance. Our evaluation highlights the friction between privacy, fairness, and utility and how this directly translates into real loss of performance and representation in common machine learning settings. Our results show that additional work improving the utility and fairness of DP generative models is required before they can be utilized as a potential solution to privacy and fairness issues stemming from lack of diversity in the training dataset.},
  isbn = {978-1-4503-8309-7},
  pagetotal = {12},
  keywords = {✔️,02,dp,gan},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\6DCB7QZM\\Cheng et al_2021_Can you fake it until you make it.pdf}
}

@inproceedings{10.1145/3490354.3494393,
  title = {Sig-Wasserstein {{GANs}} for Time Series Generation},
  booktitle = {Proceedings of the Second {{ACM}} International Conference on {{AI}} in Finance},
  author = {Ni, Hao and Szpruch, Lukasz and Sabate-Vidales, Marc and Xiao, Baoren and Wiese, Magnus and Liao, Shujian},
  date = {2021},
  series = {{{ICAIF}} '21},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3490354.3494393},
  url = {https://doi.org/10.1145/3490354.3494393},
  abstract = {Synthetic data is an emerging technology that can significantly accelerate the development and deployment of AI machine learning pipelines. In this work, we develop high-fidelity time-series generators, the SigWGAN, by combining continuous-time stochastic models with the newly proposed signature W1 metric. The former are the Logsig-RNN models based on the stochastic differential equations, whereas the latter originates from the universal and principled mathematical features to characterize the measure induced by time series. SigWGAN allows turning computationally challenging GAN min-max problem into supervised learning while generating high fidelity samples. We validate the proposed model on both synthetic data generated by popular quantitative risk models and empirical financial data. Codes are available at https://github.com/SigCGANs/Sig-Wasserstein-GANs.git},
  articleno = {28},
  isbn = {978-1-4503-9148-1},
  pagetotal = {8},
  keywords = {02,gan,generative modelling,neural networks,signatures,time series data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ANJTGY6H\\Ni et al_2021_Sig-wasserstein GANs for time series generation.pdf}
}

@inproceedings{10.1145/3510548.3519377,
  title = {{{PriveTAB}}: {{Secure}} and Privacy-Preserving Sharing of Tabular Data},
  booktitle = {Proceedings of the 2022 {{ACM}} on International Workshop on Security and Privacy Analytics},
  author = {Kotal, Anantaa and Piplai, Aritran and Chukkapalli, Sai Sree Laya and Joshi, Anupam},
  date = {2022},
  series = {{{IWSPA}} '22},
  pages = {35--45},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3510548.3519377},
  url = {https://doi.org/10.1145/3510548.3519377},
  abstract = {Machine Learning has increased our ability to model large quantities of data efficiently in a short time. Machine learning approaches in many application domains require collecting large volumes of data from distributed sources and combining them. However, sharing of data from multiple sources leads to concerns about privacy. Privacy regulations like European Union's General Data Protection Regulation (GDPR) have specific requirements on when and how such data can be shared. Even when there are no specific regulations, organizations may have concerns about revealing their data. For example in cybersecurity, organizations are reluctant to share their network-related data to permit machine learning-based intrusion detectors to be built. This has, in particular, hampered academic research. We need an approach to make confidential data widely available for accurate data analysis without violating the privacy of the data subjects. Privacy in shared data has been discussed in prior work focusing on anonymization and encryption of data. An alternate approach to make data available for analysis without sharing sensitive information is by replacing sensitive information with synthetic data that behave as original data for all analytical purposes. Generative Adversarial Networks (GANs) are one of the well-known models to generate synthetic samples that can have the same distributional characteristics as the original data. However, modeling tabular data using GAN is a non-trivial task. Tabular data contain a mix of categorical and continuous variables and require specialized constraints as described in the CTGAN model. In this paper, we propose a framework to generate privacy-preserving synthetic data suitable for release for analytical purposes. The data is generated using the CTGAN approach, and so is analytically similar to the original dataset. To ensure that the generated data meet the privacy requirements, we use the principle of t-closeness. We ensure that the distribution of attributes in the released dataset is within a certain threshold distance from the real dataset. We also encrypt sensitive values in the final released version of the dataset to minimize information leakage. We show that in a variety of cases, models trained on this synthetic data instead of the real data perform nearly as well when tested on the real data. Specifically, we show that the machine learning models used for network event/attack recognition tasks do not have a significant loss in accuracy when trained on data generated from our framework in place of the real dataset.},
  isbn = {978-1-4503-9230-3},
  pagetotal = {11},
  keywords = {02,CTGAN,data generation,data privacy,gan,generative adversarial networks,hashing,machine learning,network datasets,secure data sharing,t-closeness,tabular data,tabular datasets},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\IVS8CXXF\\Kotal et al_2022_PriveTAB.pdf}
}

@article{10.14778/3352063.3352099,
  title = {{{PSynDB}}: {{Accurate}} and Accessible Private Data Generation},
  author = {Huang, Zhiqi and McKenna, Ryan and Bissias, George and Miklau, Gerome and Hay, Michael and Machanavajjhala, Ashwin},
  date = {2019-08},
  journaltitle = {Proc. VLDB Endow.},
  volume = {12},
  number = {12},
  pages = {1918--1921},
  publisher = {{VLDB Endowment}},
  issn = {2150-8097},
  doi = {10.14778/3352063.3352099},
  url = {https://doi.org/10.14778/3352063.3352099},
  abstract = {Across many application domains, trusted parties who collect sensitive information need mechanisms to safely disseminate data. A favored approach is to generate synthetic data: a dataset similar to the original, hopefully retaining its statistical features, but one that does not reveal the private information of contributors to the data.We present PSynDB, a web-based synthetic table generator that is built on recent privacy technologies [10,11,15]. PSynDB satisfies the formal guarantee of differential privacy and generates synthetic tables with high accuracy for tasks that the user specifies as important. PSynDB allows users to browse expected error rates before running the mechanism, a useful feature for making important policy decisions, such as setting the privacy loss budget. When the user has finished configuration, the tool outputs a data synthesis program that can be ported to a trusted environment. There it can be safely executed on the private data to produce the private synthetic dataset for broad dissemination.},
  issue_date = {August 2019},
  pagetotal = {4},
  keywords = {02,dp,PSynDB},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\8EE63SDC\\Huang et al_2019_PSynDB.pdf}
}

@inproceedings{10.5555/3522802.3522942,
  title = {Challenges and Opportunities for Generative Methods in the Cyber Domain},
  booktitle = {Proceedings of the Winter Simulation Conference},
  author = {Chalé, Marc and Bastian, Nathaniel D.},
  date = {2021},
  series = {{{WSC}} '21},
  publisher = {{IEEE Press}},
  location = {{Phoenix, Arizona}},
  abstract = {Large, high quality data sets are essential for training machine learning models to perform their tasks accurately. The lack of such training data has constrained machine learning research in the cyber domain. This work explores how Markov Chain Monte Carlo (MCMC) methods can beused for realistic synthetic data generation and compares it to several existing generative machine learning techniques. The performance of MCMC is compared to generative adversarial network (GAN) and variational autoencoder (VAE) methods to estimate the joint probability distribution of network intrusion detection system data. A statistical analysis of the synthetically generated cyber data determines the goodness of fit, aiming to improve cyber threat detection. The experimental results suggest that the data generated from MCMC fits the true distribution approximately as well as the data generated from GAN and VAE; however, the MCMC requires a significantly longer training period and is unproven for higher dimensional cyber data.},
  articleno = {170},
  pagetotal = {12},
  keywords = {✔️,03,cyber secruity,gan,Markov chain,MCMC,tabular data,VAE,variational autoencoder},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\CV3UJK35\\Chalé_Bastian_2021_Challenges and opportunities for generative methods in the cyber domain.pdf}
}

@online{2022ChatGPTOptimizingLanguage,
  title = {{{ChatGPT}}: {{Optimizing Language Models}} for {{Dialogue}}},
  shorttitle = {{{ChatGPT}}},
  date = {2022-11-30T18:00:07},
  url = {https://openai.com/blog/chatgpt/},
  urldate = {2023-02-13},
  abstract = {We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests. ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in},
  langid = {english},
  organization = {{OpenAI}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ZFHNA6DG\\chatgpt.html}
}

@online{2022ImprovingDiffusionModels,
  title = {Improving {{Diffusion Models}} as an {{Alternative To GANs}}, {{Part}} 2},
  date = {2022-04-26},
  url = {https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-2/},
  urldate = {2023-01-16},
  abstract = {Part 2 of this series reviews three recent techniques developed at NVIDIA for overcoming the slow sampling challenge in diffusion models.},
  langid = {american},
  organization = {{NVIDIA Technical Blog}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LHSSGJL7\\improving-diffusion-models-as-an-alternative-to-gans-part-2.html}
}

@software{2023DiffusionModelsMissing,
  title = {Diffusion Models for Missing Value Imputation in Tabular Data},
  date = {2023-03-03T07:40:05Z},
  origdate = {2023-01-25T23:51:02Z},
  url = {https://github.com/pfnet-research/CSDI_T},
  urldate = {2023-03-03},
  abstract = {A code for the NeurIPS 2022 Table Representation Learning Workshop paper: "Diffusion models for missing value imputation in tabular data"},
  organization = {{pfnet-research}}
}

@online{2023HuggingFaceAI,
  title = {Hugging {{Face}} – {{The AI}} Community Building the Future.},
  date = {2023-02-25},
  url = {https://huggingface.co/},
  urldate = {2023-03-02},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\36WWYBAU\\huggingface.co.html}
}

@inproceedings{8877387,
  title = {{{GANEx}}: {{A}} Complete Pipeline of Training, Inference and Benchmarking {{GAN}} Experiments},
  booktitle = {2019 International Conference on Content-Based Multimedia Indexing ({{CBMI}})},
  author = {Thambawita, Vajira and Hammer, Hugo Lewi and Riegler, Michael and Halvorsen, Pål},
  date = {2019-09},
  pages = {1--4},
  issn = {1949-3991},
  doi = {10.1109/CBMI.2019.8877387},
  abstract = {Deep learning (DL) is one of the standard methods in the field of multimedia research to perform data classification, detection, segmentation and generation. Within DL, generative adversarial networks (GANs) represents a new and highly popular branch of methods. GANs have the capability to generate, from random noise or conditional input, new data realizations within the dataset population. While generation is popular and highly useful in itself, GANs can also be useful to improve supervised DL. GAN-based approaches can, for example, perform segmentation or create synthetic data for training other DL models. The latter one is especially interesting in domains where not much training data exists such as medical multimedia. In this respect, performing a series of experiments involving GANs can be very time consuming due to the lack of tools that support the whole pipeline such as structured training, testing and tracking of different architectures and configurations. Moreover, the success of generative models is highly dependent on hyper-parameter optimization and statistical analysis in the design and fine-tuning stages. In this paper, we present a new tool called GANEx for making the whole pipeline of training, inference and benchmarking GANs faster, more efficient and more structured. The tool consists of a special library called FastGAN which allows designing generative models very fast. Moreover, GANEx has a graphical user interface to support structured experimenting, quick hyper-parameter configurations and output analysis. The presented tool is not limited to a specific DL framework and can be therefore even used to compare the performance of cross frameworks.},
  keywords = {Gallium nitride,GAN Experiments,GAN Library,GAN Statistics,GANs,Generative adversarial networks,Graphical User Interface,Graphical user interfaces,Libraries,Neural Networks,Statistical analysis,Tools,Training}
}

@inproceedings{8903084,
  title = {Variational Bayesian {{GAN}}},
  booktitle = {2019 27th European Signal Processing Conference ({{EUSIPCO}})},
  author = {Chien, Jen-Tzung and Kuo, Chun-Lin},
  date = {2019-09},
  pages = {1--5},
  issn = {2076-1465},
  doi = {10.23919/EUSIPCO.2019.8903084},
  abstract = {Generative adversarial network (GAN) has been successfully developing as a generative model where the artificial data drawn from the generator are misrecognized as real samples by a discriminator. Although GAN achieves the desirable performance, the challenge is that the mode collapse easily happens in the joint optimization of generator and discriminator. This study copes with this challenge by improving the model regularization by means of representing the weight uncertainty in GAN. A new Bayesian GAN is formulated and implemented to learn a regularized model from diverse data where the strong modes are flattened via the marginalization and the issues of model collapse and gradient vanishing are alleviated. In particular, we present a variational GAN (VGAN) where the encoder, generator and discriminator are jointly estimated according to the variational Bayesian inference. The experiments on image generation over two tasks (MNIST and CeleA) demonstrate the superiority of the proposed VGAN to the variational autoencoder, the standard GAN and the Bayesian GAN based on the sampling method. The learning efficiency and generation performance are evaluated.},
  keywords = {Bayes methods,Bayesian learning,computer vision,Data models,Gallium nitride,generative adversarial networks,Generative adversarial networks,Generators,Training,Uncertainty,variational autoencoder}
}

@inproceedings{8936168,
  title = {Extending a Generative Adversarial Network to Produce Medical Records with Demographic Characteristics and Health System Use},
  booktitle = {2019 {{IEEE}} 10th Annual Information Technology, Electronics and Mobile Communication Conference ({{IEMCON}})},
  author = {Jackson, Piper and Lussetti, Marco},
  date = {2019-10},
  pages = {0515--0518},
  issn = {2644-3163},
  doi = {10.1109/IEMCON.2019.8936168},
  abstract = {Generative adversarial networks use machine learning to generate synthetic data that is similar to real data. This has been widely applied to image data, and is now being applied to electronic medical records. Synthetically generated medical records are promising for many applications where privacy and security issues make using real medical records too risky. This includes software and systems development, training, and health research. Developing upon previous work, we have extended the MEDGAN system to generate records with eight additional variables, including demographic and health system use factors. The records generated are similar in distribution to the underlying dataset for all of these added variables. Finally, we discuss our future plans, with an emphasis on privacy-protecting approaches.},
  keywords = {Aging,Data privacy,Electronic Medical Records,Generative adversarial networks,Machine learning,Machine Learning,Medical diagnostic imaging,MIMICs,Neural Networks,Privacy,Simulation}
}

@inproceedings{8952131,
  title = {Evaluating Variational Autoencoder as a Private Data Release Mechanism for Tabular Data},
  booktitle = {2019 {{IEEE}} 24th Pacific Rim International Symposium on Dependable Computing ({{PRDC}})},
  author = {Li, Szu-Chuang and Tai, Bo-Chen and Huang, Yennun},
  date = {2019-12},
  pages = {198--1988},
  issn = {2473-3105},
  doi = {10.1109/PRDC47002.2019.00050},
  abstract = {Multi-market businesses can collect data from different business entities and aggregate data from various sources to create value. However, due to the restriction of privacy regulation, it could be illegal to exchange data between business entities of the same parent company, unless the users have opted-in to allow it. Regulations such as the EU's GDPR allows data exchange if data is anonymized appropriately. In this study, we use variational autoencoder as a mechanism to generate synthetic data. The privacy and utility of the generated data sets are measured. And its performance is compared with the performance of the plain autoencoder. The primary findings of this study are 1) variational autoencoder can be an option for data exchange with good accuracy even when the number of latent dimensions is low 2) plain autoencoder still provides better accuracy when the number of hidden nodes is high 3) variational autoencoder, as a generative model, can be given to a data user to generate his version of data that closely mimic the original data set.},
  keywords = {k anonymity,k Level,private data release,variational autoencoder}
}

@article{9034117,
  title = {Anonymization through Data Synthesis Using Generative Adversarial Networks ({{ADS-GAN}})},
  author = {Yoon, Jinsung and Drumright, Lydia N. and van der Schaar, Mihaela},
  options = {useprefix=true},
  date = {2020-08},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {24},
  number = {8},
  pages = {2378--2388},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2020.2980262},
  abstract = {The medical and machine learning communities are relying on the promise of artificial intelligence (AI) to transform medicine through enabling more accurate decisions and personalized treatment. However, progress is slow. Legal and ethical issues around unconsented patient data and privacy is one of the limiting factors in data sharing, resulting in a significant barrier in accessing routinely collected electronic health records (EHR) by the machine learning community. We propose a novel framework for generating synthetic data that closely approximates the joint distribution of variables in an original EHR dataset, providing a readily accessible, legally and ethically appropriate solution to support more open data sharing, enabling the development of AI solutions. In order to address issues around lack of clarity in defining sufficient anonymization, we created a quantifiable, mathematical definition for “identifiability”. We used a conditional generative adversarial networks (GAN) framework to generate synthetic data while minimize patient identifiability that is defined based on the probability of re-identification given the combination of all data on any individual patient. We compared models fitted to our synthetically generated data to those fitted to the real data across four independent datasets to evaluate similarity in model performance, while assessing the extent to which original observations can be identified from the synthetic data. Our model, ADS-GAN, consistently outperformed state-of-the-art methods, and demonstrated reliability in the joint distributions. We propose that this method could be used to develop datasets that can be made publicly available while considerably lowering the risk of breaching patient confidentiality.},
  keywords = {✔️,02,ADS-GAN,anonymization,categorical data,electronic health records,Gallium nitride,gan,generative adversarial networks,Generative adversarial networks,Generators,identifiability,Machine learning,Medical services,mixed data,numeric data,privacy,Synthetic data generation,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\UCW8B5KJ\\Yoon et al_2020_Anonymization through data synthesis using generative adversarial networks.pdf}
}

@inproceedings{9054559,
  title = {Private {{FL-GAN}}: {{Differential}} Privacy Synthetic Data Generation Based on Federated Learning},
  booktitle = {{{ICASSP}} 2020 - 2020 {{IEEE}} International Conference on Acoustics, Speech and Signal Processing ({{ICASSP}})},
  author = {Xin, Bangzhou and Yang, Wei and Geng, Yangyang and Chen, Sheng and Wang, Shaowei and Huang, Liusheng},
  date = {2020-05},
  pages = {2927--2931},
  issn = {2379-190X},
  doi = {10.1109/ICASSP40776.2020.9054559},
  abstract = {Generative Adversarial Network (GAN) has already made a big splash in the field of generating realistic "fake" data. However, when data is distributed and data-holders are reluctant to share data for privacy reasons, GAN\&\#x2019;s training is difficult. To address this issue, we propose private FL-GAN, a differential privacy generative adversarial network model based on federated learning. By strategically combining the Lipschitz limit with the differential privacy sensitivity, the model can generate high-quality synthetic data without sacrificing the privacy of the training data. We theoretically prove that private FL-GAN can provide strict privacy guarantee with differential privacy, and experimentally demonstrate our model can generate satisfactory data.},
  keywords = {02,data generation,Data models,differential privacy,Differential privacy,Distributed databases,dp,federated learning,gan,Generative adversarial networks,information security,Signal processing algorithms,Training,Training data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\UU55IHI5\\Xin et al_2020_Private FL-GAN.pdf}
}

@inproceedings{9054677,
  title = {Sampling Strategies for {{GAN}} Synthetic Data},
  booktitle = {{{ICASSP}} 2020 - 2020 {{IEEE}} International Conference on Acoustics, Speech and Signal Processing ({{ICASSP}})},
  author = {Bhattarai, Binod and Baek, Seungryul and Bodur, Rumeysa and Kim, Tae-Kyun},
  date = {2020-05},
  pages = {2303--2307},
  issn = {2379-190X},
  doi = {10.1109/ICASSP40776.2020.9054677},
  abstract = {Generative Adversarial Networks (GANs) have been used widely to generate large volumes of synthetic data. This data is being utilised for augmenting with real examples in order to train deep Convolutional Neural Networks (CNNs). Studies have shown that the generated examples lack sufficient realism to train deep CNNs and are poor in diversity. Unlike previous studies of randomly augmenting the synthetic data with real data, we present our simple, effective and easy to implement synthetic data sampling methods to train deep CNNs more efficiently and accurately. To this end, we propose to maximally utilise the parameters learned during training of the GAN itself. These include discriminator's realism confidence score and the confidence on the target label of the synthetic data. In addition to this, we explore reinforcement learning (RL) to automatically search a subset of meaningful synthetic examples from a large pool of GAN synthetic data. We evaluate our method on two challenging face attribute classification data sets viz. AffectNet and CelebA. Our extensive experiments clearly demonstrate the need of sampling synthetic data before augmentation, which also improves the performance of one of the state-of-the-art deep CNNs in vitro.},
  keywords = {Generative adversarial networks,In vitro,Reinforcement learning,Sampling methods,Signal processing,Speech processing,Training}
}

@inproceedings{abadi2016DeepLearningDifferential,
  title = {Deep {{Learning}} with {{Differential Privacy}}},
  booktitle = {Proceedings of the 2016 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  date = {2016-10-24},
  series = {{{CCS}} '16},
  pages = {308--318},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2976749.2978318},
  url = {https://doi.org/10.1145/2976749.2978318},
  urldate = {2023-02-27},
  abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
  isbn = {978-1-4503-4139-4},
  keywords = {deep learning,differential privacy},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\4X4W2NAB\\Abadi et al_2016_Deep Learning with Differential Privacy.pdf}
}

@article{acharyaGenSynMultistageFramework,
  title = {{{GenSyn}}: {{A Multi-stage Framework}} for {{Generating Synthetic Microdata}} Using {{Macro Data Sources}}},
  author = {Acharya, Angeela and Sikdar, Siddhartha and Das, Sanmay and Rangwala, Huzefa},
  abstract = {Individual-level data (microdata) that characterizes a population, is essential for studying many real-world problems. However, acquiring such data is not straightforward due to cost and privacy constraints, and access is often limited to aggregated data (macro data) sources. In this study, we examine synthetic data generation as a tool to extrapolate difficultto-obtain high-resolution data by combining information from multiple easier-to-obtain lower-resolution data sources. In particular, we introduce a framework that uses a combination of univariate and multivariate frequency tables from a given target geographical location in combination with frequency tables from other auxiliary locations to generate synthetic microdata for individuals in the target location. Our method combines the estimation of a dependency graph and conditional probabilities from the target location with the use of a Gaussian copula to leverage the available information from the auxiliary locations. We perform extensive testing on two real-world datasets and demonstrate that our approach outperforms prior approaches in preserving the overall dependency structure of the data while also satisfying the constraints defined on the different variables.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\HKNAB7BN\\Acharya et al. - GenSyn A Multi-stage Framework for Generating Syn.pdf}
}

@book{aggarwal2018NeuralNetworksDeep,
  title = {Neural Networks and Deep Learning: A Textbook},
  shorttitle = {Neural Networks and Deep Learning},
  author = {Aggarwal, Charu C.},
  date = {2018},
  publisher = {{Springer}},
  location = {{Cham, Switzerland}},
  doi = {10.1007/978-3-319-94463-0},
  isbn = {978-3-319-94462-3 978-3-030-06856-1},
  langid = {english},
  pagetotal = {497},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\54X9KUUR\\Aggarwal_2018_Neural networks and deep learning.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\JQDJETYE\\2018_Book_NeuralNetworksAndDeepLearning.pdf}
}

@online{agostinelli2023MusicLMGeneratingMusic,
  title = {{{MusicLM}}: {{Generating Music From Text}}},
  shorttitle = {{{MusicLM}}},
  author = {Agostinelli, Andrea and Denk, Timo I. and Borsos, Zalán and Engel, Jesse and Verzetti, Mauro and Caillon, Antoine and Huang, Qingqing and Jansen, Aren and Roberts, Adam and Tagliasacchi, Marco and Sharifi, Matt and Zeghidour, Neil and Frank, Christian},
  date = {2023-01-26},
  number = {arXiv:2301.11325},
  eprint = {arXiv:2301.11325},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2301.11325},
  urldate = {2023-02-13},
  abstract = {We introduce MusicLM, a model generating high-fidelity music from text descriptions such as "a calming violin melody backed by a distorted guitar riff". MusicLM casts the process of conditional music generation as a hierarchical sequence-to-sequence modeling task, and it generates music at 24 kHz that remains consistent over several minutes. Our experiments show that MusicLM outperforms previous systems both in audio quality and adherence to the text description. Moreover, we demonstrate that MusicLM can be conditioned on both text and a melody in that it can transform whistled and hummed melodies according to the style described in a text caption. To support future research, we publicly release MusicCaps, a dataset composed of 5.5k music-text pairs, with rich text descriptions provided by human experts.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\27GRRLUM\\Agostinelli et al_2023_MusicLM.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\T35Z2A72\\2301.html}
}

@article{aguado2013InfluenceMeasurementNoise,
  title = {Influence of Measurement Noise and Laser Arrangement on Measurement Uncertainty of Laser Tracker Multilateration in Machine Tool Volumetric Verification},
  author = {Aguado, S. and Santolaria, J. and Samper, D. and Aguilar, J.J.},
  date = {2013-10-01},
  journaltitle = {Precision Engineering},
  shortjournal = {Precision Engineering},
  volume = {37},
  number = {4},
  pages = {929--943},
  issn = {0141-6359},
  doi = {10.1016/j.precisioneng.2013.03.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0141635913000561},
  abstract = {This paper aims to present different techniques and factors that affect the measurement accuracy of a commercial laser tracker responsible for capturing checkpoints used in machine tool volumetric verification. This study was conducted to uncover various sources of error affecting the measurement uncertainty of the laser tracker, additional sources of error that further contributed to the uncertainty, and the factors influencing these techniques. We also define several noise reduction techniques for the measurements. The improvement in the accuracy of captured points focuses on a multilateration technique and its various resolution methods both analytically and geometrically. Similarly, we present trilateration and least squares techniques that can be used for laser tracker self-calibration, which is an essential parameter in multilateration. This paper presents the influence of the spatial distribution of laser trackers (LTs) in measurement noise reduction by multilateration, which produces an improvement in volumetric error machine tool reduction. A study of the spatial angle between LTs, the distance and the visibility of the point to be measured are presented using a synthetic test. All of these factors limit the scope of multilateration. Similarly, a comparison of self-calibration techniques using the least squares and trilateration methods with which to determine the relative position of the laser tracker employees is presented. We also present the influence of the relationship between the radial and angular measurement noise self-calibration processes as it relates to the volumetric error reduction achieved by the machine tool with multilateration. All studies were performed using synthetic tests generated using a synthetic data parametric generator.},
  keywords = {Laser tracker positioning,Laser tracker self-calibration,Multilateration,Volumetric verification}
}

@software{akim2023TabDDPMModellingTabular,
  title = {{{TabDDPM}}: {{Modelling Tabular Data}} with {{Diffusion Models}}},
  shorttitle = {{{TabDDPM}}},
  author = {Akim},
  date = {2023-03-05T21:36:18Z},
  origdate = {2022-10-02T23:01:07Z},
  url = {https://github.com/rotot0/tab-ddpm},
  urldate = {2023-03-07},
  keywords = {deep-learning,diffusion-models,pytorch,tabular}
}

@online{alaa2021HowFaithfulYour,
  title = {How {{Faithful}} Is Your {{Synthetic Data}}? {{Sample-level Metrics}} for {{Evaluating}} and {{Auditing Generative Models}}},
  shorttitle = {How {{Faithful}} Is Your {{Synthetic Data}}?},
  author = {Alaa, Ahmed M. and van Breugel, Boris and Saveliev, Evgeny and van der Schaar, Mihaela},
  options = {useprefix=true},
  date = {2021-02-17},
  number = {arXiv:2102.08921},
  eprint = {arXiv:2102.08921},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2102.08921},
  urldate = {2022-06-23},
  abstract = {Devising domain- and model-agnostic evaluation metrics for generative models is an important and as yet unresolved problem. Most existing metrics, which were tailored solely to the image synthesis setup, exhibit a limited capacity for diagnosing the different modes of failure of generative models across broader application domains. In this paper, we introduce a 3-dimensional evaluation metric, (α-Precision, β-Recall, Authenticity), that characterizes the fidelity, diversity and generalization performance of any generative model in a domainagnostic fashion. Our metric unifies statistical divergence measures with precision-recall analysis, enabling sample- and distribution-level diagnoses of model fidelity and diversity. We introduce generalization as an additional, independent dimension (to the fidelity-diversity trade-off) that quantifies the extent to which a model copies training data—a crucial performance indicator when modeling sensitive data with requirements on privacy. The three metric components correspond to (interpretable) probabilistic quantities, and are estimated via sample-level binary classification. The sample-level nature of our metric inspires a novel use case which we call model auditing, wherein we judge the quality of individual samples generated by a (black-box) model, discarding lowquality samples and hence improving the overall model performance in a post-hoc manner.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\7L28G8JE\\Alaa et al. - 2021 - How Faithful is your Synthetic Data Sample-level .pdf}
}

@online{altman2019SynthesizingCreditCard,
  title = {Synthesizing {{Credit Card Transactions}}},
  author = {Altman, Erik R.},
  date = {2019-10-03},
  number = {arXiv:1910.03033},
  eprint = {arXiv:1910.03033},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1910.03033},
  urldate = {2022-08-30},
  abstract = {Two elements have been essential to AI's recent boom: (1) deep neural nets and the theory and practice behind them; and (2) cloud computing with its abundant labeled data and large computing resources. Abundant labeled data is available for key domains such as images, speech, natural language processing, and recommendation engines. However, there are many other domains where such data is not available, or access to it is highly restricted for privacy reasons, as with health and financial data. Even when abundant data is available, it is often not labeled. Doing such labeling is labor-intensive and non-scalable. As a result, to the best of our knowledge, key domains still lack labeled data or have at most toy data; or the synthetic data must have access to real data from which it can mimic new data. This paper outlines work to generate realistic synthetic data for an important domain: credit card transactions. Some challenges: there are many patterns and correlations in real purchases. There are millions of merchants and innumerable locations. Those merchants offer a wide variety of goods. Who shops where and when? How much do people pay? What is a realistic fraudulent transaction? We use a mixture of technical approaches and domain knowledge including mechanics of credit card processing, a broad set of consumer domains: electronics, clothing, hair styling, etc. Connecting everything is a virtual world. This paper outlines some of our key techniques and provides evidence that the data generated is indeed realistic. Beyond the scope of this paper: (1) use of our data to develop and train models to predict fraud; (2) coupling models and the synthetic dataset to assess performance in designing accelerators such as GPUs and TPUs.},
  pubstate = {preprint},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning,Computer Science - Performance},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\TKA48NBZ\\Altman_2019_Synthesizing Credit Card Transactions.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\KMIDYLXZ\\1910.html}
}

@inproceedings{alzantot2017SenseGenDeepLearning,
  title = {{{SenseGen}}: {{A}} Deep Learning Architecture for Synthetic Sensor Data Generation},
  shorttitle = {{{SenseGen}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications Workshops}} ({{PerCom Workshops}})},
  author = {Alzantot, Moustafa and Chakraborty, Supriyo and Srivastava, Mani},
  date = {2017-03},
  pages = {188--193},
  publisher = {{IEEE}},
  location = {{Kona, HI}},
  doi = {10.1109/PERCOMW.2017.7917555},
  url = {https://ieeexplore.ieee.org/document/7917555/},
  urldate = {2022-06-30},
  abstract = {Our ability to synthesize sensory data that preserves specific statistical properties of the real data has had tremendous implications on data privacy and big data analytics. The synthetic data can be used as a substitute for selective real data segments - that are sensitive to the user - thus protecting privacy and resulting in improved analytics. However, increasingly adver­ sarial roles taken by data recipients such as mobile apps, or other cloud-based analytics services, mandate that the synthetic data, in addition to preserving statistical properties, should also be "difficult to distinguish from the real data. Typically, visual inspection has been used as a test to distinguish between datasets. But more recently, sophisticated classifier models (discrimina­ tors), corresponding to a set of events, have also been employed to distinguish between synthesized and real data. The model operates on both datasets and the respective event outputs are compared for consistency.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Pervasive Computing}} and {{Communications}}: {{Workshops}} ({{PerCom Workshops}})},
  isbn = {978-1-5090-4338-5},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\7SJBKZQB\\Alzantot et al_2017_SenseGen.pdf}
}

@inproceedings{arjovsky2017WassersteinGenerativeAdversarial,
  title = {Wasserstein {{Generative Adversarial Networks}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
  date = {2017-07-17},
  pages = {214--223},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v70/arjovsky17a.html},
  urldate = {2022-07-15},
  abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to different distances between distributions.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\EW5UIYFU\\Arjovsky et al_2017_Wasserstein Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\ISLVWYXZ\\Arjovsky et al. - 2017 - Wasserstein Generative Adversarial Networks.pdf}
}

@book{baldi2021DeepLearningScience,
  title = {Deep {{Learning}} in {{Science}}},
  author = {Baldi, Pierre},
  date = {2021},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/9781108955652},
  url = {https://www.cambridge.org/core/books/deep-learning-in-science/5A620F1E5DB54A7FB1D3E3C1A80E0860},
  urldate = {2023-02-15},
  abstract = {This is the first rigorous, self-contained treatment of the theory of deep learning. Starting with the foundations of the theory and building it up, this is essential reading for any scientists, instructors, and students interested in artificial intelligence and deep learning. It provides guidance on how to think about scientific questions, and leads readers through the history of the field and its fundamental connections to neuroscience. The author discusses many applications to beautiful problems in the natural sciences, in physics, chemistry, and biomedicine. Examples include the search for exotic particles and dark matter in experimental physics, the prediction of molecular properties and reaction outcomes in chemistry, and the prediction of protein structures and the diagnostic analysis of biomedical images in the natural sciences. The text is accompanied by a full set of exercises at different difficulty levels and encourages out-of-the-box thinking.},
  isbn = {978-1-108-84535-9},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\5X3XULH3\\Baldi_2021_Deep Learning in Science.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\9MUW5VDQ\\5A620F1E5DB54A7FB1D3E3C1A80E0860.html}
}

@incollection{Bank2020Autoencoders,
  title = {Autoencoders},
  booktitle = {Deep {{Learning}} in {{Science}}},
  author = {Bank, Dor and Koenigstein, Noam and Giryes, Raja},
  date = {2020},
  volume = {abs/2003.05991},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  isbn = {978-1-108-84535-9},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\VWWDIHBW\\Baldi_2021_Deep Learning in Science.pdf}
}

@article{barros2013DeterminationWaterSaturation,
  title = {Determination of Water Saturation by Angular Competitive Neural Network},
  author = {Barros, Carolina and Andrade, André},
  date = {2013-02-01},
  journaltitle = {Journal of Petroleum Science and Engineering},
  shortjournal = {Journal of Petroleum Science and Engineering},
  volume = {102},
  pages = {47--56},
  issn = {0920-4105},
  doi = {10.1016/j.petrol.2013.01.007},
  url = {https://www.sciencedirect.com/science/article/pii/S092041051300017X},
  abstract = {The accuracy on determining water saturation is decisive to perform a realistic evaluation of hydrocarbon reserves and critical to reduce the economic risks in the oil industry investments. Water saturation is the solution of the Archie equation, but in many situations, a quick and convenient solution of this equation may be a hard problem, mainly when there is no confidence on porosity and when the conventional core analysis does not supply the cementation exponent and the water resistivity. In these cases, an association of the Hingle plot with the Pickett plot may be used to solve the Archie equation, but as any graphic these methods are frequently subject to visual misinterpretation. In this work, we assume the resistivity–porosity dependence in the Archie equation as an angular pattern and introduce an intelligent algorithm based on a new model of artificial neural network, named as angular competitive neural network, which was designed to discover angular patterns present in the data. This characteristic makes the angular competitive neural network be able to produce all parameters needed to solve the Archie equation, performing angular pattern recognition in the Hingle plot and in the Pickett plot. This method is presented with synthetic data and evaluated using actual wireline logs and conventional core analysis.},
  keywords = {artificial neural networks,formation evaluation,water saturation}
}

@book{bass2013SoftwareArchitecturePractice,
  title = {Software Architecture in Practice},
  author = {Bass, Len and Clements, Paul and Kazman, Rick},
  date = {2013},
  series = {{{SEI}} Series in Software Engineering},
  edition = {3rd ed},
  publisher = {{Addison-Wesley}},
  location = {{Upper Saddle River, NJ}},
  isbn = {978-0-321-81573-6},
  pagetotal = {589},
  keywords = {Software architecture,System design},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\KFS8UTEI\\Bass et al. - 2013 - Software architecture in practice.pdf}
}

@online{BayesianGaussianMixture,
  title = {Bayesian {{Gaussian Mixture}}},
  url = {https://scikit-learn/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html},
  urldate = {2023-03-09},
  abstract = {Examples using sklearn.mixture.BayesianGaussianMixture: Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture Concentration Prior Type Analysis of Variation Bayesian Gaussian Mix...},
  langid = {english},
  organization = {{scikit-learn}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JLVJY9XF\\sklearn.mixture.BayesianGaussianMixture.html}
}

@article{bishop1998latent,
  title = {Latent Variable Models.},
  author = {Bishop, Christopher M},
  date = {1998},
  journaltitle = {Learning in graphical models},
  volume = {371}
}

@book{bishop2006PatternRecognitionMachine,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  date = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-31073-2},
  langid = {english},
  pagetotal = {738},
  keywords = {Machine learning,Pattern perception},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\968D4335\\Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{borisov2022DeepNeuralNetworks,
  title = {Deep {{Neural Networks}} and {{Tabular Data}}: {{A Survey}}},
  shorttitle = {Deep {{Neural Networks}} and {{Tabular Data}}},
  author = {Borisov, Vadim and Leemann, Tobias and Sessler, Kathrin and Haug, Johannes and Pawelczyk, Martin and Kasneci, Gjergji},
  date = {2022},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  shortjournal = {IEEE Trans. Neural Netw. Learning Syst.},
  pages = {1--21},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2022.3229161},
  url = {https://ieeexplore.ieee.org/document/9998482/},
  urldate = {2023-01-23},
  abstract = {—Heterogeneous tabular data are the most commonly used form of data and are essential for numerous critical and computationally demanding applications. On homogeneous data sets, deep neural networks have repeatedly shown excellent performance and have therefore been widely adopted. However, their adaptation to tabular data for inference or data generation tasks remains highly challenging. To facilitate further progress in the field, this work provides an overview of state-of-the-art deep learning methods for tabular data. We categorize these methods into three groups: data transformations, specialized architectures, and regularization models. For each of these groups, our work offers a comprehensive overview of the main approaches. Moreover, we discuss deep learning approaches for generating tabular data, and we also provide an overview over strategies for explaining deep models on tabular data. Thus, our first contribution is to address the main research streams and existing methodologies in the mentioned areas, while highlighting relevant challenges and open research questions. Our second contribution is to provide an empirical comparison of traditional machine learning methods with eleven deep learning approaches across five popular real-world tabular data sets of different sizes and with different learning objectives. Our results, which we have made publicly available as competitive benchmarks, indicate that algorithms based on gradient-boosted tree ensembles still mostly outperform deep learning models on supervised learning tasks, suggesting that the research progress on competitive deep learning models for tabular data is stagnating. To the best of our knowledge, this is the first in-depth overview of deep learning approaches for tabular data; as such, this work can serve as a valuable starting point to guide researchers and practitioners interested in deep learning with tabular data.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\57KRH8DS\\Borisov et al_2022_Deep Neural Networks and Tabular Data.pdf}
}

@article{bourou2021ReviewTabularData,
  title = {A {{Review}} of {{Tabular Data Synthesis Using GANs}} on an {{IDS Dataset}}},
  author = {Bourou, Stavroula and El Saer, Andreas and Velivassaki, Terpsichori-Helen and Voulkidis, Artemis and Zahariadis, Theodore},
  date = {2021-09-14},
  journaltitle = {Information},
  shortjournal = {Information},
  volume = {12},
  number = {9},
  pages = {375},
  issn = {2078-2489},
  doi = {10.3390/info12090375},
  url = {https://www.mdpi.com/2078-2489/12/9/375},
  urldate = {2022-06-29},
  abstract = {Recent technological innovations along with the vast amount of available data worldwide have led to the rise of cyberattacks against network systems. Intrusion Detection Systems (IDS) play a crucial role as a defense mechanism in networks against adversarial attackers. Machine Learning methods provide various cybersecurity tools. However, these methods require plenty of data to be trained efficiently, which may be hard to collect or to use due to privacy reasons. One of the most notable Machine Learning tools is the Generative Adversarial Network (GAN), and it has great potential for tabular data synthesis. In this work, we start by briefly presenting the most popular GAN architectures, VanillaGAN, WGAN, and WGAN-GP. Focusing on tabular data generation, CTGAN, CopulaGAN, and TableGAN models are used for the creation of synthetic IDS data. Specifically, the models are trained and evaluated on an NSL-KDD dataset, considering the limitations and requirements that this procedure needs. Finally, based on certain quantitative and qualitative methods, we argue and evaluate the most prominent GANs for tabular network data synthesis.},
  langid = {english},
  keywords = {✔️,01,categorical data,cyber secruity,GAN,IDS,Intrusion Detection Systems,NSL-KDD dataset,synthetic dataset,tabular data generation},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\RVEMPGID\\Bourou et al_2021_A Review of Tabular Data Synthesis Using GANs on an IDS Dataset.pdf}
}

@thesis{brenninkmeijer2019GenerationEvaluationTabular,
  type = {mathesis},
  title = {On the {{Generation}} and {{Evaluation}} of {{Tabular Data}} Using {{GANs}}},
  author = {Brenninkmeijer, Bauke and Hille, Youri and Vries, Arjen},
  date = {2019-10-14},
  institution = {{Radboud University}},
  location = {{Nijmegen, Netherlands}},
  url = {https://www.researchgate.net/publication/344227988_On_the_Generation_and_Evaluation_of_Tabular_Data_using_GANs},
  abstract = {With privacy regulations becoming stricter, the opportunity to apply synthetic data is growing rapidly. Synthetic data can be used in any setting where access to data with personal information is not strictly necessary. However, many require the synthetic data to present the same relations as the original data. Existing statistical models and anonymization tools often have adverse effects on the quality of data for downstream tasks like classification. Deep learning based synthesization techniques like GANs provide solutions for cases where it is vital these relations are kept. Inspired by GANs, we propose an improvement in the state-of-the-art in maintaining these relations in synthetic data. Our proposal includes three contributions. First, we propose the addition of skip connections in the generator, which increases gradient flow and modeling capacity. Second, we propose using the WGAN-GP architecture for training the GAN, which suffers less from mode-collapse and has a more meaningful loss. And finally, we propose a new similarity metric for evaluating synthetic data. This metric better captures different aspects of synthetic data when comparing it to real data. We study the behaviour of our proposed model adaptations against several baseline models on three datasets. Our results show that our proposals improve on the state-of-the-art models, by creating higher quality data. Our evaluation metric captures quality improvements in synthetic data and gives detailed insight into the strengths and weaknesses of evaluated models. We conclude that our proposed adaptations should be used for data synthesis, and our evaluation metric is precise and gives a balanced view of different aspects of the data.},
  langid = {english},
  pagetotal = {71},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\WE3W7F5E\\Brenninkmeijer et al_2019_On the Generation and Evaluation of Tabular Data using GANs.pdf}
}

@inproceedings{brocke2009ReconstructingGiantImportance,
  title = {Reconstructing the {{Giant}}: {{On}} the {{Importance}} of {{Rigour}} in {{Documenting}} the {{Literature Search Process}}},
  shorttitle = {Reconstructing the {{Giant}}},
  author = {vom Brocke, Jan and Simons, Alexander and Niehaves, Björn and Riemer, Kai and Plattfaut, Ralf and Cleven, Anne},
  date = {2009-06-10},
  abstract = {Science is a cumulative endeavour as new knowledge is often created in the process of interpreting and combining existing knowledge. This is why literature reviews have long played a decisive role in scholarship. The quality of literature reviews is particularly determined by the literature search process. As Sir Isaac Newton eminently put it: “If I can see further, it is because I am standing on the shoulders of giants.” Drawing on this metaphor, the goal of writing a literature review is to reconstruct the giant of accumulated knowledge in a specific domain. And in doing so, a literature search represents the fundamental first step that makes up the giant’s skeleton and largely determines its reconstruction in the subsequent literature analysis. In this paper, we argue that the process of searching the literature must be comprehensibly described. Only then can readers assess the exhaustiveness of the review and other scholars in the field can more confidently (re)use the results in their own research. We set out to explore the methodological rigour of literature review articles published in ten major information systems (IS) journals and show that many of these reviews do not thoroughly document the process of literature search. The results drawn from our analysis lead us to call for more rigour in documenting the literature search process and to present guidelines for crafting a literature review and search in the IS domain.},
  eventtitle = {{{http://www.alexandria.unisg.ch/Publikationen/67910}}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\A4VBSCXS\\Brocke et al_2009_Reconstructing the Giant.pdf}
}

@online{brownlee2019GentleIntroductionGenerative,
  title = {A {{Gentle Introduction}} to {{Generative Adversarial Networks}} ({{GANs}})},
  author = {Brownlee, Jason},
  date = {2019-06-16T19:00:35+00:00},
  url = {https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/},
  urldate = {2023-01-16},
  abstract = {Generative Adversarial Networks, or GANs for short, are an approach to generative modeling using deep learning methods, such as convolutional neural networks. Generative modeling is an unsupervised learning task in machine learning that involves automatically discovering and learning the regularities or patterns in input data in such a way that the model can be used […]},
  langid = {american},
  organization = {{MachineLearningMastery.com}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\BC547M75\\what-are-generative-adversarial-networks-gans.html}
}

@book{broy2021EinfuehrungSoftwaretechnik,
  title = {Einführung in die Softwaretechnik},
  author = {Broy, Manfred and Kuhrmann, Marco},
  date = {2021},
  series = {Xpert.press},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-50263-1},
  url = {https://link.springer.com/10.1007/978-3-662-50263-1},
  urldate = {2023-03-06},
  isbn = {978-3-662-50262-4 978-3-662-50263-1},
  langid = {ngerman},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\9D8CW4LP\\Broy und Kuhrmann - 2021 - Einführung in die Softwaretechnik.pdf}
}

@article{cai2021DataSynthesisDifferentially,
  title = {Data Synthesis via Differentially Private Markov Random Fields},
  author = {Cai, Kuntai and Lei, Xiaoyu and Wei, Jianxin and Xiao, Xiaokui},
  date = {2021-07},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {14},
  number = {11},
  pages = {2190--2202},
  issn = {2150-8097},
  doi = {10.14778/3476249.3476272},
  url = {https://dl.acm.org/doi/10.14778/3476249.3476272},
  urldate = {2022-06-23},
  abstract = {This paper studies the synthesis of high-dimensional datasets with differential privacy (DP). The state-of-the-art solution addresses this problem by first generating a set M of noisy low-dimensional marginals of the input data 𝐷, and then use them to approximate the data distribution in 𝐷 for synthetic data generation. However, it imposes several constraints on M that considerably limits the choices of marginals. This makes it difficult to capture all important correlations among attributes, which in turn degrades the quality of the resulting synthetic data.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\93W5EBK4\\Cai et al_2021_Data synthesis via differentially private markov random fields.pdf}
}

@thesis{capel2022MasterThesisDenoising,
  type = {mathesis},
  title = {Master Thesis : {{Denoising}} Diffusion Probabilistic Models Applied to Energy Forecasting in Power Systems},
  author = {Capel, Hernandez},
  date = {2022},
  institution = {{University of Liège}},
  location = {{Liege, Belgium}},
  langid = {english},
  pagetotal = {75},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\BGZPLJVQ\\Capel - Master thesis  Denoising diffusion probabilistic .pdf}
}

@article{Castro201937,
  title = {A Linear Optimization-Based Method for Data Privacy in Statistical Tabular Data},
  author = {Castro, J. and González, J.A.},
  date = {2019},
  journaltitle = {Optimization Methods and Software},
  volume = {34},
  number = {1},
  pages = {37--61},
  doi = {10.1080/10556788.2017.1332620},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020545957&doi=10.1080%2f10556788.2017.1332620&partnerID=40&md5=8f6b62142cc1759c8a7b804a9b75b261},
  abstract = {National Statistical Agencies routinely disseminate large amount of data. Prior to dissemination these data have to be protected to avoid releasing confidential information. Controlled tabular adjustment (CTA) is one of the available methods for this purpose. CTA formulates an optimization problem that looks for the safe table which is closest to the original one. The standard CTA approach results in a mixed integer linear optimization (MILO) problem, which is very challenging for current technology. In this work we present a much less costly variant of CTA that formulates a multiobjective linear optimization (LO) problem, where binary variables are pre-fixed, and the resulting continuous problem is solved by lexicographic optimization. Extensive computational results are reported using both commercial (CPLEX and XPRESS) and open source (Clp) solvers, with either simplex or interior-point methods, on a set of real instances. Most instances were successfully solved with the LO-CTA variant in less than one hour, while many of them are computationally very expensive with the MILO-CTA formulation. The interior-point method outperformed simplex in this particular application. © 2017, © 2017 Informa UK Limited, trading as Taylor \& Francis Group.}
}

@misc{charitou2021SyntheticDataGenerationa,
  title = {Synthetic {{Data Generation}} for {{Fraud Detection}} Using {{GANs}}},
  author = {Charitou, Charitos and Dragicevic, Simo and d'Avila Garcez, Artur},
  options = {useprefix=true},
  date = {2021-09-26},
  number = {arXiv:2109.12546},
  eprint = {2109.12546},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2109.12546},
  url = {http://arxiv.org/abs/2109.12546},
  urldate = {2022-07-10},
  abstract = {Detecting money laundering in gambling is becoming increasingly challenging for the gambling industry as consumers migrate to online channels. Whilst increasingly stringent regulations have been applied over the years to prevent money laundering in gambling, despite this, online gambling is still a channel for criminals to spend proceeds from crime. Complementing online gambling's growth more concerns are raised to its effects compared with gambling in traditional, physical formats, as it might introduce higher levels of problem gambling or fraudulent behaviour due to its nature of immediate interaction with online gambling experience. However, in most cases the main issue when organisations try to tackle those areas is the absence of high quality data. Since fraud detection related issues face the significant problem of the class imbalance, in this paper we propose a novel system based on Generative Adversarial Networks (GANs) for generating synthetic data in order to train a supervised classifier. Our framework Synthetic Data Generation GAN (SDG-GAN), manages to outperformed density based over-sampling methods and improve the classification performance of benchmarks datasets and the real world gambling fraud dataset.},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\A7WKNJ2A\\Charitou et al_2021_Synthetic Data Generation for Fraud Detection using GANs.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\X9U37ZTF\\2109.html}
}

@article{chawla2002SMOTESyntheticMinority,
  title = {{{SMOTE}}: Synthetic Minority over-Sampling Technique},
  shorttitle = {{{SMOTE}}},
  author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
  date = {2002-06-01},
  journaltitle = {Journal of Artificial Intelligence Research},
  shortjournal = {J. Artif. Int. Res.},
  volume = {16},
  number = {1},
  pages = {321--357},
  issn = {1076-9757},
  abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of oversampling the minority (abnormal)cla ss and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space)tha n only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space)t han varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC)and the ROC convex hull strategy.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\5YIK8GWY\\Chawla et al_2002_SMOTE.pdf}
}

@article{chetluradithya2017TrendsFetalMonitoring,
  title = {Trends in Fetal Monitoring through Phonocardiography: {{Challenges}} and Future Directions},
  author = {Chetlur Adithya, Prashanth and Sankar, Ravi and Moreno, Wilfrido Alejandro and Hart, Stuart},
  date = {2017-03-01},
  journaltitle = {Biomedical Signal Processing and Control},
  shortjournal = {Biomedical Signal Processing and Control},
  volume = {33},
  pages = {289--305},
  issn = {1746-8094},
  doi = {10.1016/j.bspc.2016.11.007},
  url = {https://www.sciencedirect.com/science/article/pii/S1746809416301859},
  abstract = {Monitoring the well-being of a fetus through Fetal Phonocardiography (FPCG) has been occurring for more than a century. Throughout history, there have been continuous advances in sensor development, data acquisition systems, and signal processing techniques. Despite these advancements, FPCG based point of care technologies are facing serious challenges in translating from basic research to clinical trials and commercialization. This is partly due to the noisy characteristic associated with FPCG, to the lesser clinical knowledge about fetal and maternal physiological profiles, to the unavailability of gold standard databases, and to the limited application of reliable signal processing techniques. In order to understand why FPCG continues to be underutilized, it is necessary to know about the existing standards of fetal monitoring, data collection trends, and the signal processing aspects. To serve this purpose, this paper will first provide an overview of the existing standards of fetal monitoring and then provide a comprehensive survey on Fetal Phonocardiography with focus on trends in data collection, signal processing techniques and synthesis models that have been developed to date. Finally, a set of guidelines will be proposed for future research and use in signal analysis, processing and modeling based on the outlined challenges.},
  keywords = {De-noising,Fetal heart rate,Fetal heart sounds,Fetal monitoring,Fetal phonocardiography,Phonocardiogram modeling}
}

@inproceedings{cho2014PropertiesNeuralMachine,
  title = {On the {{Properties}} of {{Neural Machine Translation}}: {{Encoder}}–{{Decoder Approaches}}},
  shorttitle = {On the {{Properties}} of {{Neural Machine Translation}}},
  booktitle = {Proceedings of {{SSST-8}}, {{Eighth Workshop}} on {{Syntax}}, {{Semantics}} and {{Structure}} in {{Statistical Translation}}},
  author = {Cho, Kyunghyun and van Merriënboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  options = {useprefix=true},
  date = {2014-10},
  pages = {103--111},
  publisher = {{Association for Computational Linguistics}},
  location = {{Doha, Qatar}},
  doi = {10.3115/v1/W14-4012},
  url = {https://aclanthology.org/W14-4012},
  urldate = {2023-02-14},
  eventtitle = {{{SSST}} 2014},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\3RKDC8UI\\Cho et al_2014_On the Properties of Neural Machine Translation.pdf}
}

@inproceedings{choi2017GeneratingMultilabelDiscrete,
  title = {Generating {{Multi-label Discrete Patient Records}} Using {{Generative Adversarial Networks}}},
  booktitle = {Proceedings of the 2nd {{Machine Learning}} for {{Healthcare Conference}}},
  author = {Choi, Edward and Biswal, Siddharth and Malin, Bradley and Duke, Jon and Stewart, Walter F. and Sun, Jimeng},
  date = {2017-11-06},
  pages = {286--305},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v68/choi17a.html},
  urldate = {2023-03-01},
  abstract = {Access to electronic health record (EHR) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of EHR data. Sharing synthetic EHR data could mitigate risk. In this paper, we propose a new approach, medical Generative Adversarial Network (medGAN), to generate realistic synthetic patient records. Based on input real patient records, medGAN can generate high-dimensional discrete variables (e.g., binary and count features) via a combination of an autoencoder and generative adversarial networks. We also propose minibatch averaging to efficiently avoid mode collapse, and increase the learning efficiency with batch normalization and shortcut connections. To demonstrate feasibility, we showed that medGAN generates synthetic patient records that achieve comparable performance to real data on many experiments including distribution statistics, predictive modeling tasks and a medical expert review. We also empirically observe a limited privacy risk in both identity and attribute disclosure using medGAN.},
  eventtitle = {Machine {{Learning}} for {{Healthcare Conference}}},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ZZDL34EX\\Choi et al_2017_Generating Multi-label Discrete Patient Records using Generative Adversarial.pdf}
}

@article{chundawat2022UniversalMetricRobust,
  title = {A {{Universal Metric}} for {{Robust Evaluation}} of {{Synthetic Tabular Data}}},
  author = {Chundawat, Vikram S and Tarun, Ayush K and Mandal, Murari and Lahoti, Mukund and Narang, Pratik},
  date = {2022},
  journaltitle = {IEEE Transactions on Artificial Intelligence},
  pages = {1--11},
  issn = {2691-4581},
  doi = {10.1109/TAI.2022.3229289},
  abstract = {Synthetic tabular data generation becomes crucial when real data is limited, expensive to collect, or simply cannot be used due to privacy concerns. However, producing good quality synthetic data is challenging. Several probabilistic, statistical, generative adversarial networks (GANs), and variational auto-encoder (VAEs) based approaches have been presented for synthetic tabular data generation. Once generated, evaluating the quality of the synthetic data is quite challenging. Some of the traditional metrics have been used in the literature but there is lack of a common, robust, and single metric. This makes it difficult to properly compare the effectiveness of different synthetic tabular data generation methods. In this paper we propose a new universal metric, TabSynDex, for robust evaluation of synthetic data. The proposed metric assesses the similarity of synthetic data with real data through different component scores which evaluate the characteristics that are desirable for “high quality” synthetic data. Being a single score metric and having an implicit bound, TabSynDex can also be used to observe and evaluate the training of neural network based approaches. This would help in obtaining insights that was not possible earlier. We present several baseline models for comparative analysis of the proposed evaluation metric with existing generative models. We also give a comparative analysis between TabSynDex and existing synthetic tabular data evaluation metrics. This shows the effectiveness and universality of our metric over the existing metrics. Source Code: https://github.com/vikram2000b/tabsyndex},
  eventtitle = {{{IEEE Transactions}} on {{Artificial Intelligence}}},
  keywords = {Computer Science - Machine Learning,Data models,Data privacy,evaluation metrics,GANs,generative models,Generators,Measurement,Regulation,Synthetic data,Tabular data synthesis,Training},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\NJKLK2VB\\Chundawat et al_2022_TabSynDex.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\6LC6LLQA\\2207.html;C\:\\Users\\SvenG\\Zotero\\storage\\GP9P6D2A\\9984938.html}
}

@software{chundawat2022UniversalMetricRobusta,
  title = {A {{Universal Metric}} for {{Robust Evaluation}} of {{Synthetic Tabular Data}}},
  author = {Chundawat, Vikram Singh},
  date = {2022-12-11T13:48:16Z},
  origdate = {2022-12-06T12:51:58Z},
  url = {https://github.com/vikram2000b/tabsyndex},
  urldate = {2023-01-16}
}

@online{CommunityExamples,
  title = {Community {{Examples}}},
  url = {https://github.com/huggingface/diffusers},
  urldate = {2023-03-02},
  abstract = {🤗 Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch - diffusers/examples/community at main · huggingface/diffusers},
  langid = {english},
  organization = {{GitHub}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\MDK5APQL\\community.html}
}

@online{CopulaGANModelSDV,
  title = {{{CopulaGAN Model}} — {{SDV}} 0.15.0 Documentation},
  url = {https://sdv.dev/SDV/user_guides/single_table/copulagan.html},
  urldate = {2022-07-15},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\KS4SM6QU\\copulagan.html}
}

@article{dahmen2019SynSysSyntheticData,
  title = {{{SynSys}}: {{A Synthetic Data Generation System}} for {{Healthcare Applications}}},
  shorttitle = {{{SynSys}}},
  author = {Dahmen, Jessamyn and Cook, Diane},
  date = {2019-03-08},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {19},
  number = {5},
  pages = {1181},
  issn = {1424-8220},
  doi = {10.3390/s19051181},
  url = {https://www.mdpi.com/1424-8220/19/5/1181},
  urldate = {2022-06-30},
  abstract = {Creation of realistic synthetic behavior-based sensor data is an important aspect of testing machine learning techniques for healthcare applications. Many of the existing approaches for generating synthetic data are often limited in terms of complexity and realism. We introduce SynSys, a machine learning-based synthetic data generation method, to improve upon these limitations. We use this method to generate synthetic time series data that is composed of nested sequences using hidden Markov models and regression models which are initially trained on real datasets. We test our synthetic data generation technique on a real annotated smart home dataset. We use time series distance measures as a baseline to determine how realistic the generated data is compared to real data and demonstrate that SynSys produces more realistic data in terms of distance compared to random data generation, data from another home, and data from another time period. Finally, we apply our synthetic data generation technique to the problem of generating data when only a small amount of ground truth data is available. Using semi-supervised learning we demonstrate that SynSys is able to improve activity recognition accuracy compared to using the small amount of real data alone.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LIFEHCW7\\Dahmen_Cook_2019_SynSys.pdf}
}

@misc{darabi2021SynthesisingMultiModalMinoritya,
  title = {Synthesising {{Multi-Modal Minority Samples}} for {{Tabular Data}}},
  author = {Darabi, Sajad and Elor, Yotam},
  date = {2021-05-17},
  number = {arXiv:2105.08204},
  eprint = {2105.08204},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2105.08204},
  url = {http://arxiv.org/abs/2105.08204},
  urldate = {2022-07-10},
  abstract = {Real-world binary classification tasks are in many cases imbalanced, where the minority class is much smaller than the majority class. This skewness is challenging for machine learning algorithms as they tend to focus on the majority and greatly misclassify the minority. Adding synthetic minority samples to the dataset before training the model is a popular technique to address this difficulty and is commonly achieved by interpolating minority samples. Tabular datasets are often multi-modal and contain discrete (categorical) features in addition to continuous ones which makes interpolation of samples non-trivial. To address this, we propose a latent space interpolation framework which (1) maps the multi-modal samples to a dense continuous latent space using an autoencoder; (2) applies oversampling by interpolation in the latent space; and (3) maps the synthetic samples back to the original feature space. We defined metrics to directly evaluate the quality of the minority data generated and showed that our framework generates better synthetic data than the existing methods. Furthermore, the superior synthetic data yields better prediction quality in downstream binary classification tasks, as was demonstrated in extensive experiments with 27 publicly available real-world datasets},
  keywords = {02,Computer Science - Machine Learning,gan,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\C2IJIJYE\\Darabi_Elor_2021_Synthesising Multi-Modal Minority Samples for Tabular Data.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\MM55FGM7\\2105.html}
}

@inproceedings{dash2022PermutationInvariantStrategy,
  title = {Permutation {{Invariant Strategy Using Transformer Encoders}} for {{Table Understanding}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{NAACL}} 2022},
  author = {Dash, Sarthak and Bagchi, Sugato and Mihindukulasooriya, Nandana and Gliozzo, Alfio},
  date = {2022-07},
  pages = {788--800},
  publisher = {{Association for Computational Linguistics}},
  location = {{Seattle, United States}},
  doi = {10.18653/v1/2022.findings-naacl.59},
  url = {https://aclanthology.org/2022.findings-naacl.59},
  urldate = {2023-01-25},
  abstract = {Representing text in tables is essential for many business intelligence tasks such as semantic retrieval, data exploration and visualization, and question answering. Existing methods that leverage pretrained Transformer encoders range from a simple construction of pseudo-sentences by concatenating text across rows or columns to complex parameter-intensive models that encode table structure and require additional pretraining. In this work, we introduce a novel encoding strategy for Transformer encoders that preserves the critical property of permutation invariance across rows or columns. Unlike existing state-of-the-art methods for Table Understanding, our proposed approach does not require any additional pretraining and still substantially outperforms existing methods in almost all instances. We demonstrate the effectiveness of our proposed approach on three table interpretation tasks: column type annotation, relation extraction, and entity linking through extensive experiments on existing tabular datasets.},
  eventtitle = {Findings 2022},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\WDXBWI9P\\Dash et al_2022_Permutation Invariant Strategy Using Transformer Encoders for Table.pdf}
}

@inproceedings{DBLP:journals/corr/BahdanauCB14,
  title = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {3rd International Conference on Learning Representations, {{ICLR}} 2015, San Diego, {{CA}}, {{USA}}, May 7-9, 2015, Conference Track Proceedings},
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  editor = {Bengio, Yoshua and LeCun, Yann},
  date = {2015},
  url = {http://arxiv.org/abs/1409.0473},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200}
}

@misc{delaney2019SynthesisRealisticECGa,
  title = {Synthesis of {{Realistic ECG}} Using {{Generative Adversarial Networks}}},
  author = {Delaney, Anne Marie and Brophy, Eoin and Ward, Tomas E.},
  date = {2019-09-19},
  number = {arXiv:1909.09150},
  eprint = {1909.09150},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1909.09150},
  url = {http://arxiv.org/abs/1909.09150},
  urldate = {2022-07-10},
  abstract = {Access to medical data is highly restricted due to its sensitive nature, preventing communities from using this data for research or clinical training. Common methods of de-identification implemented to enable the sharing of data are sometimes inadequate to protect the individuals contained in the data. For our research, we investigate the ability of generative adversarial networks (GANs) to produce realistic medical time series data which can be used without concerns over privacy. The aim is to generate synthetic ECG signals representative of normal ECG waveforms. GANs have been used successfully to generate good quality synthetic time series and have been shown to prevent re-identification of individual records. In this work, a range of GAN architectures are developed to generate synthetic sine waves and synthetic ECG. Two evaluation metrics are then used to quantitatively assess how suitable the synthetic data is for real world applications such as clinical training and data analysis. Finally, we discuss the privacy concerns associated with sharing synthetic data produced by GANs and test their ability to withstand a simple membership inference attack. For the first time we both quantitatively and qualitatively demonstrate that GAN architecture can successfully generate time series signals that are not only structurally similar to the training sets but also diverse in nature across generated samples. We also report on their ability to withstand a simple membership inference attack, protecting the privacy of the training set.},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\V44I4GX9\\Delaney et al_2019_Synthesis of Realistic ECG using Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\YXAN3VRV\\1909.html}
}

@article{delcarmenrodriguez-hernandez2017DataGenCARSGeneratorSynthetic,
  title = {{{DataGenCARS}}: {{A}} Generator of Synthetic Data for the Evaluation of Context-Aware Recommendation Systems},
  shorttitle = {{{DataGenCARS}}},
  author = {del Carmen~Rodríguez-Hernández, María and Ilarri, Sergio and Hermoso, Ramón and Trillo-Lado, Raquel},
  options = {useprefix=true},
  date = {2017-07},
  journaltitle = {Pervasive and Mobile Computing},
  shortjournal = {Pervasive and Mobile Computing},
  volume = {38},
  pages = {516--541},
  issn = {15741192},
  doi = {10.1016/j.pmcj.2016.09.020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S157411921630270X},
  urldate = {2022-06-30},
  abstract = {Context-Aware Recommender Systems (CARS) have started to attract significant research attention in the last years, due to the interest of considering the context of the user in order to offer him/her more appropriate recommendations. However, the evaluation of CARS is a challenge, due to the scarce availability of appropriate datasets that incorporate context information related to the ratings provided by the users.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\7CG8NY3U\\del Carmen Rodríguez-Hernández et al_2017_DataGenCARS.pdf}
}

@article{DELCARMENRODRIGUEZHERNANDEZ2017516,
  title = {{{DataGenCARS}}: {{A}} Generator of Synthetic Data for the Evaluation of Context-Aware Recommendation Systems},
  author = {del Carmen Rodríguez-Hernández, María and Ilarri, Sergio and Hermoso, Ramón and Trillo-Lado, Raquel},
  options = {useprefix=true},
  date = {2017},
  journaltitle = {Pervasive and Mobile Computing},
  volume = {38},
  pages = {516--541},
  issn = {1574-1192},
  doi = {10.1016/j.pmcj.2016.09.020},
  url = {https://www.sciencedirect.com/science/article/pii/S157411921630270X},
  abstract = {Context-Aware Recommender Systems (CARS) have started to attract significant research attention in the last years, due to the interest of considering the context of the user in order to offer him/her more appropriate recommendations. However, the evaluation of CARS is a challenge, due to the scarce availability of appropriate datasets that incorporate context information related to the ratings provided by the users. In this paper, we present DataGenCARS, a complete Java-based synthetic dataset generator that can be used to obtain the required datasets for any type of scenario desired, allowing a high flexibility in the obtention of appropriate data that can be used to evaluate CARS. The generator presents features such as: a flexible definition of user schemas, user profiles, types of items, and types of contexts; a realistic generation of ratings and attributes of items; the possibility to mix real and synthetic datasets; functionalities to analyze existing datasets as a basis for synthetic data generation; and support for the automatic mapping between item schemas and Java classes. Moreover, an experimental evaluation illustrates the interest and the benefits provided by DataGenCARS.},
  keywords = {02,Context-aware recommendation systems,Dataset generation,Evaluation,Mobile recommendations},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\K2D7BJBQ\\del Carmen Rodríguez-Hernández et al_2017_DataGenCARS.pdf}
}

@article{DEMELO2022174,
  title = {Next-Generation Deep Learning Based on Simulators and Synthetic Data},
  author = {de Melo, Celso M. and Torralba, Antonio and Guibas, Leonidas and DiCarlo, James and Chellappa, Rama and Hodgins, Jessica},
  options = {useprefix=true},
  date = {2022},
  journaltitle = {Trends in Cognitive Sciences},
  volume = {26},
  number = {2},
  pages = {174--187},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2021.11.008},
  url = {https://www.sciencedirect.com/science/article/pii/S136466132100293X},
  abstract = {Deep learning (DL) is being successfully applied across multiple domains, yet these models learn in a most artificial way: they require large quantities of labeled data to grasp even simple concepts. Thus, the main bottleneck is often access to supervised data. Here, we highlight a trend in a potential solution to this challenge: synthetic data. Synthetic data are becoming accessible due to progress in rendering pipelines, generative adversarial models, and fusion models. Moreover, advancements in domain adaptation techniques help close the statistical gap between synthetic and real data. Paradoxically, this artificial solution is also likely to enable more natural learning, as seen in biological systems, including continual, multimodal, and embodied learning. Complementary to this, simulators and deep neural networks (DNNs) will also have a critical role in providing insight into the cognitive and neural functioning of biological systems. We also review the strengths of, and opportunities and novel challenges associated with, synthetic data.},
  keywords = {05,deep neural networks,domain adaptation,generative adversarial networks,graphics-rendering pipelines,next-generation learning,synthetic data}
}

@article{demelo2022NextgenerationDeepLearning,
  title = {Next-Generation Deep Learning Based on Simulators and Synthetic Data},
  author = {de Melo, Celso M. and Torralba, Antonio and Guibas, Leonidas and DiCarlo, James and Chellappa, Rama and Hodgins, Jessica},
  options = {useprefix=true},
  date = {2022-02-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {26},
  number = {2},
  pages = {174--187},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2021.11.008},
  url = {https://www.sciencedirect.com/science/article/pii/S136466132100293X},
  abstract = {Deep learning (DL) is being successfully applied across multiple domains, yet these models learn in a most artificial way: they require large quantities of labeled data to grasp even simple concepts. Thus, the main bottleneck is often access to supervised data. Here, we highlight a trend in a potential solution to this challenge: synthetic data. Synthetic data are becoming accessible due to progress in rendering pipelines, generative adversarial models, and fusion models. Moreover, advancements in domain adaptation techniques help close the statistical gap between synthetic and real data. Paradoxically, this artificial solution is also likely to enable more natural learning, as seen in biological systems, including continual, multimodal, and embodied learning. Complementary to this, simulators and deep neural networks (DNNs) will also have a critical role in providing insight into the cognitive and neural functioning of biological systems. We also review the strengths of, and opportunities and novel challenges associated with, synthetic data.},
  keywords = {deep neural networks,domain adaptation,generative adversarial networks,graphics-rendering pipelines,next-generation learning,synthetic data}
}

@article{deng2021TURLTableUnderstanding,
  title = {{{TURL}}: Table Understanding through Representation Learning},
  shorttitle = {{{TURL}}},
  author = {Deng, Xiang and Sun, Huan and Lees, Alyssa and Wu, You and Yu, Cong},
  date = {2021-12-09},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {14},
  number = {3},
  pages = {307--319},
  issn = {2150-8097},
  doi = {10.14778/3430915.3430921},
  url = {https://doi.org/10.14778/3430915.3430921},
  urldate = {2023-01-25},
  abstract = {Relational tables on the Web store a vast amount of knowledge. Owing to the wealth of such tables, there has been tremendous progress on a variety of tasks in the area of table understanding. However, existing work generally relies on heavily-engineered task-specific features and model architectures. In this paper, we present TURL, a novel framework that introduces the pre-training/fine-tuning paradigm to relational Web tables. During pre-training, our framework learns deep contextualized representations on relational tables in an unsupervised manner. Its universal model design with pre-trained representations can be applied to a wide range of tasks with minimal task-specific fine-tuning. Specifically, we propose a structure-aware Transformer encoder to model the row-column structure of relational tables, and present a new Masked Entity Recovery (MER) objective for pre-training to capture the semantics and knowledge in large-scale unlabeled data. We systematically evaluate TURL with a benchmark consisting of 6 different tasks for table understanding (e.g., relation extraction, cell filling). We show that TURL generalizes well to all tasks and substantially outperforms existing methods in almost all instances.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\SFWTJ9WU\\Deng et al_2020_TURL.pdf}
}

@inproceedings{devlin2019BERTPretrainingDeep,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}.},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{NAACL-HLT}} 2019, {{Minneapolis}}, {{MN}}, {{USA}}, {{June}} 2-7, 2019, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  date = {2019},
  pages = {4171--4186},
  doi = {10.18653/v1/n19-1423},
  url = {https://doi.org/10.18653/v1/n19-1423},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\DTXDWZJ2\\Devlin et al_2019_BERT.pdf}
}

@online{dhariwal2021DiffusionModelsBeat,
  title = {Diffusion {{Models Beat GANs}} on {{Image Synthesis}}},
  author = {Dhariwal, Prafulla and Nichol, Alex},
  date = {2021-06-01},
  number = {arXiv:2105.05233},
  eprint = {arXiv:2105.05233},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2105.05233},
  urldate = {2022-10-12},
  abstract = {We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128\$\textbackslash times\$128, 4.59 on ImageNet 256\$\textbackslash times\$256, and 7.72 on ImageNet 512\$\textbackslash times\$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256\$\textbackslash times\$256 and 3.85 on ImageNet 512\$\textbackslash times\$512. We release our code at https://github.com/openai/guided-diffusion},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\Z9PHPIMA\\Dhariwal_Nichol_2021_Diffusion Models Beat GANs on Image Synthesis.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\TK4H47LE\\2105.html}
}

@article{dicelis2016Estimating2008Quetame,
  title = {Estimating the 2008 {{Quetame}} ({{Colombia}}) Earthquake Source Parameters from Seismic Data and {{InSAR}} Measurements},
  author = {Dicelis, Gabriel and Assumpção, Marcelo and Kellogg, James and Pedraza, Patricia and Dias, Fábio},
  date = {2016-12-01},
  journaltitle = {Journal of South American Earth Sciences},
  shortjournal = {Journal of South American Earth Sciences},
  volume = {72},
  pages = {250--265},
  issn = {0895-9811},
  doi = {10.1016/j.jsames.2016.09.011},
  url = {https://www.sciencedirect.com/science/article/pii/S089598111630181X},
  abstract = {Seismic waveforms and geodetic measurements (InSAR) were used to determine the location, focal mechanism and coseismic surface displacements of the Mw 5.9 earthquake which struck the center of Colombia on May 24, 2008. We determined the focal mechanism of the main event using teleseismic P wave arrivals and regional waveform inversion for the moment tensor. We relocated the best set of aftershocks (30 events) with magnitudes larger than 2.0 recorded from May to June 2008 by a temporary local network as well as by stations of the Colombia national network. We successfully estimated coseismic deformation using SAR interferometry, despite distortion in some areas of the interferogram by atmospheric noise. The deformation was compared to synthetic data for rectangular dislocations in an elastic half-space. Nine source parameters (strike, dip, length, width, strike-slip deformation, dip-slip deformation, latitude shift, longitude shift, and minimum depth) were inverted to fit the observed changes in line-of-sight (LOS) toward the satellite four derived parameters were also estimated (rake, average slip, maximum depth and seismic moment). The aftershock relocation, the focal mechanism and the coseismic dislocation model agree with a right-lateral strike-slip fault with nodal planes oriented NE-SW and NW-SE. We use the results of the waveform inversion, radar interferometry and aftershock relocations to identify the high-angle NE-SW nodal plane as the primary fault. The inferred subsurface rupture length is roughly 11~km, which is consistent with the 12~km long distribution of aftershocks. This coseismic model can provide insights on earthquake mechanisms and seismic hazard assessments for the area, including the 8 million residents of Colombia's nearby capital city Bogota. The 2008 Quetame earthquake appears to be associated with the northeastward “escape” of the North Andean block, and it may help to illuminate how margin-parallel shear slip is partitioned in the Eastern Cordillera.},
  keywords = {Aftershocks,Earthquake,Geodesy,InSAR,Seismology,Surface deformation}
}

@online{dong2022GeneratingSyntheticData,
  title = {Generating {{Synthetic Data}} with {{Transformers}}: {{A Solution}} for {{Enterprise Data Challenges}}},
  shorttitle = {Generating {{Synthetic Data}} with {{Transformers}}},
  author = {Dong, Yi and Scoullos, Emanuel},
  date = {2022-05-09T16:00+00:00},
  url = {https://developer.nvidia.com/blog/generating-synthetic-data-with-transformers-a-solution-for-enterprise-data-challenges/},
  urldate = {2023-02-07},
  abstract = {Data privacy and availability remain an issue for enterprises. Delve into how synthetic tabular data generated by NeMo addresses these challenges.},
  langid = {american},
  organization = {{NVIDIA Technical Blog}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\9VXWNXJI\\generating-synthetic-data-with-transformers-a-solution-for-enterprise-data-challenges.html}
}

@incollection{dougherty1995SupervisedUnsupervisedDiscretization,
  title = {Supervised and {{Unsupervised Discretization}} of {{Continuous Features}}},
  booktitle = {Machine {{Learning Proceedings}} 1995},
  author = {Dougherty, James and Kohavi, Ron and Sahami, Mehran},
  editor = {Prieditis, Armand and Russell, Stuart},
  date = {1995-01-01},
  pages = {194--202},
  publisher = {{Morgan Kaufmann}},
  location = {{San Francisco (CA)}},
  doi = {10.1016/B978-1-55860-377-6.50032-3},
  url = {https://www.sciencedirect.com/science/article/pii/B9781558603776500323},
  urldate = {2023-02-07},
  abstract = {Many supervised machine learning algorithms require a discrete feature space. In this paper, we review previous work on continuous feature discretization, identify defining characteristics of the methods, and conduct an empirical evaluation of several methods. We compare binning, an unsupervised discretization method, to entropy-based and purity-based methods, which are supervised algorithms. We found that the performance of the Naive-Bayes algorithm significantly improved when features were discretized using an entropy-based method. In fact, over the 16 tested datasets, the discretized version of Naive-Bayes slightly outperformed C4.5 on average. We also show that in some cases, the performance of the C4.5 induction algorithm significantly improved if features were discretized in advance; in our experiments, the performance never significantly degraded, an interesting phenomenon considering the fact that C4.5 is capable of locally discretizing features.},
  isbn = {978-1-55860-377-6},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\95VHTF4Y\\Dougherty et al_1995_Supervised and Unsupervised Discretization of Continuous Features.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\DU8S75ZG\\B9781558603776500323.html}
}

@misc{Dua:2019,
  title = {{{UCI}} Machine Learning Repository},
  author = {Dua, Dheeru and Graff, Casey},
  date = {2017},
  publisher = {{University of California, Irvine, School of Information and Computer Sciences}},
  url = {http://archive.ics.uci.edu/ml}
}

@article{duval-poo2018SolarHardXray,
  title = {Solar Hard {{X-ray}} Imaging by Means of Compressed Sensing and Finite Isotropic Wavelet Transform},
  author = {Duval-Poo, M. A. and Piana, M. and Massone, A. M.},
  date = {2018-07},
  journaltitle = {Astronomy \& Astrophysics},
  shortjournal = {A\&A},
  volume = {615},
  pages = {A59},
  issn = {0004-6361, 1432-0746},
  doi = {10.1051/0004-6361/201731765},
  url = {https://www.aanda.org/10.1051/0004-6361/201731765},
  urldate = {2022-07-10},
  abstract = {Aims               . Compressed sensing realized by means of regularized deconvolution and the finite isotropic wavelet transform is effective and reliable in hard X-ray solar imaging.                                         Methods               . The method uses the finite isotropic wavelet transform with the Meyer function as the mother wavelet. Furthermore, compressed sensing is realized by optimizing a sparsity-promoting regularized objective function by means of the fast iterative shrinkage-thresholding algorithm. Eventually, the regularization parameter is selected by means of the Miller criterion.                                         Results               . The method is applied against both synthetic data mimicking measurements made with the Spectrometer/Telescope Imaging X-rays (STIX) and experimental observations provided by the Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI). The performances of the method are qualitatively validated by comparing some morphological properties of the reconstructed sources with those of the corresponding synthetic configurations. Furthermore, the results concerning experimental data are compared with those obtained by applying other visibility-based reconstruction methods.                                         Conclusions               . The results show that when the new method is applied to synthetic STIX visibility sets, it provides reconstructions with a spatial accuracy comparable to the accuracy provided by the most popular method in hard X-ray solar imaging and with a higher spatial resolution. Furthermore, when it is applied to experimental RHESSI data, the reconstructions are characterized by reliable photometry and by a notable reduction of the ringing effects caused by the instrument point spread function.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\2L7TGG4Y\\Duval-Poo et al_2018_Solar hard X-ray imaging by means of compressed sensing and finite isotropic.pdf}
}

@inproceedings{dwork2008DifferentialPrivacySurvey,
  title = {Differential {{Privacy}}: {{A Survey}} of {{Results}}},
  shorttitle = {Differential {{Privacy}}},
  booktitle = {Theory and {{Applications}} of {{Models}} of {{Computation}}},
  author = {Dwork, Cynthia},
  editor = {Agrawal, Manindra and Du, Dingzhu and Duan, Zhenhua and Li, Angsheng},
  date = {2008},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--19},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-79228-4_1},
  abstract = {Over the past five years a new approach to privacy-preserving data analysis has born fruit [13, 18, 7, 19, 5, 37, 35, 8, 32]. This approach differs from much (but not all!) of the related literature in the statistics, databases, theory, and cryptography communities, in that a formal and ad omnia privacy guarantee is defined, and the data analysis techniques presented are rigorously proved to satisfy the guarantee. The key privacy guarantee that has emerged is differential privacy. Roughly speaking, this ensures that (almost, and quantifiably) no risk is incurred by joining a statistical database.},
  isbn = {978-3-540-79228-4},
  langid = {english},
  keywords = {Differential Privacy,Privacy Mechanism,Statistical Database,Statistical Query,True Answer},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\NDJGV3GN\\Dwork_2008_Differential Privacy.pdf}
}

@incollection{dwork2011DifferentialPrivacy,
  title = {Differential {{Privacy}}},
  booktitle = {Encyclopedia of {{Cryptography}} and {{Security}}},
  author = {Dwork, Cynthia},
  editor = {van Tilborg, Henk C. A. and Jajodia, Sushil},
  options = {useprefix=true},
  date = {2011},
  pages = {338--340},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-1-4419-5906-5_752},
  url = {https://doi.org/10.1007/978-1-4419-5906-5_752},
  urldate = {2023-02-27},
  isbn = {978-1-4419-5906-5},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LHGN5LVM\\Dwork_2011_Differential Privacy.pdf}
}

@book{eid2010StatistikUndForschungsmethoden,
  title = {Statistik und Forschungsmethoden},
  author = {Eid, Michael and Gollwitzer, Mario and Schmitt, Manfred},
  date = {2010-11-04},
  publisher = {{Technische Universität Dortmund}},
  doi = {10.17877/DE290R-12739},
  url = {https://sfbs.tu-dortmund.de/handle/sfbs/1006},
  urldate = {2023-02-13},
  abstract = {Statistik und Forschungsmethoden zählen nicht zu den beliebtesten Fächern in der Psychologie, zu groß ist der Respekt vor ihnen. Jetzt liegt ein Lehrbuch vor, das Abhilfe schafft anschaulich und nachvollziehbar werden die statistischen Verfahren dargestellt. Dabei sind viele Formeln notwendig, Rechenschritte werden aber immer in einzelnen Schritten erläutert und durch Beispiele und konkrete Anwendungen ergänzt. So leuchtet dem Leser ein, wozu Statistik gut ist und wie sie funktioniert! Aus dem Inhalt Forschungsmethoden Messtheoretische und deskriptivstatistische Grundlagen Wahrscheinlichkeitstheorie und inferenzstatistische Grundlagen Methoden zum Vergleich von Gruppen Zusammenhangs- und Regressionsanalyse Modelle mit latenten Variablen Mit Online-Materialien: Kommentierte Links zu im Internet frei verfügbaren Computerprogrammen und Tabellen Lösungen der Übungsaufgaben Datensätze zum Selbst-Nachrechnen Häufig gestellte Fragen Neuigkeiten},
  editora = {Technische Universität Dortmund and Technische Universität Dortmund},
  editoratype = {collaborator},
  langid = {ngerman},
  keywords = {310,Statistik}
}

@article{elemam2020SevenWaysEvaluate,
  title = {Seven {{Ways}} to {{Evaluate}} the {{Utility}} of {{Synthetic Data}}},
  author = {El Emam, Khaled},
  date = {2020-07},
  journaltitle = {IEEE Security \& Privacy},
  shortjournal = {IEEE Secur. Privacy},
  volume = {18},
  number = {4},
  pages = {56--59},
  issn = {1540-7993, 1558-4046},
  doi = {10.1109/MSEC.2020.2992821},
  url = {https://ieeexplore.ieee.org/document/9138552/},
  urldate = {2022-06-23},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\MCD5JHSE\\El Emam - 2020 - Seven Ways to Evaluate the Utility of Synthetic Da.pdf}
}

@online{EmbeddingPyTorch13,
  title = {Embedding — {{PyTorch}} 1.13 Documentation},
  url = {https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html},
  urldate = {2023-03-10},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\XNRME22L\\torch.nn.Embedding.html}
}

@article{esmaeilpour2022BidiscriminatorGANTabular,
  title = {Bi-Discriminator {{GAN}} for Tabular Data Synthesis},
  author = {Esmaeilpour, Mohammad and Chaalia, Nourhene and Abusitta, Adel and Devailly, Franşois-Xavier and Maazoun, Wissem and Cardinal, Patrick},
  date = {2022-07},
  journaltitle = {Pattern Recognition Letters},
  shortjournal = {Pattern Recognition Letters},
  volume = {159},
  pages = {204--210},
  issn = {01678655},
  doi = {10.1016/j.patrec.2022.05.023},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865522001830},
  urldate = {2022-07-16},
  abstract = {This paper introduces a bi-discriminator GAN for synthesizing tabular datasets containing continuous, binary, and discrete columns. Our proposed approach employs an adapted preprocessing scheme and a novel conditional term using the χβ2 distribution for the generator network to more effectively capture the input sample distributions. Additionally, we implement straightforward yet effective architectures for discriminator networks aiming at providing more discriminative gradient information to the generator. Our experimental results on four benchmarking public datasets corroborates the superior performance of our GAN both in terms of likelihood fitness metric and machine learning efficacy.},
  langid = {english},
  keywords = {✔️,01,BCT-GAN,Bi-discriminator GAN,categorical data,Conditional generator,gan,Generative adversarial network (GAN),numeric data,tabular data,Tabular data synthesis,Variational Gaussian mixture model (VGM)},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\PV68XENG\\Esmaeilpour et al_2022_Bi-discriminator GAN for tabular data synthesis.pdf}
}

@misc{esteban2017RealvaluedMedicalTimea,
  title = {Real-Valued ({{Medical}}) {{Time Series Generation}} with {{Recurrent Conditional GANs}}},
  author = {Esteban, Cristóbal and Hyland, Stephanie L. and Rätsch, Gunnar},
  date = {2017-12-03},
  number = {arXiv:1706.02633},
  eprint = {1706.02633},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.02633},
  url = {http://arxiv.org/abs/1706.02633},
  urldate = {2022-07-10},
  abstract = {Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from 'serialised' MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data.},
  keywords = {01,Computer Science - Machine Learning,conditional GAN,gans,RCGAN,RGAN,RNN,Statistics - Machine Learning,time series data,TSTR},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\H7AVCI5Z\\Esteban et al_2017_Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\WAY9M4MK\\1706.html}
}

@misc{european_commission_regulation_2016,
  title = {Regulation ({{EU}}) 2016/679 of the {{European Parliament}} and of the {{Council}} of 27 {{April}} 2016 on the Protection of Natural Persons with Regard to the Processing of Personal Data and on the Free Movement of Such Data, and Repealing {{Directive}} 95/46/{{EC}} ({{General Data Protection Regulation}}) ({{Text}} with {{EEA}} Relevance)},
  author = {{European Commission}},
  date = {2016},
  publisher = {{European Commission}},
  url = {https://eur-lex.europa.eu/eli/reg/2016/679/oj},
  abstract = {EU Datenschutzgrundverordnung (kurz: DS-GVO / auch: DSGVO) im Orginal mit allen Sprachversionen},
  added-at = {2020-08-20T11:33:21.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/243a2175512dc8b9d8855fa7a763cdc3e/zotero},
  interhash = {c7b667cac6031282160a9e94d5a118f8},
  intrahash = {43a2175512dc8b9d8855fa7a763cdc3e},
  keywords = {ddm en m1.3 openₐccess},
  timestamp = {2020-08-20T11:33:21.000+0200}
}

@misc{fan2020RelationalDataSynthesisa,
  title = {Relational {{Data Synthesis}} Using {{Generative Adversarial Networks}}: {{A Design Space Exploration}}},
  shorttitle = {Relational {{Data Synthesis}} Using {{Generative Adversarial Networks}}},
  author = {Fan, Ju and Liu, Tongyu and Li, Guoliang and Chen, Junyou and Shen, Yuwei and Du, Xiaoyong},
  date = {2020-08-28},
  number = {arXiv:2008.12763},
  eprint = {2008.12763},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2008.12763},
  url = {http://arxiv.org/abs/2008.12763},
  urldate = {2022-07-10},
  abstract = {The proliferation of big data has brought an urgent demand for privacy-preserving data publishing. Traditional solutions to this demand have limitations on effectively balancing the tradeoff between privacy and utility of the released data. Thus, the database community and machine learning community have recently studied a new problem of relational data synthesis using generative adversarial networks (GAN) and proposed various algorithms. However, these algorithms are not compared under the same framework and thus it is hard for practitioners to understand GAN's benefits and limitations. To bridge the gaps, we conduct so far the most comprehensive experimental study that investigates applying GAN to relational data synthesis. We introduce a unified GAN-based framework and define a space of design solutions for each component in the framework, including neural network architectures and training strategies. We conduct extensive experiments to explore the design space and compare with traditional data synthesis approaches. Through extensive experiments, we find that GAN is very promising for relational data synthesis, and provide guidance for selecting appropriate design solutions. We also point out limitations of GAN and identify future research directions.},
  keywords = {01,Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Machine Learning,gan},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\2J8NGKAG\\Fan et al_2020_Relational Data Synthesis using Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\TE6Y92K6\\2008.html}
}

@article{FAN2021111423,
  title = {Quantitative Assessments on Advanced Data Synthesis Strategies for Enhancing Imbalanced {{AHU}} Fault Diagnosis Performance},
  author = {Fan, Cheng and Li, Xueqing and Zhao, Yang and Wang, Jiayuan},
  date = {2021},
  journaltitle = {Energy and Buildings},
  volume = {252},
  pages = {111423},
  issn = {0378-7788},
  doi = {10.1016/j.enbuild.2021.111423},
  url = {https://www.sciencedirect.com/science/article/pii/S0378778821007076},
  abstract = {The accurate and reliable fault diagnosis of air handling units (AHUs) has profound impacts on building energy efficiency and indoor thermal comforts. Data-driven fault diagnosis methods have gained increasing popularity considering the wide availabilities of operational data and advances in data analytics. In practice, the data-driven fault diagnosis performance can be severely degraded by the imbalanced nature of building operational data, i.e., the data samples of faulty operations are much smaller than that of normal operations. This study serves as a comprehensive study to investigate the potential of different data synthesis techniques in enhancing the performance of imbalanced AHU fault diagnosis. A variety of data synthesis strategies, ranging from conventional random sampling-based to advanced variational autoencoder-based techniques, have been developed for synthetic data generation. Data experiments have been designed to quantitatively evaluate the value of data synthesis in data scenarios considering various data amounts and imbalanced ratios. The research results indicate that synthetic data can significantly enhance the performance of imbalanced AHU fault diagnosis by up to 8.94\%. Optimal data synthesis strategies have been identified in different data scenarios. The research outcomes are helpful for the development of reliable data-driven tools for practical tasks in building energy management.},
  keywords = {Air handling units,Data synthesis,Generative modeling,Imbalanced fault diagnosis,Variational auto-encoder}
}

@article{fang2022CryptocurrencyTradingComprehensive,
  title = {Cryptocurrency Trading: A Comprehensive Survey},
  shorttitle = {Cryptocurrency Trading},
  author = {Fang, Fan and Ventre, Carmine and Basios, Michail and Kanthan, Leslie and Martinez-Rego, David and Wu, Fan and Li, Lingbo},
  date = {2022-12},
  journaltitle = {Financial Innovation},
  shortjournal = {Financ Innov},
  volume = {8},
  number = {1},
  pages = {13},
  issn = {2199-4730},
  doi = {10.1186/s40854-021-00321-6},
  url = {https://jfin-swufe.springeropen.com/articles/10.1186/s40854-021-00321-6},
  urldate = {2022-07-18},
  abstract = {Abstract                            In recent years, the tendency of the number of financial institutions to include cryptocurrencies in their portfolios has accelerated. Cryptocurrencies are the first pure digital assets to be included by asset managers. Although they have some commonalities with more traditional assets, they have their own separate nature and their behaviour as an asset is still in the process of being understood. It is therefore important to summarise existing research papers and results on cryptocurrency trading, including available trading platforms, trading signals, trading strategy research and risk management. This paper provides a comprehensive survey of cryptocurrency trading research, by covering 146 research papers on various aspects of cryptocurrency trading (               e               .               g               ., cryptocurrency trading systems, bubble and extreme condition, prediction of volatility and return, crypto-assets portfolio construction and crypto-assets, technical trading and others). This paper also analyses datasets, research trends and distribution among research objects (contents/properties) and technologies, concluding with some promising opportunities that remain open in cryptocurrency trading.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ZNK5UKXH\\Fang et al_2022_Cryptocurrency trading.pdf}
}

@article{fang2022CryptocurrencyTradingComprehensivea,
  title = {Cryptocurrency Trading: A Comprehensive Survey},
  shorttitle = {Cryptocurrency Trading},
  author = {Fang, F. and Ventre, C. and Basios, M. and Kanthan, L. and Martinez-Rego, D. and Wu, F. and Li, L.},
  date = {2022},
  journaltitle = {Financial Innovation},
  volume = {8},
  number = {1},
  issn = {2199-4730},
  doi = {10.1186/s40854-021-00321-6},
  abstract = {In recent years, the tendency of the number of financial institutions to include cryptocurrencies in their portfolios has accelerated. Cryptocurrencies are the first pure digital assets to be included by asset managers. Although they have some commonalities with more traditional assets, they have their own separate nature and their behaviour as an asset is still in the process of being understood. It is therefore important to summarise existing research papers and results on cryptocurrency trading, including available trading platforms, trading signals, trading strategy research and risk management. This paper provides a comprehensive survey of cryptocurrency trading research, by covering 146 research papers on various aspects of cryptocurrency trading (e.g., cryptocurrency trading systems, bubble and extreme condition, prediction of volatility and return, crypto-assets portfolio construction and crypto-assets, technical trading and others). This paper also analyses datasets, research trends and distribution among research objects (contents/properties) and technologies, concluding with some promising opportunities that remain open in cryptocurrency trading. © 2022, The Author(s).},
  langid = {english},
  keywords = {Cryptocurrency,Econometrics,Machine learning,Trading},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\IWG75KKE\\Fang et al_2022_Cryptocurrency trading.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\MK972YB7\\display.html}
}

@article{fangOvercomingChallengesSynthetic,
  title = {Overcoming {{Challenges}} of {{Synthetic Data Generation}}},
  author = {Fang, Kevin and Mugunthan, Vaikkunth and Ramkumar, Vayd},
  abstract = {There are several shortcomings in current methods of generating synthetic data using Generative Adversarial Networks (GANs). First, they tend to only emulate certain attributes of the original dataset. Second, they do not effectively model unbalanced discrete columns, long tails, or bimodal distributions of continuous columns. Lastly, these approaches often do not consider the potential for information leakage from the generated data. We propose UniformGAN, a GAN with a novel uniform loss function, which addresses these challenges and provides strong privacy guarantees using differential privacy. UniformGAN preprocesses datasets to transpose each column into a uniform distribution. We use a modified D eep C onvolutional Generative Adversarial Network (DCGAN) architecture in which we replace ReLU activation functions with the more robust SeLU, which has significantly b etter p erformance a nd b etter c onvergence properties, and apply Dense-Sparse-Dense training to our network. We also use differential privacy to add noise to the discriminator during training. Along with UniformGAN, we provide a configurable command-line tool to generate and evaluate synthetic datasets on numerous metrics. It allows users to generate synthetic datasets from CTGAN, TableGAN, UniformGAN, or a custom framework and analyze the resultant datasets. This tool will help data scientists and industry users compare different synthetic dataset generation models and enable them to improve existing methods. We evaluated UniformGAN using multiple datasets, including the Adult, Covertype, and Credit Kaggle datasets, as well as two insurance-related Kaggle datasets. The results show that, when used on datatsets containing a large number of continuous columns, UniformGAN out performs other methods by producing synthetic data with similar correlations and distributions as the original dataset while ensuring privacy.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\58NWFL2N\\Fang et al. - Overcoming Challenges of Synthetic Data Generation.pdf}
}

@inproceedings{fitkov-norris2012EvaluatingImpactCategorical,
  title = {Evaluating the {{Impact}} of {{Categorical Data Encoding}} and {{Scaling}} on {{Neural Network Classification Performance}}: {{The Case}} of {{Repeat Consumption}} of {{Identical Cultural Goods}}},
  shorttitle = {Evaluating the {{Impact}} of {{Categorical Data Encoding}} and {{Scaling}} on {{Neural Network Classification Performance}}},
  booktitle = {Engineering {{Applications}} of {{Neural Networks}}},
  author = {Fitkov-Norris, Elena and Vahid, Samireh and Hand, Chris},
  editor = {Jayne, Chrisina and Yue, Shigang and Iliadis, Lazaros},
  date = {2012},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {343--352},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-32909-8_35},
  abstract = {This article investigated the impact of categorical input encoding and scaling approaches on neural network sensitivity and overall classification performance in the context of predicting the repeat viewing propensity of movie goers. The results show that neural network out of sample minimum sensitivity and overall classification performance are indifferent to the scaling of the categorical inputs. However, the encoding of inputs had a significant impact on classification accuracy and utilising ordinal or thermometer encoding approaches for categorical inputs significantly increases the out of sample accuracy of the neural network classifier. These findings confirm that the impact of categorical encoding is problem specific for an ordinal approach, and support thermometer encoding as most suitable for categorical inputs. The classification performance of neural networks was compared against a logistic regression model and the results show that in this instance, the non-parametric approach does not offer any advantage over standard statistical models.},
  isbn = {978-3-642-32909-8},
  langid = {english},
  keywords = {categorical input,encoding,logistic regression,neural networks,scaling},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\RBKNYA9N\\Fitkov-Norris et al_2012_Evaluating the Impact of Categorical Data Encoding and Scaling on Neural.pdf}
}

@article{fredette2019WillowsEnvironmentalProjects,
  title = {Willows for Environmental Projects: {{A}} Literature Review of Results on Evapotranspiration Rate and Its Driving Factors across the Genus {{Salix}}},
  author = {Frédette, Chloé and Labrecque, Michel and Comeau, Yves and Brisson, Jacques},
  date = {2019-09-15},
  journaltitle = {Journal of Environmental Management},
  shortjournal = {Journal of Environmental Management},
  volume = {246},
  pages = {526--537},
  issn = {0301-4797},
  doi = {10.1016/j.jenvman.2019.06.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0301479719308011},
  abstract = {Willows are increasingly used for a wide range of environmental projects, including biomass production, leachate treatment, riparian buffers and treatment wetlands. Evapotranspiration (ET), assumed to be high for most willow species used in environmental projects, affects hydrological cycles and is of key interest for project managers working with willows. Here, we present a comprehensive review of ET rates provided in the literature for the genus Salix. We aim to summarize current knowledge of willow ET and analyze its variability depending on context. We compiled and analyzed data from 57 studies, covering 16 countries, 19 willow species and dozens of cultivars. We found a mean reported ET rate of 4.6\,±\,4.2\,mm/d, with minimum and maximum values of 0.7 and 22.7\,mm/d respectively. Although results reported here varied significantly between some species, overall interspecific standard deviation (±3.6\,mm/d) was similar to intraspecific variation (±3.3\,mm/d) calculated for S. viminalis, suggesting a greater influence of the growing context on ET than species identity. In terms of environmental and management variables, water supply, fertilization and contamination were identified as driving factors of ET across willow species. Effects of root age, experimental context, planting density and soil type were more nuanced. Our findings provide synthetic data regarding willow ET. We encourage practitioners who use ET data from the literature to be aware of the main drivers of ET and to consider the influence of the experimental aspects of a study in order to interpret data accurately and improve project planning.},
  keywords = {Evapotranspiration variability,Irrigation planning,Water loss,Water use,Wetland design,Willow coppicing}
}

@online{frogner2015LearningWassersteinLoss,
  title = {Learning with a {{Wasserstein Loss}}},
  author = {Frogner, Charlie and Zhang, Chiyuan and Mobahi, Hossein and Araya-Polo, Mauricio and Poggio, Tomaso},
  date = {2015-12-29},
  number = {arXiv:1506.05439},
  eprint = {arXiv:1506.05439},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1506.05439},
  urldate = {2023-01-09},
  abstract = {Learning to predict multi-label outputs is challenging, but in many problems there is a natural metric on the outputs that can be used to improve predictions. In this paper we develop a loss function for multi-label learning, based on the Wasserstein distance. The Wasserstein distance provides a natural notion of dissimilarity for probability measures. Although optimizing with respect to the exact Wasserstein distance is costly, recent work has described a regularized approximation that is efficiently computed. We describe an efficient learning algorithm based on this regularization, as well as a novel extension of the Wasserstein distance from probability measures to unnormalized measures. We also describe a statistical learning bound for the loss. The Wasserstein loss can encourage smoothness of the predictions with respect to a chosen metric on the output space. We demonstrate this property on a real-data tag prediction problem, using the Yahoo Flickr Creative Commons dataset, outperforming a baseline that doesn't use the metric.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\AMQGBHAZ\\Frogner et al. - 2015 - Learning with a Wasserstein Loss.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\H86RRFVY\\1506.html}
}

@book{gamma1994design,
  title = {Design Patterns: {{Elements}} of Reusable Object-Oriented Software},
  author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John M.},
  date = {1994},
  edition = {1},
  publisher = {{Addison-Wesley Professional}},
  url = {http://www.amazon.com/Design-Patterns-Elements-Reusable-Object-Oriented/dp/0201633612/ref=ntt_at_ep_dpi_1},
  added-at = {2010-06-05T16:40:25.000+0200},
  asin = {0201633612},
  biburl = {https://www.bibsonomy.org/bibtex/27e3f1154ab1fbce54752a46dba7f2217/pnk},
  description = {Amazon.com: Design Patterns: Elements of Reusable Object-Oriented Software (9780201633610): Erich Gamma, Richard Helm, Ralph Johnson, John M. Vlissides: Books},
  dewey = {005.12},
  ean = {9780201633610},
  interhash = {7fe32957be97afaf4ecb38b5490d23b4},
  intrahash = {7e3f1154ab1fbce54752a46dba7f2217},
  isbn = {0-201-63361-2},
  keywords = {DBIS Design Object-Oriented Patterns SS2010 Seminar Software},
  timestamp = {2010-06-05T16:40:25.000+0200},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\9BH6XE3S\\articulo.pdf}
}

@misc{garcia-jara2022ImprovingAstronomicalTimeseriesa,
  title = {Improving {{Astronomical Time-series Classification}} via {{Data Augmentation}} with {{Generative Adversarial Networks}}},
  author = {García-Jara, Germán and Protopapas, Pavlos and Estévez, Pablo A.},
  date = {2022-05-13},
  number = {arXiv:2205.06758},
  eprint = {2205.06758},
  eprinttype = {arxiv},
  eprintclass = {astro-ph},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.06758},
  url = {http://arxiv.org/abs/2205.06758},
  urldate = {2022-07-10},
  abstract = {Due to the latest advances in technology, telescopes with significant sky coverage will produce millions of astronomical alerts per night that must be classified both rapidly and automatically. Currently, classification consists of supervised machine learning algorithms whose performance is limited by the number of existing annotations of astronomical objects and their highly imbalanced class distributions. In this work, we propose a data augmentation methodology based on Generative Adversarial Networks (GANs) to generate a variety of synthetic light curves from variable stars. Our novel contributions, consisting of a resampling technique and an evaluation metric, can assess the quality of generative models in unbalanced datasets and identify GAN-overfitting cases that the Fr\textbackslash 'echet Inception Distance does not reveal. We applied our proposed model to two datasets taken from the Catalina and Zwicky Transient Facility surveys. The classification accuracy of variable stars is improved significantly when training with synthetic data and testing with real data with respect to the case of using only real data.},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Machine Learning,J.2.3},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\4JLPGQKL\\García-Jara et al_2022_Improving Astronomical Time-series Classification via Data Augmentation with.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\KHI3WPXU\\2205.html}
}

@article{garcia2016BigDataPreprocessing,
  title = {Big Data Preprocessing: Methods and Prospects},
  shorttitle = {Big Data Preprocessing},
  author = {García, Salvador and Ramírez-Gallego, Sergio and Luengo, Julián and Benítez, José Manuel and Herrera, Francisco},
  date = {2016-11-01},
  journaltitle = {Big Data Analytics},
  shortjournal = {Big Data Analytics},
  volume = {1},
  number = {1},
  pages = {9},
  issn = {2058-6345},
  doi = {10.1186/s41044-016-0014-0},
  url = {https://doi.org/10.1186/s41044-016-0014-0},
  urldate = {2023-02-03},
  abstract = {The massive growth in the scale of data has been observed in recent years being a key factor of the Big Data scenario. Big Data can be defined as high volume, velocity and variety of data that require a new high-performance processing. Addressing big data is a challenging and time-demanding task that requires a large computational infrastructure to ensure successful data processing and analysis. The presence of data preprocessing methods for data mining in big data is reviewed in this paper. The definition, characteristics, and categorization of data preprocessing approaches in big data are introduced. The connection between big data and data preprocessing throughout all families of methods and big data technologies are also examined, including a review of the state-of-the-art. In addition, research challenges are discussed, with focus on developments on different big data framework, such as Hadoop, Spark and Flink and the encouragement in devoting substantial research efforts in some families of data preprocessing methods and applications on new big data learning paradigms.},
  keywords = {Big data,Data mining,Data preprocessing,Data transformation,Feature selection,Hadoop,Imperfect data,Instance reduction,Spark},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JBQLBTUH\\García et al_2016_Big data preprocessing.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\PYGTFUS3\\s41044-016-0014-0.html}
}

@article{ge2021KaminoConstraintawareDifferentially,
  title = {Kamino: Constraint-Aware Differentially Private Data Synthesis},
  shorttitle = {Kamino},
  author = {Ge, Chang and Mohapatra, Shubhankar and He, Xi and Ilyas, Ihab F.},
  date = {2021-06},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {14},
  number = {10},
  pages = {1886--1899},
  issn = {2150-8097},
  doi = {10.14778/3467861.3467876},
  url = {https://dl.acm.org/doi/10.14778/3467861.3467876},
  urldate = {2022-06-30},
  abstract = {Organizations are increasingly relying on data to support decisions. When data contains private and sensitive information, the data owner often desires to publish a synthetic database instance that is similarly useful as the true data, while ensuring the privacy of individual data records. Existing differentially private data synthesis methods aim to generate useful data based on applications, but they fail in keeping one of the most fundamental data properties of the structured data — the underlying correlations and dependencies among tuples and attributes (i.e., the structure of the data). This structure is often expressed as integrity and schema constraints, or with a probabilistic generative process. As a result, the synthesized data is not useful for any downstream tasks that require this structure to be preserved. This work presents Kamino, a data synthesis system to ensure differential privacy and to preserve the structure and correlations present in the original dataset. Kamino takes as input of a database instance, along with its schema (including integrity constraints), and produces a synthetic database instance with differential privacy and structure preservation guarantees. We empirically show that while preserving the structure of the data, Kamino achieves comparable and even better usefulness in applications of training classification models and answering marginal queries than the state-of-the-art methods of differentially private data synthesis.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\YJXRVBVX\\Ge et al_2021_Kamino.pdf}
}

@article{gelman1992InferenceIterativeSimulation,
  title = {Inference from {{Iterative Simulation Using Multiple Sequences}}},
  author = {Gelman, Andrew and Rubin, Donald B.},
  date = {1992-11},
  journaltitle = {Statistical Science},
  volume = {7},
  number = {4},
  pages = {457--472},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177011136},
  url = {https://projecteuclid.org/journals/statistical-science/volume-7/issue-4/Inference-from-Iterative-Simulation-Using-Multiple-Sequences/10.1214/ss/1177011136.full},
  urldate = {2023-02-10},
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  keywords = {Bayesian inference,Convergence of stochastic processes,ECM,EM,Gibbs sampler,importance sampling,Metropolis algorithm,multiple imputation,random-effects model,SIR},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\HTD2K28B\\Gelman_Rubin_1992_Inference from Iterative Simulation Using Multiple Sequences.pdf}
}

@online{Gen1Runway,
  title = {Gen-1 by {{Runway}}},
  url = {https://research.runwayml.com/gen1},
  urldate = {2023-02-13},
  abstract = {The Next Step Forward for Generative AI},
  langid = {american},
  organization = {{Runway}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\A3K96TAX\\gen1.html}
}

@report{georges-filteau2020SyntheticObservationalHealth,
  type = {preprint},
  title = {Synthetic {{Observational Health Data}} with {{GANs}}: From Slow Adoption to a Boom in Medical Research and Ultimately Digital Twins?},
  shorttitle = {Synthetic {{Observational Health Data}} with {{GANs}}},
  author = {Georges-Filteau, Jeremy and Cirillo, Elisa},
  date = {2020-11-16},
  institution = {{Preprints}},
  doi = {10.22541/au.158921777.79483839/v2},
  url = {https://www.authorea.com/users/299755/articles/429273-synthetic-observational-health-data-with-gans-from-slow-adoption-to-a-boom-in-medical-research-and-ultimately-digital-twins?commit=4fd87839648573f4929662434c34cd0c2c6b0460},
  urldate = {2022-07-10},
  abstract = {After being collected for patient care, Observational Health Data (OHD) can further benefit patient well-being by sustaining the development of health informatics and medical research. Vast potential is unexploited because of the fiercely private nature of patient-related data and regulation about its distribution. Generative Adversarial Networks (GANs) have recently emerged as a groundbreaking approach to learn generative models efficiently that produce realistic Synthetic Data (SD). They have revolutionized practices in multiple domains such as self-driving cars, fraud detection, simulations in the and marketing industrial sectors known as digital twins, and medical imaging. The digital twin concept could readily apply to modelling and quantifying disease progression. In addition, GANs posses a multitude of capabilities relevant to common problems in the healthcare: augmenting small dataset, correcting class imbalance, domain translation for rare diseases, let alone preserving privacy. Unlocking open access to privacy-preserving OHD could be transformative for scientific research. In the COVID-19’s midst, the healthcare system is facing unprecedented challenges, many of which of are data related and could be alleviated by the capabilities of GANs. Considering these facts, publications concerning the development of GAN applied to OHD seemed to be severely lacking. To uncover the reasons for the slow adoption ofGANs for OHD, we broadly reviewed the published literature on the subject. Our findings show that the properties of OHD and eval-uating the SD were initially challenging for the existing GAN algorithms (unlike medical imaging, for which state-of-the-art model were directly transferable) and the choice of metrics ambiguous. We find many publications on the subject, starting slowly in 2017and since then being published at an increasing rate. The difficulties of OHD remain, and we discuss issues relating to evaluation,consistency, benchmarking, data modeling, and reproducibility.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\BNI3TQ44\\Georges-Filteau_Cirillo_2020_Synthetic Observational Health Data with GANs.pdf}
}

@misc{ger2020AutoencodersGenerativeAdversariala,
  title = {Autoencoders and {{Generative Adversarial Networks}} for {{Imbalanced Sequence Classification}}},
  author = {Ger, Stephanie and Klabjan, Diego},
  date = {2020-08-19},
  number = {arXiv:1901.02514},
  eprint = {1901.02514},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1901.02514},
  url = {http://arxiv.org/abs/1901.02514},
  urldate = {2022-07-10},
  abstract = {Generative Adversarial Networks (GANs) have been used in many different applications to generate realistic synthetic data. We introduce a novel GAN with Autoencoder (GAN-AE) architecture to generate synthetic samples for variable length, multi-feature sequence datasets. In this model, we develop a GAN architecture with an additional autoencoder component, where recurrent neural networks (RNNs) are used for each component of the model in order to generate synthetic data to improve classification accuracy for a highly imbalanced medical device dataset. In addition to the medical device dataset, we also evaluate the GAN-AE performance on two additional datasets and demonstrate the application of GAN-AE to a sequence-to-sequence task where both synthetic sequence inputs and sequence outputs must be generated. To evaluate the quality of the synthetic data, we train encoder-decoder models both with and without the synthetic data and compare the classification model performance. We show that a model trained with GAN-AE generated synthetic data outperforms models trained with synthetic data generated both with standard oversampling techniques such as SMOTE and Autoencoders as well as with state of the art GAN-based models.},
  keywords = {✔️,01,Autoencoder,Computer Science - Machine Learning,gan,GAN-AE,RNN,seq2seq,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\UAXPXRRU\\Ger_Klabjan_2020_Autoencoders and Generative Adversarial Networks for Imbalanced Sequence.pdf}
}

@inproceedings{gilad2021SynthesizingLinkedData,
  title = {Synthesizing {{Linked Data Under Cardinality}} and {{Integrity Constraints}}},
  booktitle = {Proceedings of the 2021 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Gilad, Amir and Patwa, Shweta and Machanavajjhala, Ashwin},
  date = {2021-06-09},
  pages = {619--631},
  publisher = {{ACM}},
  location = {{Virtual Event China}},
  doi = {10.1145/3448016.3457242},
  url = {https://dl.acm.org/doi/10.1145/3448016.3457242},
  urldate = {2023-01-07},
  eventtitle = {{{SIGMOD}}/{{PODS}} '21: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-8343-1},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\CE6S4PZZ\\Gilad et al_2021_Synthesizing Linked Data Under Cardinality and Integrity Constraints.pdf}
}

@inproceedings{gillioz2020OverviewTransformerbasedModels,
  title = {Overview of the {{Transformer-based Models}} for {{NLP Tasks}}},
  booktitle = {2020 15th {{Conference}} on {{Computer Science}} and {{Information Systems}} ({{FedCSIS}})},
  author = {Gillioz, Anthony and Casas, Jacky and Mugellini, Elena and Khaled, Omar Abou},
  date = {2020-09},
  pages = {179--183},
  doi = {10.15439/2020F20},
  abstract = {In 2017, Vaswani et al. proposed a new neural network architecture named Transformer. That modern architecture quickly revolutionized the natural language processing world. Models like GPT and BERT relying on this Transformer architecture have fully outperformed the previous state-of-theart networks. It surpassed the earlier approaches by such a wide margin that all the recent cutting edge models seem to rely on these Transformer-based architectures. In this paper, we provide an overview and explanations of the latest models. We cover the auto-regressive models such as GPT, GPT-2 and XLNET, as well as the auto-encoder architecture such as BERT and a lot of post-BERT models like RoBERTa, ALBERT, ERNIE 1.0/2.0.},
  eventtitle = {2020 15th {{Conference}} on {{Computer Science}} and {{Information Systems}} ({{FedCSIS}})},
  keywords = {Bit error rate,Computer architecture,Computer science,Natural language processing,Neural networks,Task analysis,Transformers},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ZDSWU9ET\\Gillioz et al_2020_Overview of the Transformer-based Models for NLP Tasks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\NHZRL6BH\\9222960.html}
}

@article{goncalves2020GenerationEvaluationSynthetic,
  title = {Generation and Evaluation of Synthetic Patient Data},
  author = {Goncalves, Andre and Ray, Priyadip and Soper, Braden and Stevens, Jennifer and Coyle, Linda and Sales, Ana Paula},
  date = {2020-12},
  journaltitle = {BMC Medical Research Methodology},
  shortjournal = {BMC Med Res Methodol},
  volume = {20},
  number = {1},
  pages = {108},
  issn = {1471-2288},
  doi = {10.1186/s12874-020-00977-1},
  url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-00977-1},
  urldate = {2022-06-23},
  abstract = {Background: Machine learning (ML) has made a significant impact in medicine and cancer research; however, its impact in these areas has been undeniably slower and more limited than in other application domains. A major reason for this has been the lack of availability of patient data to the broader ML research community, in large part due to patient privacy protection concerns. High-quality, realistic, synthetic datasets can be leveraged to accelerate methodological developments in medicine. By and large, medical data is high dimensional and often categorical. These characteristics pose multiple modeling challenges. Methods: In this paper, we evaluate three classes of synthetic data generation approaches; probabilistic models, classification-based imputation models, and generative adversarial neural networks. Metrics for evaluating the quality of the generated synthetic datasets are presented and discussed. Results: While the results and discussions are broadly applicable to medical data, for demonstration purposes we generate synthetic datasets for cancer based on the publicly available cancer registry data from the Surveillance Epidemiology and End Results (SEER) program. Specifically, our cohort consists of breast, respiratory, and non-solid cancer cases diagnosed between 2010 and 2015, which includes over 360,000 individual cases. Conclusions: We discuss the trade-offs of the different methods and metrics, providing guidance on considerations for the generation and usage of medical synthetic data.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\L9G95CPM\\Goncalves et al. - 2020 - Generation and evaluation of synthetic patient dat.pdf}
}

@article{gong2022SSASTSelfSupervisedAudio,
  title = {{{SSAST}}: {{Self-Supervised Audio Spectrogram Transformer}}},
  shorttitle = {{{SSAST}}},
  author = {Gong, Yuan and Lai, Cheng-I. and Chung, Yu-An and Glass, James},
  date = {2022-06-28},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {10},
  pages = {10699--10709},
  issn = {2374-3468},
  doi = {10.1609/aaai.v36i10.21315},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/21315},
  urldate = {2023-02-20},
  abstract = {Recently, neural networks based purely on self-attention, such as the Vision Transformer (ViT), have been shown to outperform deep learning models constructed with convolutional neural networks (CNNs) on various vision tasks, thus extending the success of Transformers, which were originally developed for language processing, to the vision domain. A recent study showed that a similar methodology can also be applied to the audio domain. Specifically, the Audio Spectrogram Transformer (AST) achieves state-of-the-art results on various audio classification benchmarks. However, pure Transformer models tend to require more training data compared to CNNs, and the success of the AST relies on supervised pretraining that requires a large amount of labeled data and a complex training pipeline, thus limiting the practical usage of AST. This paper focuses on audio and speech classification, and aims to reduce the need for large amounts of labeled data for the AST by leveraging self-supervised learning using unlabeled data. Specifically, we propose to pretrain the AST model with joint discriminative and generative masked spectrogram patch modeling (MSPM) using unlabeled audio from AudioSet and Librispeech. We evaluate our pretrained models on both audio and speech classification tasks including audio event classification, keyword spotting, emotion recognition, and speaker identification. The proposed self-supervised framework significantly boosts AST performance on all tasks, with an average improvement of 60.9\%, leading to similar or even better results than a supervised pretrained AST. To the best of our knowledge, it is the first patch-based self-supervised learning framework in the audio and speech domain, and also the first self-supervised learning framework for AST.},
  issue = {10},
  langid = {english},
  keywords = {Speech & Natural Language Processing (SNLP)},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\5B2M2JE2\\Gong et al_2022_SSAST.pdf}
}

@book{Goodfellow-et-al-2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{MIT Press}},
  isbn = {978-0-262-03561-3}
}

@online{goodfellow2014GenerativeAdversarialNetworks,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014-06-10},
  number = {arXiv:1406.2661},
  eprint = {arXiv:1406.2661},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1406.2661},
  urldate = {2023-02-19},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\MU2T2L2J\\Goodfellow et al_2014_Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\2A9I2H3U\\1406.html}
}

@article{goodfellow2020GenerativeAdversarialNetworks,
  title = {Generative Adversarial Networks},
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2020-10-22},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {63},
  number = {11},
  pages = {139--144},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3422622},
  url = {https://dl.acm.org/doi/10.1145/3422622},
  urldate = {2023-01-09},
  abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the               generative modeling               problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\I5YRVXQC\\Goodfellow et al_2020_Generative adversarial networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\YD7C5QFE\\Goodfellow et al. - Generative Adversarial Nets.pdf}
}

@inproceedings{gorishniy2021RevisitingDeepLearning,
  title = {Revisiting {{Deep Learning Models}} for {{Tabular Data}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Gorishniy, Yury and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  date = {2021},
  volume = {34},
  pages = {18932--18943},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2021/hash/9d86d83f925f2149e9edb0ac3b49229c-Abstract.html},
  urldate = {2023-02-09},
  abstract = {The existing literature on deep learning for tabular data proposes a wide range of novel architectures and reports competitive results on various datasets. However, the proposed models are usually not properly compared to each other and existing works often use different benchmarks and experiment protocols. As a result, it is unclear for both researchers and practitioners what models perform best. Additionally, the field still lacks effective baselines, that is, the easy-to-use models that provide competitive performance across different problems.In this work, we perform an overview of the main families of DL architectures for tabular data and raise the bar of baselines in tabular DL by identifying two simple and powerful deep architectures. The first one is a ResNet-like architecture which turns out to be a strong baseline that is often missing in prior works. The second model is our simple adaptation of the Transformer architecture for tabular data, which outperforms other solutions on most tasks. Both models are compared to many existing architectures on a diverse set of tasks under the same training and tuning protocols. We also compare the best DL models with Gradient Boosted Decision Trees and conclude that there is still no universally superior solution. The source code is available at https://github.com/yandex-research/rtdl.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\2AX4BEST\\Gorishniy et al. - 2021 - Revisiting Deep Learning Models for Tabular Data.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\ZR29R8DE\\Gorishniy et al_2021_Revisiting Deep Learning Models for Tabular Data.pdf}
}

@online{gorishniy2022EmbeddingsNumericalFeatures,
  title = {On {{Embeddings}} for {{Numerical Features}} in {{Tabular Deep Learning}}},
  author = {Gorishniy, Yury and Rubachev, Ivan and Babenko, Artem},
  date = {2022-03-15},
  number = {arXiv:2203.05556},
  eprint = {arXiv:2203.05556},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2203.05556},
  urldate = {2023-01-30},
  abstract = {Recently, Transformer-like deep architectures have shown strong performance on tabular data problems. Unlike traditional models, e.g., MLP, these architectures map scalar values of numerical features to high-dimensional embeddings before mixing them in the main backbone. In this work, we argue that embeddings for numerical features are an underexplored degree of freedom in tabular DL, which allows constructing more powerful DL models and competing with GBDT on some traditionally GBDT-friendly benchmarks. We start by describing two conceptually different approaches to building embedding modules: the first one is based on a piecewise linear encoding of scalar values, and the second one utilizes periodic activations. Then, we empirically demonstrate that these two approaches can lead to significant performance boosts compared to the embeddings based on conventional blocks such as linear layers and ReLU activations. Importantly, we also show that embedding numerical features is beneficial for many backbones, not only for Transformers. Specifically, after proper embeddings, simple MLP-like models can perform on par with the attention-based architectures. Overall, we highlight embeddings for numerical features as an important design aspect with good potential for further improvements in tabular DL.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JYATZBKV\\Gorishniy et al_2022_On Embeddings for Numerical Features in Tabular Deep Learning.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\3475GBST\\2203.html}
}

@software{gorishniy2023EmbeddingsNumericalFeatures,
  title = {On {{Embeddings}} for {{Numerical Features}} in {{Tabular Deep Learning}}},
  author = {Gorishniy, Yura},
  date = {2023-02-28T07:13:11Z},
  origdate = {2022-03-15T11:17:11Z},
  url = {https://github.com/Yura52/tabular-dl-num-embeddings/blob/88ffa9fe0f6bb0446464896937cef91fe944296d/bin/datasets.py},
  urldate = {2023-03-08},
  abstract = {The official implementation of the paper "On Embeddings for Numerical Features in Tabular Deep Learning"}
}

@inproceedings{gulrajani2017ImprovedTrainingWasserstein,
  title = {Improved {{Training}} of {{Wasserstein GANs}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2017/hash/892c3b1c6dccd52936e27cbd0ff683d6-Abstract.html},
  urldate = {2022-07-15},
  abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\B4EN9W7Y\\Gulrajani et al_2017_Improved Training of Wasserstein GANs.pdf}
}

@article{guo2022AttentionMechanismsComputer,
  title = {Attention Mechanisms in Computer Vision: {{A}} Survey},
  shorttitle = {Attention Mechanisms in Computer Vision},
  author = {Guo, Meng-Hao and Xu, Tian-Xing and Liu, Jiang-Jiang and Liu, Zheng-Ning and Jiang, Peng-Tao and Mu, Tai-Jiang and Zhang, Song-Hai and Martin, Ralph R. and Cheng, Ming-Ming and Hu, Shi-Min},
  date = {2022-09},
  journaltitle = {Computational Visual Media},
  shortjournal = {Comp. Visual Media},
  volume = {8},
  number = {3},
  pages = {331--368},
  issn = {2096-0433, 2096-0662},
  doi = {10.1007/s41095-022-0271-y},
  url = {https://link.springer.com/10.1007/s41095-022-0271-y},
  urldate = {2023-02-15},
  abstract = {Abstract                            Humans can naturally and effectively find salient regions in complex scenes. Motivated by this observation, attention mechanisms were introduced into computer vision with the aim of imitating this aspect of the human visual system. Such an attention mechanism can be regarded as a dynamic weight adjustment process based on features of the input image. Attention mechanisms have achieved great success in many visual tasks, including image classification, object detection, semantic segmentation, video understanding, image generation, 3D vision, multimodal tasks, and self-supervised learning. In this survey, we provide a comprehensive review of various attention mechanisms in computer vision and categorize them according to approach, such as channel attention, spatial attention, temporal attention, and branch attention; a related repository               https://github.com/MenghaoGuo/Awesome-Vision-Attentions               is dedicated to collecting related work. We also suggest future directions for attention mechanism research.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\565VYG5Q\\Guo et al_2022_Attention mechanisms in computer vision.pdf}
}

@article{gutierrez-alcaraz2015RenewableEnergyResources,
  title = {Renewable Energy Resources Short-Term Scheduling and Dynamic Network Reconfiguration for Sustainable Energy Consumption},
  author = {Gutiérrez-Alcaraz, G. and Galván, E. and González-Cabrera, N. and Javadi, M.S.},
  date = {2015-12-01},
  journaltitle = {Renewable and Sustainable Energy Reviews},
  shortjournal = {Renewable and Sustainable Energy Reviews},
  volume = {52},
  pages = {256--264},
  issn = {1364-0321},
  doi = {10.1016/j.rser.2015.07.105},
  url = {https://www.sciencedirect.com/science/article/pii/S1364032115007522},
  abstract = {This paper proposes a two-phase approach for optimal short-term operational scheduling with intermittent renewable energy resources (RES) in an active distribution system. The first phase determines the amounts of purchased power from the market and the unit status of distributed generation (DG) and feeds the data into the second phase, a real-time scheduling coordination with hourly network reconfiguration. The two-phase proposed approach is applied to a case study of a sixteen-bus test system that uses synthetic data from renewable power generators and forecasts local user demands with a sampling time of five minutes.},
  keywords = {Distributed generation,Electricity market,Network reconfiguration,Renewable energy resources}
}

@misc{haas2020StatisticalAnalysisWassersteina,
  title = {Statistical Analysis of {{Wasserstein GANs}} with Applications to Time Series Forecasting},
  author = {Haas, Moritz and Richter, Stefan},
  date = {2020-11-05},
  number = {arXiv:2011.03074},
  eprint = {2011.03074},
  eprinttype = {arxiv},
  eprintclass = {math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2011.03074},
  url = {http://arxiv.org/abs/2011.03074},
  urldate = {2022-07-10},
  abstract = {We provide statistical theory for conditional and unconditional Wasserstein generative adversarial networks (WGANs) in the framework of dependent observations. We prove upper bounds for the excess Bayes risk of the WGAN estimators with respect to a modified Wasserstein-type distance. Furthermore, we formalize and derive statements on the weak convergence of the estimators and use them to develop confidence intervals for new observations. The theory is applied to the special case of high-dimensional time series forecasting. We analyze the behavior of the estimators in simulations based on synthetic data and investigate a real data example with temperature data. The dependency of the data is quantified with absolutely regular beta-mixing coefficients.},
  keywords = {62M45,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\53Q9VMBE\\Haas_Richter_2020_Statistical analysis of Wasserstein GANs with applications to time series.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\HJHPIPAG\\2011.html}
}

@article{hallAnalyzingPrepareFuture,
  title = {Analyzing the {{Past}} to {{Prepare}} for the {{Future}}: {{Writing}} a {{Literature Review}}},
  shorttitle = {Analyzing the {{Past}} to {{Prepare}} for the {{Future}}},
  author = {Hall, Jonathan},
  doi = {10.2307/4132319},
  url = {https://www.academia.edu/37761918/Analyzing_the_Past_to_Prepare_for_the_Future_Writing_a_Literature_Review},
  urldate = {2022-07-05},
  abstract = {Analyzing the Past to Prepare for the Future: Writing a Literature Review},
  issue = {Management Information Systems Quarterly},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\EFIRZLM7\\Webster und Watson - Guest Editorial  Analyzing the Past to Prepare fo.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\HGJETJTL\\Analyzing_the_Past_to_Prepare_for_the_Future_Writing_a_Literature_Review.html}
}

@article{haoues2017GuidelineSoftwareArchitecture,
  title = {A Guideline for Software Architecture Selection Based on {{ISO}} 25010 Quality Related Characteristics},
  author = {Haoues, Mariem and Sellami, Asma and Ben-Abdallah, Hanêne and Cheikhi, Laila},
  date = {2017-11},
  journaltitle = {International Journal of System Assurance Engineering and Management},
  shortjournal = {Int J Syst Assur Eng Manag},
  volume = {8},
  number = {S2},
  pages = {886--909},
  issn = {0975-6809, 0976-4348},
  doi = {10.1007/s13198-016-0546-8},
  url = {http://link.springer.com/10.1007/s13198-016-0546-8},
  urldate = {2023-03-06},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\8K6Z9BKE\\Haoues et al_2017_A guideline for software architecture selection based on ISO 25010 quality.pdf}
}

@article{harris2020array,
  title = {Array Programming with {{NumPy}}},
  author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del Río, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
  options = {useprefix=true},
  date = {2020-09},
  journaltitle = {Nature},
  volume = {585},
  number = {7825},
  pages = {357--362},
  publisher = {{Springer Science and Business Media LLC}},
  doi = {10.1038/s41586-020-2649-2},
  url = {https://doi.org/10.1038/s41586-020-2649-2}
}

@inproceedings{he2016DeepResidualLearning,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016-06},
  pages = {770--778},
  publisher = {{IEEE}},
  location = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR.2016.90},
  url = {http://ieeexplore.ieee.org/document/7780459/},
  urldate = {2023-02-15},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-8851-1},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LI3Z6MQJ\\He et al_2016_Deep Residual Learning for Image Recognition.pdf}
}

@article{hearst1998SupportVectorMachines,
  title = {Support Vector Machines},
  author = {Hearst, M.A. and Dumais, S.T. and Osuna, E. and Platt, J. and Scholkopf, B.},
  date = {1998-07},
  journaltitle = {IEEE Intelligent Systems and their Applications},
  volume = {13},
  number = {4},
  pages = {18--28},
  issn = {2374-9423},
  doi = {10.1109/5254.708428},
  abstract = {My first exposure to Support Vector Machines came this spring when heard Sue Dumais present impressive results on text categorization using this analysis technique. This issue's collection of essays should help familiarize our readers with this interesting new racehorse in the Machine Learning stable. Bernhard Scholkopf, in an introductory overview, points out that a particular advantage of SVMs over other learning algorithms is that it can be analyzed theoretically using concepts from computational learning theory, and at the same time can achieve good performance when applied to real problems. Examples of these real-world applications are provided by Sue Dumais, who describes the aforementioned text-categorization problem, yielding the best results to date on the Reuters collection, and Edgar Osuna, who presents strong results on application to face detection. Our fourth author, John Platt, gives us a practical guide and a new technique for implementing the algorithm efficiently.},
  eventtitle = {{{IEEE Intelligent Systems}} and Their {{Applications}}},
  keywords = {Algorithm design and analysis,Character recognition,Kernel,Machine learning,Neural networks,Pattern recognition,Polynomials,Support vector machines,Training data,Web pages},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\NT2PVR2W\\Hearst et al_1998_Support vector machines.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\GGLEI95L\\708428.html}
}

@article{hernandez2022SyntheticDataGeneration,
  title = {Synthetic Data Generation for Tabular Health Records: {{A}} Systematic Review},
  shorttitle = {Synthetic Data Generation for Tabular Health Records},
  author = {Hernandez, Mikel and Epelde, Gorka and Alberdi, Ane and Cilla, Rodrigo and Rankin, Debbie},
  date = {2022-07},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {493},
  pages = {28--45},
  issn = {09252312},
  doi = {10.1016/j.neucom.2022.04.053},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231222004349},
  urldate = {2022-08-08},
  langid = {english},
  keywords = {01,Artificial intelligence,Data sharing,Generative adversarial networks,Healthcare,Privacy preserving data,Synthetic data generation},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\HAGVQHCE\\Hernandez et al_2022_Synthetic data generation for tabular health records.pdf}
}

@inproceedings{herzig2020TaPasWeaklySupervised,
  title = {{{TaPas}}: {{Weakly Supervised Table Parsing}} via {{Pre-training}}},
  shorttitle = {{{TaPas}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Herzig, Jonathan and Nowak, Pawel Krzysztof and Müller, Thomas and Piccinno, Francesco and Eisenschlos, Julian},
  date = {2020-07},
  pages = {4320--4333},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.acl-main.398},
  url = {https://aclanthology.org/2020.acl-main.398},
  urldate = {2023-01-25},
  abstract = {Answering natural language questions over tables is usually seen as a semantic parsing task. To alleviate the collection cost of full logical forms, one popular approach focuses on weak supervision consisting of denotations instead of logical forms. However, training semantic parsers from weak supervision poses difficulties, and in addition, the generated logical forms are only used as an intermediate step prior to retrieving the denotation. In this paper, we present TaPas, an approach to question answering over tables without generating logical forms. TaPas trains from weak supervision, and predicts the denotation by selecting table cells and optionally applying a corresponding aggregation operator to such selection. TaPas extends BERT's architecture to encode tables as input, initializes from an effective joint pre-training of text segments and tables crawled from Wikipedia, and is trained end-to-end. We experiment with three different semantic parsing datasets, and find that TaPas outperforms or rivals semantic parsing models by improving state-of-the-art accuracy on SQA from 55.1 to 67.2 and performing on par with the state-of-the-art on WikiSQL and WikiTQ, but with a simpler model architecture. We additionally find that transfer learning, which is trivial in our setting, from WikiSQL to WikiTQ, yields 48.7 accuracy, 4.2 points above the state-of-the-art.},
  eventtitle = {{{ACL}} 2020},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\SLVFHCYJ\\Herzig et al_2020_TaPas.pdf}
}

@inproceedings{hittmeir2019UtilitySyntheticData,
  title = {On the {{Utility}} of {{Synthetic Data}}: {{An Empirical Evaluation}} on {{Machine Learning Tasks}}},
  shorttitle = {On the {{Utility}} of {{Synthetic Data}}},
  booktitle = {Proceedings of the 14th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Hittmeir, Markus and Ekelhart, Andreas and Mayer, Rudolf},
  date = {2019-08-26},
  pages = {1--6},
  publisher = {{ACM}},
  location = {{Canterbury CA United Kingdom}},
  doi = {10.1145/3339252.3339281},
  url = {https://dl.acm.org/doi/10.1145/3339252.3339281},
  urldate = {2022-06-23},
  abstract = {With the recent advances and increasing activities in data mining and analysis, the protection of the privacy of individuals is crucial. Several approaches address this concern, from techniques like data anonymisation to secure, non-disclosive computation, all of which have their specific strengths and weaknesses, depending on the specific requirements. A slightly different approach is the generation of synthetic data, which tries to preserve the overall properties and characteristics of the original data without revealing information about actual individual data samples. The promise is that, for most purposes, models trained on the synthetic data instead of the real data do not show a significant loss of performance. In this paper, we give an overview on currently available approaches for synthetic data generation, and empirically evaluate the utility of the generated synthetic data by testing them on a number of supervised machine learning tasks on several publicly available datasets.},
  eventtitle = {{{ARES}} '19: 14th {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  isbn = {978-1-4503-7164-3},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\I3EET8PU\\Hittmeir et al. - 2019 - On the Utility of Synthetic Data An Empirical Eva.pdf}
}

@online{ho2020DenoisingDiffusionProbabilistic,
  title = {Denoising {{Diffusion Probabilistic Models}}},
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  date = {2020-12-16},
  number = {arXiv:2006.11239},
  eprint = {arXiv:2006.11239},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2006.11239},
  urldate = {2023-01-09},
  abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\8CAFBID2\\Ho et al_2020_Denoising Diffusion Probabilistic Models.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\F2BFBZYJ\\2006.html}
}

@online{ho2022ClassifierFreeDiffusionGuidance,
  title = {Classifier-{{Free Diffusion Guidance}}},
  author = {Ho, Jonathan and Salimans, Tim},
  date = {2022-07-25},
  number = {arXiv:2207.12598},
  eprint = {arXiv:2207.12598},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2207.12598},
  urldate = {2023-01-10},
  abstract = {Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\QUZSJMU4\\Ho_Salimans_2022_Classifier-Free Diffusion Guidance.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\H62954ZP\\2207.html}
}

@online{ho2022VideoDiffusionModels,
  title = {Video {{Diffusion Models}}},
  author = {Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J.},
  date = {2022-06-22},
  number = {arXiv:2204.03458},
  eprint = {arXiv:2204.03458},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2204.03458},
  urldate = {2023-02-13},
  abstract = {Generating temporally coherent high fidelity video is an important milestone in generative modeling research. We make progress towards this milestone by proposing a diffusion model for video generation that shows very promising initial results. Our model is a natural extension of the standard image diffusion architecture, and it enables jointly training from image and video data, which we find to reduce the variance of minibatch gradients and speed up optimization. To generate long and higher resolution videos we introduce a new conditional sampling technique for spatial and temporal video extension that performs better than previously proposed methods. We present the first results on a large text-conditioned video generation task, as well as state-of-the-art results on established benchmarks for video prediction and unconditional video generation. Supplementary material is available at https://video-diffusion.github.io/},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\CDQJZLGH\\Ho et al_2022_Video Diffusion Models.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\JTDLYI3K\\2204.html}
}

@article{hochreiter1997LongShortTermMemory,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  date = {1997-11-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Comput.},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  url = {https://doi.org/10.1162/neco.1997.9.8.1735},
  urldate = {2023-02-14},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}
}

@inproceedings{hoogeboom2021ArgmaxFlowsMultinomial,
  title = {Argmax {{Flows}} and {{Multinomial Diffusion}}: {{Learning Categorical Distributions}}},
  shorttitle = {Argmax {{Flows}} and {{Multinomial Diffusion}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forré, Patrick and Welling, Max},
  date = {2021},
  volume = {34},
  pages = {12454--12465},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2021/hash/67d96d458abdef21792e6d8e590244e7-Abstract.html},
  urldate = {2023-01-16},
  abstract = {Generative flows and diffusion models have been predominantly trained on ordinal data, for example natural images. This paper introduces two extensions of flows and diffusion for categorical data such as language or image segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined by a composition of a continuous distribution (such as a normalizing flow), and an argmax function. To optimize this model, we learn a probabilistic inverse for the argmax that lifts the categorical data to a continuous space. Multinomial Diffusion gradually adds categorical noise in a diffusion process, for which the generative denoising process is learned. We demonstrate that our method outperforms existing dequantization approaches on text modelling and modelling on image segmentation maps in log-likelihood.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\RIRLJD5E\\Hoogeboom et al_2021_Argmax Flows and Multinomial Diffusion.pdf}
}

@article{hornik1989MultilayerFeedforwardNetworks,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  date = {1989-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {08936080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
  urldate = {2023-02-14},
  abstract = {This paper rigorously establishes thut standard rnultiluyer feedforward networks with as f\&v us one hidden layer using arbitrary squashing functions ure capable of upproximating uny Bore1 measurable function from one finite dimensional space to another to any desired degree of uccuracy, provided sujficirntly muny hidden units are available. In this sense, multilayer feedforward networks are u class of universul rlpproximators.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\C22ZDANL\\Hornik et al. - 1989 - Multilayer feedforward networks are universal appr.pdf}
}

@article{hosseini2017NonintrusiveLoadMonitoring,
  title = {Non-Intrusive Load Monitoring through Home Energy Management Systems: {{A}} Comprehensive Review},
  author = {Hosseini, Sayed Saeed and Agbossou, Kodjo and Kelouwani, Sousso and Cardenas, Alben},
  date = {2017-11-01},
  journaltitle = {Renewable and Sustainable Energy Reviews},
  shortjournal = {Renewable and Sustainable Energy Reviews},
  volume = {79},
  pages = {1266--1274},
  issn = {1364-0321},
  doi = {10.1016/j.rser.2017.05.096},
  url = {https://www.sciencedirect.com/science/article/pii/S1364032117307359},
  abstract = {The enhanced utilization of Appliance Load Monitoring (ALM) in customer sites enabled by Home Energy Management Systems (HEMS) technologies, offers customized services and enables demand side flexibility in power systems. The significant integration of advanced electrical and computer engineering tools makes the nonintrusive approach of ALM a technically feasible solution to improve demand side energy utilization in the context of HEMS. This paper presents a comprehensive study conducted to reveal significant inevitabilities of a well organized Non-intrusive Load Monitoring (NILM) that aids Smart Home (SH) idea to be implemented. In fact, the viewpoint of this study is to discuss critical issues related to NILM prerequisite necessities, hindered the practical implication of this approach despite improvements during over 30 years. Accordingly, this work presents actual analyses in order to elucidate some arguments using state of the art procedures and results of a semi-synthetic data generator tool. In addition, with the aim of an achievable NILM, we analyze NILM applications from the stakeholders’ perspective to assist the choice of employed techniques. Consequently, by investigating crucial intentions of an effective NILM considering current standstill and future progression, the authors propose the Advanced NILM (ANILM) concept and describe its properties to provide an enhanced energy usage system in demand side. In order to meet its ambition, the paper uses a realistic point of view to pinpoint major obstacles toward NILM and elaborate various factors that will make it effectively feasible.},
  keywords = {Advanced non-intrusive load monitoring,Appliance load monitoring,Home energy management systems,Non-intrusive load monitoring,Smart grids,Smart home}
}

@online{huang2020TabTransformerTabularData,
  title = {{{TabTransformer}}: {{Tabular Data Modeling Using Contextual Embeddings}}},
  shorttitle = {{{TabTransformer}}},
  author = {Huang, Xin and Khetan, Ashish and Cvitkovic, Milan and Karnin, Zohar},
  date = {2020-12-11},
  number = {arXiv:2012.06678},
  eprint = {arXiv:2012.06678},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2012.06678},
  url = {http://arxiv.org/abs/2012.06678},
  urldate = {2023-02-20},
  abstract = {We propose TabTransformer, a novel deep tabular data modeling architecture for supervised and semi-supervised learning. The TabTransformer is built upon self-attention based Transformers. The Transformer layers transform the embeddings of categorical features into robust contextual embeddings to achieve higher prediction accuracy. Through extensive experiments on fifteen publicly available datasets, we show that the TabTransformer outperforms the state-of-the-art deep learning methods for tabular data by at least 1.0\% on mean AUC, and matches the performance of tree-based ensemble models. Furthermore, we demonstrate that the contextual embeddings learned from TabTransformer are highly robust against both missing and noisy data features, and provide better interpretability. Lastly, for the semi-supervised setting we develop an unsupervised pre-training procedure to learn data-driven contextual embeddings, resulting in an average 2.1\% AUC lift over the state-of-the-art methods.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FJ2J3Y2B\\Huang et al_2020_TabTransformer.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\K4H72RDC\\2012.html}
}

@online{huggingface2023DiffusersPipelines,
  title = {Diffusers {{Pipelines}}},
  author = {Huggingface},
  date = {2023-02-03},
  url = {https://github.com/huggingface/diffusers},
  urldate = {2023-03-02},
  abstract = {🤗 Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch - diffusers/src/diffusers/pipelines at main · huggingface/diffusers},
  organization = {{Github}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\CSSMBYEI\\pipelines.html}
}

@inproceedings{iida2021TABBIEPretrainedRepresentations,
  title = {{{TABBIE}}: {{Pretrained Representations}} of {{Tabular Data}}},
  shorttitle = {{{TABBIE}}},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Iida, Hiroshi and Thai, Dung and Manjunatha, Varun and Iyyer, Mohit},
  date = {2021-06},
  pages = {3446--3456},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2021.naacl-main.270},
  url = {https://aclanthology.org/2021.naacl-main.270},
  urldate = {2023-01-25},
  abstract = {Existing work on tabular representation-learning jointly models tables and associated text using self-supervised objective functions derived from pretrained language models such as BERT. While this joint pretraining improves tasks involving paired tables and text (e.g., answering questions about tables), we show that it underperforms on tasks that operate over tables without any associated text (e.g., populating missing cells). We devise a simple pretraining objective (corrupt cell detection) that learns exclusively from tabular data and reaches the state-of-the-art on a suite of table-based prediction tasks. Unlike competing approaches, our model (TABBIE) provides embeddings of all table substructures (cells, rows, and columns), and it also requires far less compute to train. A qualitative analysis of our model's learned cell, column, and row representations shows that it understands complex table semantics and numerical trends.},
  eventtitle = {{{NAACL-HLT}} 2021},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JPD62LHS\\Iida et al_2021_TABBIE.pdf}
}

@article{izonin2022TwoStepDataNormalization,
  title = {A {{Two-Step Data Normalization Approach}} for {{Improving Classification Accuracy}} in the {{Medical Diagnosis Domain}}},
  author = {Izonin, Ivan and Tkachenko, Roman and Shakhovska, Nataliya and Ilchyshyn, Bohdan and Singh, Krishna Kant},
  date = {2022-01},
  journaltitle = {Mathematics},
  volume = {10},
  number = {11},
  pages = {1942},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2227-7390},
  doi = {10.3390/math10111942},
  url = {https://www.mdpi.com/2227-7390/10/11/1942},
  urldate = {2023-02-11},
  abstract = {Data normalization is a data preprocessing task and one of the first to be performed during intellectual analysis, particularly in the case of tabular data. The importance of its implementation is determined by the need to reduce the sensitivity of the artificial intelligence model to the values of the features in the dataset to increase the studied model’s adequacy. This paper focuses on the problem of effectively preprocessing data to improve the accuracy of intellectual analysis in the case of performing medical diagnostic tasks. We developed a new two-step method for data normalization of numerical medical datasets. It is based on the possibility of considering both the interdependencies between the features of each observation from the dataset and their absolute values to improve the accuracy when performing medical data mining tasks. We describe and substantiate each step of the algorithmic implementation of the method. We also visualize the results of the proposed method. The proposed method was modeled using six different machine learning methods based on decision trees when performing binary and multiclass classification tasks. We used six real-world, freely available medical datasets with different numbers of vectors, attributes, and classes to conduct experiments. A comparison between the effectiveness of the developed method and that of five existing data normalization methods was carried out. It was experimentally established that the developed method increases the accuracy of the Decision Tree and Extra Trees Classifier by 1–5\% in the case of performing the binary classification task and the accuracy of the Bagging, Decision Tree, and Extra Trees Classifier by 1–6\% in the case of performing the multiclass classification task. Increasing the accuracy of these classifiers only by using the new data normalization method satisfies all the prerequisites for its application in practice when performing various medical data mining tasks.},
  issue = {11},
  langid = {english},
  keywords = {binary classification,classification accuracy,data normalization,decision trees,machine learning,medical diagnostics,multiclass classification,precision model,preprocessing,scalers,small data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\IIBVPIX5\\Izonin et al_2022_A Two-Step Data Normalization Approach for Improving Classification Accuracy in.pdf}
}

@misc{jain2018ImaginingEngineerGANBaseda,
  title = {Imagining an {{Engineer}}: {{On GAN-Based Data Augmentation Perpetuating Biases}}},
  shorttitle = {Imagining an {{Engineer}}},
  author = {Jain, Niharika and Manikonda, Lydia and Hernandez, Alberto Olmo and Sengupta, Sailik and Kambhampati, Subbarao},
  date = {2018-11-08},
  number = {arXiv:1811.03751},
  eprint = {1811.03751},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1811.03751},
  url = {http://arxiv.org/abs/1811.03751},
  urldate = {2022-07-10},
  abstract = {The use of synthetic data generated by Generative Adversarial Networks (GANs) has become quite a popular method to do data augmentation for many applications. While practitioners celebrate this as an economical way to get more synthetic data that can be used to train downstream classifiers, it is not clear that they recognize the inherent pitfalls of this technique. In this paper, we aim to exhort practitioners against deriving any false sense of security against data biases based on data augmentation. To drive this point home, we show that starting with a dataset consisting of head-shots of engineering researchers, GAN-based augmentation "imagines" synthetic engineers, most of whom have masculine features and white skin color (inferred from a human subject study conducted on Amazon Mechanical Turk). This demonstrates how biases inherent in the training data are reinforced, and sometimes even amplified, by GAN-based data augmentation; it should serve as a cautionary tale for the lay practitioners.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\8IKQ4TIM\\Jain et al_2018_Imagining an Engineer.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\K2MPTXQT\\1811.html}
}

@inproceedings{jordon2018PATEGANGeneratingSynthetic,
  title = {{{PATE-GAN}}: {{Generating Synthetic Data}} with {{Differential Privacy Guarantees}}},
  shorttitle = {{{PATE-GAN}}},
  author = {Jordon, James and Yoon, Jinsung and Schaar, M.},
  date = {2018-09-27},
  url = {https://www.semanticscholar.org/paper/PATE-GAN%3A-Generating-Synthetic-Data-with-Privacy-Jordon-Yoon/af1841e1db6579f1f1777a59c7e9e4658d2ac466},
  urldate = {2023-02-27},
  abstract = {Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the stateof-the-art method with respect to this and other notions of synthetic data quality.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}}
}

@article{kaloskampis2020SyntheticDataCivil,
  title = {Synthetic Data in the Civil Service},
  author = {Kaloskampis, Ioannis and Joshi, Chaitanya and Cheung, Catrin and Pugh, David and Nolan, Louisa},
  date = {2020},
  journaltitle = {Significance},
  volume = {17},
  number = {6},
  pages = {18--23},
  issn = {1740-9713},
  doi = {10.1111/1740-9713.01466},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1740-9713.01466},
  urldate = {2023-02-10},
  abstract = {In a data-driven economy, access to data is vital. So, what happens when data are not available due to disclosure issues or other restrictions? As Ioannis Kaloskampis, Chaitanya Joshi, Catrin Cheung, David Pugh and Louisa Nolan explain, in such situations it may still be possible to draw useful conclusions based on carefully manufactured data},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\AW52Z3XP\\Kaloskampis et al_2020_Synthetic data in the civil service.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\KNGWRMX5\\1740-9713.html}
}

@online{kamthe2021CopulaFlowsSynthetic,
  title = {Copula {{Flows}} for {{Synthetic Data Generation}}},
  author = {Kamthe, Sanket and Assefa, Samuel and Deisenroth, Marc},
  date = {2021-01-03},
  number = {arXiv:2101.00598},
  eprint = {arXiv:2101.00598},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2101.00598},
  urldate = {2023-03-02},
  abstract = {The ability to generate high-fidelity synthetic data is crucial when available (real) data is limited or where privacy and data protection standards allow only for limited use of the given data, e.g., in medical and financial data-sets. Current state-of-the-art methods for synthetic data generation are based on generative models, such as Generative Adversarial Networks (GANs). Even though GANs have achieved remarkable results in synthetic data generation, they are often challenging to interpret.Furthermore, GAN-based methods can suffer when used with mixed real and categorical variables.Moreover, loss function (discriminator loss) design itself is problem specific, i.e., the generative model may not be useful for tasks it was not explicitly trained for. In this paper, we propose to use a probabilistic model as a synthetic data generator. Learning the probabilistic model for the data is equivalent to estimating the density of the data. Based on the copula theory, we divide the density estimation task into two parts, i.e., estimating univariate marginals and estimating the multivariate copula density over the univariate marginals. We use normalising flows to learn both the copula density and univariate marginals. We benchmark our method on both simulated and real data-sets in terms of density estimation as well as the ability to generate high-fidelity synthetic data},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Applications,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\75VN5PFL\\Kamthe et al_2021_Copula Flows for Synthetic Data Generation.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\XGGXRZP8\\2101.html}
}

@article{karaali2013MetallicityDependentTransformationsRed,
  title = {Metallicity-{{Dependent Transformations}} for {{Red Giants}} with {{Synthetic Colours}} of {{{\emph{UBV}}}} and {\emph{Ugr}}},
  author = {Karaali, S. and Gökçe, E. Yaz},
  date = {2013},
  journaltitle = {Publications of the Astronomical Society of Australia},
  shortjournal = {Publ. Astron. Soc. Aust.},
  volume = {30},
  pages = {e040},
  issn = {1323-3580, 1448-6083},
  doi = {10.1017/pasa.2013.17},
  url = {https://www.cambridge.org/core/product/identifier/S1323358013000179/type/journal_article},
  urldate = {2022-07-10},
  abstract = {Abstract                            We present metallicity-dependent transformation equations between               UBV               and SDSS               ugr               colours for red giants with synthetic data. The ranges of the colours used for the transformations are 0.400 ≤ (               B               −               V               )               0               ≤ 1.460, −0.085 ≤ (               U               −               B               )               0               ≤ 1.868, 0.291 ≤ (               g               −               r               )               0               ≤ 1.326, and 1.030 ≤ (               u               −               g               )               0               ≤ 3.316 mag, and cover almost all the observational colours of red giants. We applied the transformation equations to six clusters with different metallicities and compared the resulting (               u               −               g               )               0               colours with those estimated by the calibration of the fiducial sequences of the clusters. The mean and standard deviation of the residuals for all clusters are {$<$}Δ(               u               −               g               )               0               {$>$} = −0.01 and σ(               u               −               g               )               0               = 0.07 mag, respectively. We showed that interstellar reddening plays an important role on the derived colours. The transformations can be applied to clusters as well as to field stars. They can be used to extend the colour range of the red giants in the clusters which are restricted due to the saturation of the SDSS data.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\L5LBGJ8Y\\Karaali_Gökçe_2013_Metallicity-Dependent Transformations for Red Giants with Synthetic Colours of.pdf}
}

@article{khan2022TransformersVisionSurvey,
  title = {Transformers in {{Vision}}: {{A Survey}}},
  shorttitle = {Transformers in {{Vision}}},
  author = {Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
  date = {2022-09-13},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {54},
  pages = {200:1--200:41},
  issn = {0360-0300},
  doi = {10.1145/3505244},
  url = {https://doi.org/10.1145/3505244},
  urldate = {2023-02-20},
  abstract = {Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks, e.g., Long short-term memory. Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text, and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers, i.e., self-attention, large-scale pre-training, and bidirectional feature encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization), and three-dimensional analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works. We hope this effort will ignite further interest in the community to solve current challenges toward the application of transformer models in computer vision.},
  issue = {10s},
  keywords = {bidirectional encoders,convolutional networks,deep neural networks,literature survey,Self-attention,self-supervision,transformers},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\37CTEL6E\\Khan et al_2022_Transformers in Vision.pdf}
}

@article{kherchouche2022AttentionguidedNeuralNetwork,
  title = {Attention-Guided Neural Network for Early Dementia Detection Using {{MRS}} Data},
  author = {Kherchouche, Anouar and Ben-Ahmed, Olfa and Guillevin, Carole and Tremblais, Benoit and Julian, Adrien and Fernandez-Maloigne, Christine and Guillevin, Rémy},
  date = {2022-07-01},
  journaltitle = {Computerized Medical Imaging and Graphics},
  shortjournal = {Computerized Medical Imaging and Graphics},
  volume = {99},
  pages = {102074},
  issn = {0895-6111},
  doi = {10.1016/j.compmedimag.2022.102074},
  url = {https://www.sciencedirect.com/science/article/pii/S0895611122000477},
  abstract = {Imaging bio-markers have been widely used for Computer-Aided Diagnosis (CAD) of Alzheimer’s Disease (AD) with Deep Learning (DL). However, the structural brain atrophy is not detectable at an early stage of the disease (namely for Mild Cognitive Impairment (MCI) and Mild Alzheimer’s Disease (MAD)). Indeed, potential biological bio-markers have been proved their ability to early detect brain abnormalities related to AD before brain structural damage and clinical manifestation. Proton Magnetic Resonance Spectroscopy (1H-MRS) provides a promising solution for biological brain changes detection in a no invasive manner. In this paper, we propose an attention-guided supervised DL framework for early AD detection using 1H-MRS data. In the early stages of AD, features may be closely related and often complex to delineate between subjects. Hence, we develop a 1D attention mechanism that explicitly guides the classifier to focus on diagnostically relevant metabolites for classes discrimination. Synthetic data are used to tackle the lack of data problem and to help in learning the feature space. Data used in this paper are collected in the University Hospital of Poitiers, which contained 111 1H-MRS samples extracted from the Posterior Cingulate Cortex (PCC) brain region. The data contain 33 Normal Control (NC), 49 MCI due to AD, and 29 MAD subjects. The proposed model achieves an average classification accuracy of 95.23\%. Our framework outperforms state of the art imaging-based approaches, proving the robustness of learning metabolites features against traditional imaging bio-markers for early AD detection.},
  keywords = {Alzheimer’s disease,Attention mechanism,Computer-Aided Diagnosis,Deep learning,Feature refinement,Magnetic resonance spectroscopy}
}

@inproceedings{kim2021OCTGANNeuralODEbased,
  title = {{{OCT-GAN}}: {{Neural ODE-based Conditional Tabular GANs}}},
  shorttitle = {{{OCT-GAN}}},
  booktitle = {Proceedings of the {{Web Conference}} 2021},
  author = {Kim, Jayoung and Jeon, Jinsung and Lee, Jaehoon and Hyeong, Jihyeon and Park, Noseong},
  date = {2021-04-19},
  pages = {1506--1515},
  publisher = {{ACM}},
  location = {{Ljubljana Slovenia}},
  doi = {10.1145/3442381.3449999},
  url = {https://dl.acm.org/doi/10.1145/3442381.3449999},
  urldate = {2022-08-07},
  eventtitle = {{{WWW}} '21: {{The Web Conference}} 2021},
  isbn = {978-1-4503-8312-7},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\MLZ7Q8QT\\Kim et al_2021_OCT-GAN.pdf}
}

@online{kingma2013AutoEncodingVariationalBayes,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2013},
  number = {arXiv:1312.6114},
  eprint = {arXiv:1312.6114},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1312.6114},
  urldate = {2023-01-09},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\UIDKU835\\Kingma_Welling_2022_Auto-Encoding Variational Bayes.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\EMVJ4YTZ\\1312.html}
}

@article{kingma2019IntroductionVariationalAutoencoders,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2019-11-27},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {MAL},
  volume = {12},
  number = {4},
  pages = {307--392},
  publisher = {{Now Publishers, Inc.}},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  url = {https://www.nowpublishers.com/article/Details/MAL-056},
  urldate = {2023-02-15},
  abstract = {An Introduction to Variational Autoencoders},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\TBIZNI22\\Kingma_Welling_2019_An Introduction to Variational Autoencoders.pdf}
}

@article{klaudiny2014ErrorAnalysisPhotometric,
  title = {Error Analysis of Photometric Stereo with Colour Lights},
  author = {Klaudiny, Martin and Hilton, Adrian},
  date = {2014-10-15},
  journaltitle = {Celebrating the life and work of Maria Petrou},
  shortjournal = {Pattern Recognition Letters},
  volume = {48},
  pages = {81--92},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2013.12.013},
  url = {https://www.sciencedirect.com/science/article/pii/S0167865513005114},
  abstract = {This paper presents a comprehensive error analysis of photometric stereo with colour lights for surface normal estimation. An analytic formulation is introduced for the error in albedo-scaled normal estimation with respect to all inputs to the photometric stereo – pixel colour, light directions and light-sensor-material interaction. This characterises the error in the estimated normal for all possible directions with respect to the light setup given discrepancies in the inputs. The theoretical formulation is validated by an extensive set of experiments with synthetic data. Example discrepancies in each input to the photometric stereo calculation show a complex distribution of the error of an albedo-scaled normal over the space of possible orientations. This is generalised in the empirical sensitivity analysis which demonstrates that the magnitude of the error propagation from the light directions and the light-sensor-material interaction depends on the surface orientation. However, the image noise is propagated uniformly to all normal directions. There is a linear relationship between the uncertainty in the individual inputs and in the output normals. The theoretical and experimental findings provide several recommendations on designing a capture setup which is the least sensitive to the inaccuracies in the pixel colours, the light directions and the light-sensor-material interaction. An example is provided showing how to assess the inaccuracies in PSCL calculation for a real-world setup.},
  keywords = {Error analysis,Photometric stereo,Photometric stereo with colour lights,Sensitivity analysis}
}

@article{knackstedt2006OnlineLiteraturdatenbankenImBereich,
  title = {Online-Literaturdatenbanken im Bereich der Wirtschaftsinformatik: Bereitstellung wissenschaftlicher Literatur und Analyse von Interaktionen der Wissensteilung},
  shorttitle = {Online-Literaturdatenbanken im Bereich der Wirtschaftsinformatik},
  author = {Knackstedt, Ralf and Winkelmann, Axel},
  date = {2006-01},
  journaltitle = {WIRTSCHAFTSINFORMATIK},
  shortjournal = {Wirtsch. Inform.},
  volume = {48},
  number = {1},
  pages = {47--59},
  issn = {0937-6429, 1861-8936},
  doi = {10.1007/s11576-006-0006-1},
  url = {http://link.springer.com/10.1007/s11576-006-0006-1},
  urldate = {2022-07-05},
  langid = {ngerman},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\CHA84XMA\\Knackstedt_Winkelmann_2006_Online-Literaturdatenbanken im Bereich der Wirtschaftsinformatik.pdf}
}

@article{knackstedt2006OnlineLiteraturdatenbankenImBereicha,
  title = {Online-{{Literaturdatenbanken}} Im {{Bereich}} Der {{Wirtschaftsinformatik}}: {{Bereitstellung}} Wissenschaftlicher {{Literatur}} Und {{Analyse}} von {{Interaktionen}} Der {{Wissensteilung}}},
  shorttitle = {Online-{{Literaturdatenbanken}} Im {{Bereich}} Der {{Wirtschaftsinformatik}}},
  author = {Knackstedt, Ralf and Winkelmann, Axel},
  date = {2006},
  publisher = {{Springer}},
  issn = {1861-8936},
  url = {http://dl.gi.de/handle/20.500.12116/12522},
  urldate = {2022-07-05},
  abstract = {Knowledge sharing is fundamental for innovations in the scientific community. The paper examines how the interaction of knowledge sharing is supported by online services. With respect to business information systems, a survey of online literature databases is given, providing an aggregation of various publication sources, a direct access to publications, and which are available to the public. Furthermore, special analysis services are presented which describe competitive interactions of knowledge sharing via rankings on the one hand, and cooperative interactions of knowledge sharing via co-authorship evaluation on the other.},
  langid = {english},
  annotation = {Accepted: 2018-01-16T08:54:05Z},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LRW537QB\\12522.html}
}

@article{knackstedt2006OnlineLiteraturdatenbankenImBereichb,
  title = {Online-Literaturdatenbanken im Bereich der Wirtschaftsinformatik: Bereitstellung wissenschaftlicher Literatur und Analyse von Interaktionen der Wissensteilung},
  author = {Knackstedt, Ralf and Winkelmann, Axel},
  date = {2006},
  pages = {13},
  langid = {ngerman}
}

@inproceedings{kohavi1996ScalingAccuracyNaiveBayes,
  title = {Scaling {{Up}} the {{Accuracy}} of {{Naive-Bayes Classifiers}}: {{A Decision-Tree Hybrid}}},
  shorttitle = {Scaling {{Up}} the {{Accuracy}} of {{Naive-Bayes Classifiers}}},
  author = {Kohavi, Ron},
  date = {1996-08-02},
  url = {https://www.semanticscholar.org/paper/Scaling-Up-the-Accuracy-of-Naive-Bayes-Classifiers%3A-Kohavi/34ae1e95775cfec793441c9f588a68c0020f21e5},
  urldate = {2023-03-13},
  abstract = {Naive-Bayes induction algorithms were previously shown to be surprisingly accurate on many classification tasks even when the conditional independence assumption on which they are based is violated. However, most studies were done on small databases. We show that in some larger databases, the accuracy of Naive-Bayes does not scale up as well as decision trees. We then propose a new algorithm, NBTree, which induces a hybrid of decision-tree classifiers and Naive-Bayes classifiers: the decision-tree nodes contain univariate splits as regular decision-trees, but the leaves contain Naive-Bayesian classifiers. The approach retains the interpretability of Naive-Bayes and decision trees, while resulting in classifiers that frequently outperform both constituents, especially in the larger databases tested.},
  eventtitle = {Knowledge {{Discovery}} and {{Data Mining}}}
}

@article{kohavi2001StudyCrossValidationBootstrap,
  title = {A {{Study}} of {{Cross-Validation}} and {{Bootstrap}} for {{Accuracy Estimation}} and {{Model Selection}}},
  author = {Kohavi, Ron},
  date = {2001-03-03},
  volume = {14},
  abstract = {We review accuracy estimation methods and compare the two most common methods: crossvalidation and bootstrap. Recent experimental results on artificial data and theoretical results in restricted settings have shown that for selecting a good classifier from a set of classifiers (model selection), ten-fold cross-validation may be better than the more expensiveleaveone -out cross-validation. We report on a largescale experiment---over half a million runs of C4.5 and a Naive-Bayes algorithm---to estimate the effects of different parameters on these algorithms on real-world datasets. For crossvalidation, wevary the number of folds and whether the folds are stratified or not\# for bootstrap, wevary the number of bootstrap samples. Our results indicate that for real-word datasets similar to ours, the best method to use for model selection is ten-fold stratified cross validation, even if computation power allows using more folds. 1 Introduction It can not be emphasized eno...},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JXGV9IBN\\Kohavi_2001_A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model.pdf}
}

@article{kosinka2015WatertightConversionTrimmed,
  title = {Watertight Conversion of Trimmed {{CAD}} Surfaces to {{Clough}}–{{Tocher}} Splines},
  author = {Kosinka, Jiří and Cashman, Thomas J.},
  date = {2015-08-01},
  journaltitle = {Computer Aided Geometric Design},
  shortjournal = {Computer Aided Geometric Design},
  volume = {37},
  pages = {25--41},
  issn = {0167-8396},
  doi = {10.1016/j.cagd.2015.06.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0167839615000795},
  abstract = {The boundary representations (B-reps) that are used to represent shape in Computer-Aided Design systems create unavoidable gaps at the face boundaries of a model. Although these inconsistencies can be kept below the scale that is important for visualisation and manufacture, they cause problems for many downstream tasks, making it difficult to use CAD models directly for simulation or advanced geometric analysis, for example. Motivated by this need for watertight models, we address the problem of converting B-rep models to a collection of cubic C1 Clough–Tocher splines. These splines allow a watertight join between B-rep faces, provide a homogeneous representation of shape, and also support local adaptivity. We perform a comparative study of the most prominent Clough–Tocher constructions and include some novel variants. Our criteria include visual fairness, invariance to affine reparameterisations, polynomial precision and approximation error. The constructions are tested on both synthetic data and CAD models that have been triangulated. Our results show that no construction is optimal in every scenario, with surface quality depending heavily on the triangulation and parameterisation that are used.},
  keywords = {Boundary representation,CAD model,Clough–Tocher spline,Watertight conversion}
}

@inproceedings{kossen2021SelfAttentionDatapointsGoing,
  title = {Self-{{Attention Between Datapoints}}: {{Going Beyond Individual Input-Output Pairs}} in {{Deep Learning}}},
  shorttitle = {Self-{{Attention Between Datapoints}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kossen, Jannik and Band, Neil and Lyle, Clare and Gomez, Aidan N and Rainforth, Thomas and Gal, Yarin},
  date = {2021},
  volume = {34},
  pages = {28742--28756},
  publisher = {{Curran Associates, Inc.}},
  url = {https://papers.nips.cc/paper/2021/hash/f1507aba9fc82ffa7cc7373c58f8a613-Abstract.html},
  urldate = {2023-01-31},
  abstract = {We challenge a common assumption underlying most supervised deep learning: that a model makes a prediction depending only on its parameters and the features of a single input. To this end, we introduce a general-purpose deep learning architecture that takes as input the entire dataset instead of processing one datapoint at a time. Our approach uses self-attention to reason about relationships between datapoints explicitly, which can be seen as realizing non-parametric models using parametric attention mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, our models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive results on tabular data, early results on CIFAR-10, and give insight into how the model makes use of the interactions between points.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\NIZMLXPJ\\Kossen et al_2021_Self-Attention Between Datapoints.pdf}
}

@online{kotelnikov2022TabDDPMModellingTabular,
  title = {{{TabDDPM}}: {{Modelling Tabular Data}} with {{Diffusion Models}}},
  shorttitle = {{{TabDDPM}}},
  author = {Kotelnikov, Akim and Baranchuk, Dmitry and Rubachev, Ivan and Babenko, Artem},
  date = {2022-09-30},
  number = {arXiv:2209.15421},
  eprint = {arXiv:2209.15421},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2209.15421},
  urldate = {2022-10-11},
  abstract = {Denoising diffusion probabilistic models are currently becoming the leading paradigm of generative modeling for many important data modalities. Being the most prevalent in the computer vision community, diffusion models have also recently gained some attention in other domains, including speech, NLP, and graph-like data. In this work, we investigate if the framework of diffusion models can be advantageous for general tabular problems, where datapoints are typically represented by vectors of heterogeneous features. The inherent heterogeneity of tabular data makes it quite challenging for accurate modeling, since the individual features can be of completely different nature, i.e., some of them can be continuous and some of them can be discrete. To address such data types, we introduce TabDDPM -- a diffusion model that can be universally applied to any tabular dataset and handles any type of feature. We extensively evaluate TabDDPM on a wide set of benchmarks and demonstrate its superiority over existing GAN/VAE alternatives, which is consistent with the advantage of diffusion models in other fields. Additionally, we show that TabDDPM is eligible for privacy-oriented setups, where the original datapoints cannot be publicly shared.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\3PV2Q4BQ\\Kotelnikov et al_2022_TabDDPM.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\8XD7IHM6\\2209.html}
}

@article{kowalczyk2022TaxonomyUseSynthetic,
  title = {Towards a {{Taxonomy}} for the {{Use}} of {{Synthetic Data}} in {{Advanced Analytics}}},
  author = {Kowalczyk, Peter and Welsch, Giacomo and Thiesse, Frédéric},
  date = {2022},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2212.02622},
  url = {https://arxiv.org/abs/2212.02622},
  urldate = {2023-01-06},
  abstract = {The proliferation of deep learning techniques led to a wide range of advanced analytics applications in important business areas such as predictive maintenance or product recommendation. However, as the effectiveness of advanced analytics naturally depends on the availability of sufficient data, an organization’s ability to exploit the benefits might be restricted by limited data or likewise data access. These challenges could force organizations to spend substantial amounts of money on data, accept constrained analytics capacities, or even turn into a showstopper for analytics projects. Against this backdrop, recent advances in deep learning to generate synthetic data may help to overcome these barriers. Despite its great potential, however, synthetic data are rarely employed. Therefore, we present a taxonomy highlighting the various facets of deploying synthetic data for advanced analytics systems. Furthermore, we identify typical application scenarios for synthetic data to assess the current state of adoption and thereby unveil missed opportunities to pave the way for further research.},
  langid = {english},
  version = {1},
  keywords = {A.1; H.0; H.4; I.2.1,Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\WMXLBH8W\\Kowalczyk et al. - 2022 - Towards a Taxonomy for the Use of Synthetic Data i.pdf}
}

@misc{kunar2021DTGANDifferentialPrivatea,
  title = {{{DTGAN}}: {{Differential Private Training}} for {{Tabular GANs}}},
  shorttitle = {{{DTGAN}}},
  author = {Kunar, Aditya and Birke, Robert and Zhao, Zilong and Chen, Lydia},
  date = {2021-08-02},
  number = {arXiv:2107.02521},
  eprint = {2107.02521},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2107.02521},
  url = {http://arxiv.org/abs/2107.02521},
  urldate = {2022-07-10},
  abstract = {Tabular generative adversarial networks (TGAN) have recently emerged to cater to the need of synthesizing tabular data – the most widely used data format. While synthetic tabular data offers the advantage of complying with privacy regulations, there still exists a risk of privacy leakage via inference attacks due to interpolating the properties of real data during training. Differential private (DP) training algorithms provide theoretical guarantees for training machine learning models by injecting statistical noise to prevent privacy leaks. However, the challenges of applying DP on TGAN are to determine the most optimal framework (i.e., PATE/DP-SGD) and neural network (i.e., Generator/Discriminator)to inject noise such that the data utility is well maintained under a given privacy guarantee. In this paper, we propose DTGAN, a novel conditional Wasserstein tabular GAN that comes in two variants DTGAN\_G and DTGAN\_D, for providing a detailed comparison of tabular GANs trained using DP-SGD for the generator vs discriminator, respectively. We elicit the privacy analysis associated with training the generator with complex loss functions (i.e., classification and information losses) needed for high quality tabular data synthesis. Additionally, we rigorously evaluate the theoretical privacy guarantees offered by DP empirically against membership and attribute inference attacks. Our results on 3 datasets show that the DP-SGD framework is superior to PATE and that a DP discriminator is more optimal for training convergence. Thus, we find (i) DTGAN\_D is capable of maintaining the highest data utility across 4 ML models by up to 18\% in terms of the average precision score for a strict privacy budget, epsilon = 1, as compared to the prior studies and (ii) DP effectively prevents privacy loss against inference attacks by restricting the success probability of membership attacks to be close to 50\%.},
  keywords = {02,Computer Science - Machine Learning,DP,DTGAN,gan,wasserstein},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\74HQDD8C\\Kunar et al_2021_DTGAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\LUFJ4MYB\\2107.html}
}

@misc{kunar2021EffectivePrivacyPreservinga,
  title = {Effective and {{Privacy}} Preserving {{Tabular Data Synthesizing}}},
  author = {Kunar, Aditya},
  date = {2021-08-11},
  number = {arXiv:2108.10064},
  eprint = {2108.10064},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2108.10064},
  url = {http://arxiv.org/abs/2108.10064},
  urldate = {2022-07-10},
  abstract = {While data sharing is crucial for knowledge development, privacy concerns and strict regulation (e.g., European General Data Protection Regulation (GDPR)) unfortunately limits its full effectiveness. Synthetic tabular data emerges as an alternative to enable data sharing while fulfilling regulatory and privacy constraints. The state-of-the-art tabular data synthesizers draw methodologies from Generative Adversarial Networks (GAN). In this thesis, we develop CTAB-GAN, a novel conditional table GAN architecture that can effectively model diverse data types with complex distributions. CTAB-GAN is extensively evaluated with the state of the art GANs that generate synthetic tables, in terms of data similarity and analysis utility. The results on five datasets show that the synthetic data of CTAB-GAN remarkably resembles the real data for all three types of variables and results in higher accuracy for five machine learning algorithms, by up to 17\%. Additionally, to ensure greater security for training tabular GANs against malicious privacy attacks, differential privacy (DP) is studied and used to train CTAB-GAN with strict privacy guarantees. DP-CTAB-GAN is rigorously evaluated using state-of-the-art DP-tabular GANs in terms of data utility and privacy robustness against membership and attribute inference attacks. Our results on three datasets indicate that strict theoretical differential privacy guarantees come only after severely affecting data utility. However, it is shown empirically that these guarantees help provide a stronger defence against privacy attacks. Overall, it is found that DP-CTABGAN is capable of being robust to privacy attacks while maintaining the highest data utility as compared to prior work, by up to 18\% in terms of the average precision score.},
  keywords = {01,Computer Science - Machine Learning,CTAB-GAN,DP,DP-CTAB-GAN,gan,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\S5MDBAXS\\Kunar_2021_Effective and Privacy preserving Tabular Data Synthesizing.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\XH778AAK\\2108.html}
}

@article{KWON2020105441,
  title = {Real and Synthetic Data Sets for Benchmarking Key-Value Stores Focusing on Various Data Types and Sizes},
  author = {Kwon, Hyuk-Yoon},
  date = {2020},
  journaltitle = {Data in Brief},
  volume = {30},
  pages = {105441},
  issn = {2352-3409},
  doi = {10.1016/j.dib.2020.105441},
  url = {https://www.sciencedirect.com/science/article/pii/S2352340920303358},
  abstract = {In this article, we present real and synthetic data sets for benchmarking key-values stores. Here, we focus on various data types and sizes. Key-value pairs in key-value data sets consist of the key and the value. We can construct any kinds of data as key-value data sets by assigning an arbitrary type of data as the value and a unique ID as the key. Therefore, key-value pairs are quite worthy when we deal with big data because the data types in the big data application become more various and, even sometimes, they are not known or determined. In this article, we crawl four kinds of real data sets by varying the type of data sets (i.e., variety) and generate four kinds of synthetic data sets by varying the size of data sets (i.e., volume). For real data sets, we crawl data sets with various data types from Twitter, i.e., Tweets in text, a list of hashtags, geo-location of the tweet, and the number of followers. We also present algorithms for crawling real data sets based on REST APIs and streaming APIs and for generating synthetic data sets. Using those algorithms, we can crawl any key-value pairs of data types supported by Twitter and can generate any size of synthetic data sets by extending them simply. Last, we show that the crawled and generated data sets are actually utilized for the well-known key-value stores such as Level DB of Google, RocksDB of Facebook, and Berkeley DB of Oracle. Actually, the presented real and synthetic data sets have been used for comparing the performance of them. As an example, we present an algorithm of the basic operations for the key-value stores of LevelDB.},
  keywords = {Benchmark,Big data,Geographic location,Key-value pairs,Key-value stores,Social network analysis,Twitter}
}

@book{lane2003IntroductionStatistics,
  title = {Introduction to {{Statistics}}},
  author = {Lane, David M.},
  date = {2003},
  url = {https://open.umn.edu/opentextbooks/textbooks/459},
  urldate = {2023-01-30},
  abstract = {Introduction to Statistics is a resource for learning and teaching introductory statistics. This work is in the public domain. Therefore, it can be copied and reproduced without limitation. However, we would appreciate a citation where possible. Please cite as: Online Statistics Education: A Multimedia Course of Study (http://onlinestatbook.com/). Project Leader: David M. Lane, Rice University. Instructor\&\#39;s manual, PowerPoint Slides, and additional questions are available.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\PRF7QKKB\\Online_Statistics_Education.pdf}
}

@article{lecun1998GradientbasedLearningApplied,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  date = {1998-11},
  journaltitle = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  issn = {1558-2256},
  doi = {10.1109/5.726791},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  eventtitle = {Proceedings of the {{IEEE}}},
  keywords = {Character recognition,Feature extraction,Hidden Markov models,Machine learning,Multi-layer neural network,Neural networks,Optical character recognition software,Optical computing,Pattern recognition,Principal component analysis},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\8M5B5I9X\\726791.html}
}

@misc{lederrey2022DATGANIntegratingExperta,
  title = {{{DATGAN}}: {{Integrating}} Expert Knowledge into Deep Learning for Synthetic Tabular Data},
  shorttitle = {{{DATGAN}}},
  author = {Lederrey, Gael and Hillel, Tim and Bierlaire, Michel},
  date = {2022-03-07},
  number = {arXiv:2203.03489},
  eprint = {2203.03489},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2203.03489},
  url = {http://arxiv.org/abs/2203.03489},
  urldate = {2022-07-10},
  abstract = {Synthetic data can be used in various applications, such as correcting bias datasets or replacing scarce original data for simulation purposes. Generative Adversarial Networks (GANs) are considered state-of-the-art for developing generative models. However, these deep learning models are data-driven, and it is, thus, difficult to control the generation process. It can, therefore, lead to the following issues: lack of representativity in the generated data, the introduction of bias, and the possibility of overfitting the sample's noise. This article presents the Directed Acyclic Tabular GAN (DATGAN) to address these limitations by integrating expert knowledge in deep learning models for synthetic tabular data generation. This approach allows the interactions between variables to be specified explicitly using a Directed Acyclic Graph (DAG). The DAG is then converted to a network of modified Long Short-Term Memory (LSTM) cells to accept multiple inputs. Multiple DATGAN versions are systematically tested on multiple assessment metrics. We show that the best versions of the DATGAN outperform state-of-the-art generative models on multiple case studies. Finally, we show how the DAG can create hypothetical synthetic datasets.},
  keywords = {✔️,01,Computer Science - Machine Learning,DAG,DATGAN,gan,LSTM},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FN7MN8Z3\\Lederrey et al_2022_DATGAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\IICY76PV\\2203.html}
}

@online{lee2022InvertibleTabularGANs,
  title = {Invertible {{Tabular GANs}}: {{Killing Two Birds}} with {{OneStone}} for {{Tabular Data Synthesis}}},
  shorttitle = {Invertible {{Tabular GANs}}},
  author = {Lee, Jaehoon and Hyeong, Jihyeon and Jeon, Jinsung and Park, Noseong and Cho, Jihoon},
  date = {2022-02-07},
  number = {arXiv:2202.03636},
  eprint = {arXiv:2202.03636},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2202.03636},
  url = {http://arxiv.org/abs/2202.03636},
  urldate = {2022-06-29},
  abstract = {Tabular data synthesis has received wide attention in the literature. This is because available data is often limited, incomplete, or cannot be obtained easily, and data privacy is becoming increasingly important. In this work, we present a generalized GAN framework for tabular synthesis, which combines the adversarial training of GANs and the negative log-density regularization of invertible neural networks. The proposed framework can be used for two distinctive objectives. First, we can further improve the synthesis quality, by decreasing the negative log-density of real records in the process of adversarial training. On the other hand, by increasing the negative log-density of real records, realistic fake records can be synthesized in a way that they are not too much close to real records and reduce the chance of potential information leakage. We conduct experiments with real-world datasets for classification, regression, and privacy attacks. In general, the proposed method demonstrates the best synthesis quality (in terms of task-oriented evaluation metrics, e.g., F1) when decreasing the negative log-density during the adversarial training. If increasing the negative log-density, our experimental results show that the distance between real and fake records increases, enhancing robustness against privacy attacks.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\3HDBTCKR\\Lee et al_2022_Invertible Tabular GANs.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\8J63XHT4\\2202.html}
}

@article{leminh2021AirGenGANbasedSynthetic,
  title = {{{AirGen}}: {{GAN-based}} Synthetic Data Generator for Air Monitoring in {{Smart City}}},
  author = {Le Minh, Khanh-Hoi and Le, Kim Hung},
  date = {2021-09-06},
  doi = {10.1109/rtsi50628.2021.9597364},
  abstract = {The past decade has seen a notable increase in air pollution that directly damages health, animals, and plants worldwide. To mitigate such negative effects, several research groups have been working on predicting air quality using deep learning. However, the lack of high-quality air quality datasets is a major obstacle encountered to achieve high accuracy prediction. In this paper, we introduce an air monitoring data generator powered by learning distributed real sequences using the generative adversarial network (GAN), namely AirGen. An unsupervised adversarial loss is also employed in the network to minimize the difference between generated synthetic and original data in the training process. Experiments on real datasets indicate that the data generated by Airgen could significantly increase the prediction accuracy performed by deep learning models. The mean square error (MSE) is remarkably reduced from 0.024 to 0.015.},
  annotation = {MAG ID: 3211749811}
}

@inproceedings{leminh2021AirGenGANbasedSynthetica,
  title = {{{AirGen}}: {{GAN-based}} Synthetic Data Generator for Air Monitoring in {{Smart City}}},
  shorttitle = {{{AirGen}}},
  booktitle = {2021 {{IEEE}} 6th {{International Forum}} on {{Research}} and {{Technology}} for {{Society}} and {{Industry}} ({{RTSI}})},
  author = {Le Minh, Khanh-Hoi and Le, Kim-Hung},
  date = {2021-09-06},
  pages = {317--322},
  publisher = {{IEEE}},
  location = {{Naples, Italy}},
  doi = {10.1109/RTSI50628.2021.9597364},
  url = {https://ieeexplore.ieee.org/document/9597364/},
  urldate = {2022-06-30},
  abstract = {The past decade has seen a notable increase in air pollution that directly damages health, animals, and plants worldwide. To mitigate such negative effects, several research groups have been working on predicting air quality using deep learning. However, the lack of high-quality air quality datasets is a major obstacle encountered to achieve high accuracy prediction. In this paper, we introduce an air monitoring data generator powered by learning distributed real sequences using the generative adversarial network (GAN), namely AirGen. An unsupervised adversarial loss is also employed in the network to minimize the difference between generated synthetic and original data in the training process. Experiments on real datasets indicate that the data generated by Airgen could significantly increase the prediction accuracy performed by deep learning models. The mean square error (MSE) is remarkably reduced from 0.024 to 0.015.},
  eventtitle = {2021 {{IEEE}} 6th {{International Forum}} on {{Research}} and {{Technology}} for {{Society}} and {{Industry}} ({{RTSI}})},
  isbn = {978-1-66544-135-3},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\5GZAZ27W\\Le Minh_Le_2021_AirGen.pdf}
}

@inproceedings{li2020SupportingDatabaseConstraints,
  title = {Supporting {{Database Constraints}} in {{Synthetic Data Generation}} Based on {{Generative Adversarial Networks}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Li, Wanxin},
  date = {2020-06-11},
  pages = {2875--2877},
  publisher = {{ACM}},
  location = {{Portland OR USA}},
  doi = {10.1145/3318464.3384414},
  url = {https://dl.acm.org/doi/10.1145/3318464.3384414},
  urldate = {2022-08-08},
  eventtitle = {{{SIGMOD}}/{{PODS}} '20: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  keywords = {01,constraint,data synthesization,database constraint,gan,generative adversarial network,logic constraint,tabular,TGAN},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\45Z4NQCY\\Li_2020_Supporting database constraints in synthetic data generation based on.pdf}
}

@article{li2021ImprovingGANInverse,
  title = {Improving {{GAN}} with Inverse Cumulative Distribution Function for Tabular Data Synthesis},
  author = {Li, Ban and Luo, Senlin and Qin, Xiaonan and Pan, Limin},
  date = {2021-10},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {456},
  pages = {373--383},
  issn = {09252312},
  doi = {10.1016/j.neucom.2021.05.098},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231221008614},
  urldate = {2022-08-04},
  abstract = {Designing a generative model to synthesize realistic tabular data is of great significance in data science. Existing tabular data generative models have difficulty in handling complicated and diverse marginal dis-tribution types due to the gradient vanishing problem, and these models pay little attention to the cor-relation between attributes. We propose a method that improves the generative adversarial network (GAN) with inverse cumulative distribution function for tabular data synthesis. This method first trans -forms continuous columns into uniform distribution data by using the cumulative distribution function, which can alleviate the gradient vanishing problem in model training. Then the method trains GAN with the transformed data, where the discriminator with label reconstruction function is presented to model the correlation among attributes accurately by introducing an auxiliary supervised task to help the cor-relations extraction. After that, we train a neural network for each continuous column to perform the inverse transformation of generated data into the target distribution, thereby the synthetic data is obtained. Experiments on simulated and real-world datasets show that our method compares favorably against the state-of-the-art methods in modeling tabular data. (c) 2021 Elsevier B.V. All rights reserved.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\R8MKWB5M\\Li et al_2021_Improving GAN with inverse cumulative distribution function for tabular data.pdf}
}

@misc{li2022TTSCGANTransformerTimeSeriesa,
  title = {{{TTS-CGAN}}: {{A Transformer Time-Series Conditional GAN}} for {{Biosignal Data Augmentation}}},
  shorttitle = {{{TTS-CGAN}}},
  author = {Li, Xiaomin and Ngu, Anne Hee Hiong and Metsis, Vangelis},
  date = {2022-06-27},
  number = {arXiv:2206.13676},
  eprint = {2206.13676},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2206.13676},
  url = {http://arxiv.org/abs/2206.13676},
  urldate = {2022-07-10},
  abstract = {Signal measurement appearing in the form of time series is one of the most common types of data used in medical machine learning applications. Such datasets are often small in size, expensive to collect and annotate, and might involve privacy issues, which hinders our ability to train large, state-of-the-art deep learning models for biomedical applications. For time-series data, the suite of data augmentation strategies we can use to expand the size of the dataset is limited by the need to maintain the basic properties of the signal. Generative Adversarial Networks (GANs) can be utilized as another data augmentation tool. In this paper, we present TTS-CGAN, a transformer-based conditional GAN model that can be trained on existing multi-class datasets and generate class-specific synthetic time-series sequences of arbitrary length. We elaborate on the model architecture and design strategies. Synthetic sequences generated by our model are indistinguishable from real ones, and can be used to complement or replace real signals of the same type, thus achieving the goal of data augmentation. To evaluate the quality of the generated data, we modify the wavelet coherence metric to be able to compare the similarity between two sets of signals, and also conduct a case study where a mix of synthetic and real data are used to train a deep learning model for sequence classification. Together with other visualization techniques and qualitative evaluation approaches, we demonstrate that TTS-CGAN generated synthetic data are similar to real data, and that our model performs better than the other state-of-the-art GAN models built for time-series data generation.},
  keywords = {01,Computer Science - Machine Learning,gan,time series data,Transformer},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\2PCXYQKY\\Li et al_2022_TTS-CGAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\UKNTRZPX\\2206.html}
}

@online{li2022TTSGANTransformerbasedTimeSeries,
  title = {{{TTS-GAN}}: {{A Transformer-based Time-Series Generative Adversarial Network}}},
  shorttitle = {{{TTS-GAN}}},
  author = {Li, Xiaomin and Metsis, Vangelis and Wang, Huangyingrui and Ngu, Anne Hee Hiong},
  date = {2022-06-26},
  number = {arXiv:2202.02691},
  eprint = {arXiv:2202.02691},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2202.02691},
  urldate = {2022-06-30},
  abstract = {Signal measurements appearing in the form of time series are one of the most common types of data used in medical machine learning applications. However, such datasets are often small, making the training of deep neural network architectures ineffective. For time-series, the suite of data augmentation tricks we can use to expand the size of the dataset is limited by the need to maintain the basic properties of the signal. Data generated by a Generative Adversarial Network (GAN) can be utilized as another data augmentation tool. RNN-based GANs suffer from the fact that they cannot effectively model long sequences of data points with irregular temporal relations. To tackle these problems, we introduce TTS-GAN, a transformer-based GAN which can successfully generate realistic synthetic time-series data sequences of arbitrary length, similar to the real ones. Both the generator and discriminator networks of the GAN model are built using a pure transformer encoder architecture. We use visualizations and dimensionality reduction techniques to demonstrate the similarity of real and generated time-series data. We also compare the quality of our generated data with the best existing alternative, which is an RNN-based time-series GAN.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\SVTLHDDM\\Li et al_2022_TTS-GAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\FH4323V5\\2202.html}
}

@article{Lin2022,
  title = {{{DPView}}: {{Differentially}} Private Data Synthesis through Domain Size Information},
  author = {Lin, C. and Yu, C. and Huang, C.},
  date = {2022},
  journaltitle = {IEEE Internet of Things Journal},
  doi = {10.1109/JIOT.2022.3151550},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124825229&doi=10.1109%2fJIOT.2022.3151550&partnerID=40&md5=40aaf736f6025107637b21665eadec74},
  abstract = {The use of differentially private synthetic data has been adopted as a common security measure for the public release of sensitive data. However, the existing solutions either suffer from serious privacy budget splitting or fail to fully automate the generation procedures. In this study, we propose an automated system for synthesizing differentially private synthetic tabular data, called DPView. Our key insight is that high-dimensional data synthesis can be accomplished by utilizing the domain sizes of attributes, which are public information, whereas identifying the correlation among attributes is necessary but leads to severe privacy budget splitting. In addition, we analytically optimize both the privacy budget allocation and consistency procedures of the proposed method through mathematical programming. We further propose two novel methods, including iterative non-negativity and consistency-aware normalization, to post-process the synthetic data. An extensive set of experimental results demonstrates the superior utility of DPView. IEEE},
  keywords = {04,DPView,privacy},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\VG7GFZH3\\Lin et al_2022_DPView.pdf}
}

@article{lin2022SurveyTransformers,
  title = {A Survey of Transformers},
  author = {Lin, Tianyang and Wang, Yuxin and Liu, Xiangyang and Qiu, Xipeng},
  date = {2022-01-01},
  journaltitle = {AI Open},
  shortjournal = {AI Open},
  volume = {3},
  pages = {111--132},
  issn = {2666-6510},
  doi = {10.1016/j.aiopen.2022.10.001},
  url = {https://www.sciencedirect.com/science/article/pii/S2666651022000146},
  urldate = {2023-02-20},
  abstract = {Transformers have achieved great success in many artificial intelligence fields, such as natural language processing, computer vision, and audio processing. Therefore, it is natural to attract lots of interest from academic and industry researchers. Up to the present, a great variety of Transformer variants (a.k.a. X-formers) have been proposed, however, a systematic and comprehensive literature review on these Transformer variants is still missing. In this survey, we provide a comprehensive review of various X-formers. We first briefly introduce the vanilla Transformer and then propose a new taxonomy of X-formers. Next, we introduce the various X-formers from three perspectives: architectural modification, pre-training, and applications. Finally, we outline some potential directions for future research.},
  langid = {english},
  keywords = {Deep learning,Pre-trained models,Self-attention,Transformer},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\7YIGMM5I\\Lin et al_2022_A survey of transformers.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\LX5HKVQV\\S2666651022000146.html}
}

@inproceedings{little2021GenerativeAdversarialNetworksa,
  title = {Generative {{Adversarial Networks}} for {{Synthetic Data Generation}}: {{A Comparative Study}}},
  shorttitle = {Generative {{Adversarial Networks}} for {{Synthetic Data Generation}}},
  author = {Little, Claire and Elliot, Mark and Allmendinger, Richard and Samani, Sahel Shariati},
  date = {2021-12-03},
  number = {arXiv:2112.01925},
  eprint = {2112.01925},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2112.01925},
  url = {http://arxiv.org/abs/2112.01925},
  urldate = {2022-07-10},
  abstract = {Generative Adversarial Networks (GANs) are gaining increasing attention as a means for synthesising data. So far much of this work has been applied to use cases outside of the data confidentiality domain with a common application being the production of artificial images. Here we consider the potential application of GANs for the purpose of generating synthetic census microdata. We employ a battery of utility metrics and a disclosure risk metric (the Targeted Correct Attribution Probability) to compare the data produced by tabular GANs with those produced using orthodox data synthesis methods.},
  keywords = {01,Computer Science - Machine Learning,gan,microdata},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\U8JVFTK3\\Little et al_2021_Generative Adversarial Networks for Synthetic Data Generation.pdf}
}

@inproceedings{liu2019PPGANPrivacyPreservingGenerative,
  title = {{{PPGAN}}: {{Privacy-Preserving Generative Adversarial Network}}},
  shorttitle = {{{PPGAN}}},
  booktitle = {2019 {{IEEE}} 25th {{International Conference}} on {{Parallel}} and {{Distributed Systems}} ({{ICPADS}})},
  author = {Liu, Yi and Peng, Jialiang and Yu, James J.Q. and Wu, Yi},
  date = {2019-12},
  pages = {985--989},
  publisher = {{IEEE}},
  location = {{Tianjin, China}},
  doi = {10.1109/ICPADS47876.2019.00150},
  url = {https://ieeexplore.ieee.org/document/8975823/},
  urldate = {2022-07-10},
  eventtitle = {2019 {{IEEE}} 25th {{International Conference}} on {{Parallel}} and {{Distributed Systems}} ({{ICPADS}})},
  isbn = {978-1-72812-583-1},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\6H8T7QKT\\Liu et al_2019_PPGAN.pdf}
}

@inproceedings{liu2019PPGANPrivacypreservingGenerativea,
  title = {{{PPGAN}}: {{Privacy-preserving Generative Adversarial Network}}},
  shorttitle = {{{PPGAN}}},
  booktitle = {2019 {{IEEE}} 25th {{International Conference}} on {{Parallel}} and {{Distributed Systems}} ({{ICPADS}})},
  author = {Liu, Yi and Peng, Jialiang and Yu, James J. Q. and Wu, Yi},
  date = {2019-12},
  eprint = {1910.02007},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {985--989},
  doi = {10.1109/ICPADS47876.2019.00150},
  url = {http://arxiv.org/abs/1910.02007},
  urldate = {2022-07-10},
  abstract = {Generative Adversarial Network (GAN) and its variants serve as a perfect representation of the data generation model, providing researchers with a large amount of high-quality generated data. They illustrate a promising direction for research with limited data availability. When GAN learns the semantic-rich data distribution from a dataset, the density of the generated distribution tends to concentrate on the training data. Due to the gradient parameters of the deep neural network contain the data distribution of the training samples, they can easily remember the training samples. When GAN is applied to private or sensitive data, for instance, patient medical records, as private information may be leakage. To address this issue, we propose a Privacy-preserving Generative Adversarial Network (PPGAN) model, in which we achieve differential privacy in GANs by adding well-designed noise to the gradient during the model learning procedure. Besides, we introduced the Moments Accountant strategy in the PPGAN training process to improve the stability and compatibility of the model by controlling privacy loss. We also give a mathematical proof of the differential privacy discriminator. Through extensive case studies of the benchmark datasets, we demonstrate that PPGAN can generate high-quality synthetic data while retaining the required data available under a reasonable privacy budget.},
  keywords = {02,Computer Science - Machine Learning,dp,gan,gan+,PPGAN,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\Q5LDJRAQ\\Liu et al_2019_PPGAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\4KY5DV48\\1910.html}
}

@misc{liu2021BetterLongrangeTimea,
  title = {Towards {{Better Long-range Time Series Forecasting}} Using {{Generative Adversarial Networks}}},
  author = {Liu, Shiyu and Motani, Mehul},
  date = {2021-10-17},
  number = {arXiv:2110.08770},
  eprint = {2110.08770},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2110.08770},
  url = {http://arxiv.org/abs/2110.08770},
  urldate = {2022-07-10},
  abstract = {Accurate long-range forecasting of time series data is an important problem in many sectors, such as energy, healthcare, and finance. In recent years, Generative Adversarial Networks (GAN) have provided a revolutionary approach to many problems. However, the use of GAN to improve long-range time series forecasting remains relatively unexplored. In this paper, we utilize a Conditional Wasserstein GAN (CWGAN) and augment it with an error penalty term, leading to a new generative model which aims to generate high-quality synthetic time series data, called CWGAN-TS. By using such synthetic data, we develop a long-range forecasting approach, called Generative Forecasting (GenF), consisting of three components: (i) CWGAN-TS to generate synthetic data for the next few time steps. (ii) a predictor which makes long-range predictions based on generated and observed data. (iii) an information theoretic clustering (ITC) algorithm to better train the CWGAN-TS and the predictor. Our experimental results on three public datasets demonstrate that GenF significantly outperforms a diverse range of state-of-the-art benchmarks and classical approaches. In most cases, we find a 6\% - 12\% improvement in predictive performance (mean absolute error) and a 37\% reduction in parameters compared to the best performing benchmark. Lastly, we conduct an ablation study to demonstrate the effectiveness of the CWGAN-TS and the ITC algorithm.},
  keywords = {01,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,conditional GAN,CWGAN-TS,gan,time series data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ILYDK9JC\\Liu_Motani_2021_Towards Better Long-range Time Series Forecasting using Generative Adversarial.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\4VZGBJF6\\2110.html}
}

@inproceedings{lu2019EmpiricalEvaluationSynthetic,
  title = {Empirical {{Evaluation}} on {{Synthetic Data Generation}} with {{Generative Adversarial Network}}},
  booktitle = {Proceedings of the 9th {{International Conference}} on {{Web Intelligence}}, {{Mining}} and {{Semantics}} - {{WIMS2019}}},
  author = {Lu, Pei-Hsuan and Wang, Pang-Chieh and Yu, Chia-Mu},
  date = {2019},
  pages = {1--6},
  publisher = {{ACM Press}},
  location = {{Seoul, Republic of Korea}},
  doi = {10.1145/3326467.3326474},
  url = {http://dl.acm.org/citation.cfm?doid=3326467.3326474},
  urldate = {2022-08-04},
  eventtitle = {The 9th {{International Conference}}},
  isbn = {978-1-4503-6190-3},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\XFISJ9AR\\Lu et al_2019_Empirical evaluation on synthetic data generation with generative adversarial.pdf}
}

@online{lu2021PretrainedTransformersUniversal,
  title = {Pretrained {{Transformers}} as {{Universal Computation Engines}}},
  author = {Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  date = {2021-06-30},
  number = {arXiv:2103.05247},
  eprint = {arXiv:2103.05247},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2103.05247},
  url = {http://arxiv.org/abs/2103.05247},
  urldate = {2023-02-20},
  abstract = {We investigate the capability of a transformer pretrained on natural language to generalize to other modalities with minimal finetuning -- in particular, without finetuning of the self-attention and feedforward layers of the residual blocks. We consider such a model, which we call a Frozen Pretrained Transformer (FPT), and study finetuning it on a variety of sequence classification tasks spanning numerical computation, vision, and protein fold prediction. In contrast to prior works which investigate finetuning on the same modality as the pretraining dataset, we show that pretraining on natural language can improve performance and compute efficiency on non-language downstream tasks. Additionally, we perform an analysis of the architecture, comparing the performance of a random initialized transformer to a random LSTM. Combining the two insights, we find language-pretrained transformers can obtain strong performance on a variety of non-language tasks.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FPZZGC49\\Lu et al_2021_Pretrained Transformers as Universal Computation Engines.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\BM4QD9XN\\2103.html}
}

@misc{lu2022MultiLabelClinicalTimeSeriesa,
  title = {Multi-{{Label Clinical Time-Series Generation}} via {{Conditional GAN}}},
  author = {Lu, Chang and Reddy, Chandan K. and Wang, Ping and Nie, Dong and Ning, Yue},
  date = {2022-04-10},
  number = {arXiv:2204.04797},
  eprint = {2204.04797},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2204.04797},
  url = {http://arxiv.org/abs/2204.04797},
  urldate = {2022-07-10},
  abstract = {With wide applications of electronic health records (EHR), deep learning methods have been adopted to analyze EHR data on various tasks such as representation learning, clinical event prediction, and phenotyping. However, due to privacy constraints, limited access to EHR becomes a bottleneck for deep learning research. Recently, generative adversarial networks (GANs) have been successful in generating EHR data. However, there are still challenges in high-quality EHR generation, including generating time-series EHR and uncommon diseases given imbalanced datasets. In this work, we propose a Multi-label Time-series GAN (MTGAN) to generate EHR data and simultaneously improve the quality of uncommon disease generation. The generator of MTGAN uses a gated recurrent unit (GRU) with a smooth conditional matrix to generate sequences and uncommon diseases. The critic gives scores using Wasserstein distance to recognize real samples from synthetic samples by considering both data and temporal features. We also propose a training strategy to calculate temporal features for real data and stabilize GAN training. Furthermore, we design multiple statistical metrics and prediction tasks to evaluate the generated data. Experimental results demonstrate the quality of the synthetic data and the effectiveness of MTGAN in generating realistic sequential EHR data, especially for uncommon diseases.},
  keywords = {01,Computer Science - Machine Learning,gan,GRU,MTGAN,Multi-label Time-series GAN,time series data,wasserstein},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\NET9D2FI\\Lu et al_2022_Multi-Label Clinical Time-Series Generation via Conditional GAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\DXS2W9N5\\2204.html}
}

@inproceedings{luo2020NetworkNetworkTabular,
  title = {Network {{On Network}} for {{Tabular Data Classification}} in {{Real-world Applications}}},
  booktitle = {Proceedings of the 43rd {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Luo, Yuanfei and Zhou, Hao and Tu, Wei-Wei and Chen, Yuqiang and Dai, Wenyuan and Yang, Qiang},
  date = {2020-07-25},
  series = {{{SIGIR}} '20},
  pages = {2317--2326},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3397271.3401437},
  url = {https://doi.org/10.1145/3397271.3401437},
  urldate = {2023-02-07},
  abstract = {Tabular data is the most common data format adopted by our customers ranging from retail, finance to E-commerce, and tabular data classification plays an essential role to their businesses. In this paper, we present Network On Network (NON), a practical tabular data classification model based on deep neural network to provide accurate predictions. Various deep methods have been proposed and promising progress has been made. However, most of them use operations like neural network and factorization machines to fuse the embeddings of different features directly, and linearly combine the outputs of those operations to get the final prediction. As a result, the intra-field information and the non-linear interactions between those operations (e.g. neural network and factorization machines) are ignored. Intra-field information is the information that features inside each field belong to the same field. NON is proposed to take full advantage of intra-field information and non-linear interactions. It consists of three components: field-wise network at the bottom to capture the intra-field information, across field network in the middle to choose suitable operations data-drivenly, and operation fusion network on the top to fuse outputs of the chosen operations deeply. Extensive experiments on six real-world datasets demonstrate NON can outperform the state-of-the-art models significantly. Furthermore, both qualitative and quantitative study of the features in the embedding space show NON can capture intra-field information effectively.},
  isbn = {978-1-4503-8016-4},
  keywords = {classification,deep learning,neural network,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\7JECHVR8\\Luo et al_2020_Network On Network for Tabular Data Classification in Real-world Applications.pdf}
}

@article{MACIA20131054,
  title = {Learner Excellence Biased by Data Set Selection: {{A}} Case for Data Characterisation and Artificial Data Sets},
  author = {Macià, Núria and Bernadó-Mansilla, Ester and Orriols-Puig, Albert and Kam Ho, Tin},
  date = {2013},
  journaltitle = {Pattern Recognition},
  volume = {46},
  number = {3},
  pages = {1054--1066},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2012.09.022},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320312004281},
  abstract = {The excellence of a given learner is usually claimed through a performance comparison with other learners over a collection of data sets. Too often, researchers are not aware of the impact of their data selection on the results. Their test beds are small, and the selection of the data sets is not supported by any previous data analysis. Conclusions drawn on such test beds cannot be generalised, because particular data characteristics may favour certain learners unnoticeably. This work raises these issues and proposes the characterisation of data sets using complexity measures, which can be helpful for both guiding experimental design and explaining the behaviour of learners.},
  keywords = {Data complexity,Learner assessment,Supervised learning}
}

@inproceedings{maheshwari2022AutoencoderIssuesChallenges,
  title = {Autoencoder: {{Issues}}, {{Challenges}} and {{Future Prospect}}},
  shorttitle = {Autoencoder},
  booktitle = {Recent {{Innovations}} in {{Mechanical Engineering}}},
  author = {Maheshwari, Anega and Mitra, Priyanka and Sharma, Bhavna},
  editor = {Vashista, Meghanshu and Manik, Gaurav and Verma, Om Prakash and Bhardwaj, Bhuvnesh},
  date = {2022},
  series = {Lecture {{Notes}} in {{Mechanical Engineering}}},
  pages = {257--266},
  publisher = {{Springer}},
  location = {{Singapore}},
  doi = {10.1007/978-981-16-9236-9_24},
  abstract = {As of more recently, deep learning-based models have demonstrated considerable potential, as they have outperformed all traditional practices. When data becomes high dimensional, extraction of features and compression of data become progressively significant. In this paper, we describe the autoencoder deep learning algorithm. Autoencoder is primarily a neural network-based feature extraction methodology that accomplishes outstanding victory in producing highlights of high-dimensional data. Autoencoder assumes a principal job in unsupervised learning which targets to rework inputs into outputs with minimal reconstruction error.},
  isbn = {9789811692369},
  langid = {english},
  keywords = {Autoencoder,Convolutional autoencoder,Denoising autoencoder,Unsupervised learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ST8MWZUW\\Maheshwari et al_2022_Autoencoder.pdf}
}

@inproceedings{mannino2019ThisRealGenerating,
  title = {Is This {{Real}}?: {{Generating Synthetic Data}} That {{Looks Real}}},
  shorttitle = {Is This {{Real}}?},
  booktitle = {Proceedings of the 32nd {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Mannino, Miro and Abouzied, Azza},
  date = {2019-10-17},
  pages = {549--561},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3332165.3347866},
  url = {https://dl.acm.org/doi/10.1145/3332165.3347866},
  urldate = {2022-06-30},
  eventtitle = {{{UIST}} '19: {{The}} 32nd {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-6816-2},
  langid = {english}
}

@online{martirosRiffusion,
  title = {Riffusion},
  author = {Martiros, Seth Forsgren {and} Hayk},
  url = {http://www.riffusion.},
  urldate = {2023-02-13},
  abstract = {Stable diffusion for real-time music generation},
  organization = {{Riffusion}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\3L9NMTAH\\www.riffusion.com.html}
}

@inproceedings{mckeever2020SynthesisingTabularDatasets,
  title = {Synthesising {{Tabular Datasets Using Wasserstein Conditional GANS}} with {{Gradient Penalty}} ({{WCGAN-GP}})},
  author = {McKeever, Susan and Walia, Manhar Singh and Tierney, Brendan},
  date = {2020},
  series = {{{CEUR Workshop Proceedings}}},
  volume = {2771},
  pages = {325--336},
  publisher = {{Technological University Dublin}},
  doi = {10.21427/E6WA-SZ92},
  url = {https://arrow.tudublin.ie/scschcomcon/285/},
  urldate = {2022-08-08},
  keywords = {01,conditional GAN,gan,mixed data,tabular,wasserstein,Wasserstein GAN},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\USK7AN8A\\Walia et al_2020_Synthesising tabular data using wasserstein conditional gans with gradient.pdf}
}

@inproceedings{mikolov2013DistributedRepresentationsWords,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  date = {2013},
  volume = {26},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html},
  urldate = {2023-02-09},
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships.  In this paper we present several improvements that make the Skip-gram model more expressive and enable it to learn higher quality vectors more rapidly.  We show that by subsampling frequent words we obtain significant speedup,  and also learn higher quality representations as measured by our tasks. We also introduce Negative Sampling, a simplified variant of Noise Contrastive Estimation (NCE) that learns more accurate vectors for frequent words compared to the hierarchical softmax.   An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases.  For example, the meanings of Canada'' and "Air'' cannot be easily combined to obtain "Air Canada''.  Motivated by this example, we present a simple and efficient method for finding phrases, and show that their vector representations can be accurately learned by the Skip-gram model. "},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\YLE9UQ2M\\Mikolov et al_2013_Distributed Representations of Words and Phrases and their Compositionality.pdf}
}

@online{mirza2014ConditionalGenerativeAdversarial,
  title = {Conditional {{Generative Adversarial Nets}}},
  author = {Mirza, Mehdi and Osindero, Simon},
  date = {2014-11-06},
  number = {arXiv:1411.1784},
  eprint = {arXiv:1411.1784},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1411.1784},
  urldate = {2023-01-09},
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\23DSAX7E\\Mirza_Osindero_2014_Conditional Generative Adversarial Nets.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\J38UGWED\\1411.html}
}

@online{mottini2018AirlinePassengerName,
  title = {Airline {{Passenger Name Record Generation}} Using {{Generative Adversarial Networks}}},
  author = {Mottini, Alejandro and Lheritier, Alix and Acuna-Agost, Rodrigo},
  date = {2018-07-17},
  number = {arXiv:1807.06657},
  eprint = {arXiv:1807.06657},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1807.06657},
  url = {http://arxiv.org/abs/1807.06657},
  urldate = {2022-07-16},
  abstract = {Passenger Name Records (PNRs) are at the heart of the travel industry. Created when an itinerary is booked, they contain travel and passenger information. It is usual for airlines and other actors in the industry to inter-exchange and access each other's PNR, creating the challenge of using them without infringing data ownership laws. To address this difficulty, we propose a method to generate realistic synthetic PNRs using Generative Adversarial Networks (GANs). Unlike other GAN applications, PNRs consist of categorical and numerical features with missing/NaN values, which makes the use of GANs challenging. We propose a solution based on Cram\textbackslash '\{e\}r GANs, categorical feature embedding and a Cross-Net architecture. The method was tested on a real PNR dataset, and evaluated in terms of distribution matching, memorization, and performance of predictive models for two real business problems: client segmentation and passenger nationality prediction. Results show that the generated data matches well with the real PNRs without memorizing them, and that it can be used to train models for real business applications.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\E4UI5CNW\\Mottini et al_2018_Airline Passenger Name Record Generation using Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\HDT6ENBQ\\1807.html}
}

@article{mozo2022SyntheticFlowbasedCryptomining,
  title = {Synthetic Flow-Based Cryptomining Attack Generation through {{Generative Adversarial Networks}}},
  author = {Mozo, Alberto and González-Prieto, Ángel and Pastor, Antonio and Gómez-Canaval, Sandra and Talavera, Edgar},
  date = {2022-12},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {12},
  number = {1},
  pages = {2091},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-06057-2},
  url = {https://www.nature.com/articles/s41598-022-06057-2},
  urldate = {2022-07-10},
  abstract = {Abstract             Due to the growing rise of cyber attacks in the Internet, the demand of accurate intrusion detection systems (IDS) to prevent these vulnerabilities is increasing. To this aim, Machine Learning (ML) components have been proposed as an efficient and effective solution. However, its applicability scope is limited by two important issues: (i) the shortage of network traffic data datasets for attack analysis, and (ii) the data privacy constraints of the data to be used. To overcome these problems, Generative Adversarial Networks (GANs) have been proposed for synthetic flow-based network traffic generation. However, due to the ill-convergence of the GAN training, none of the existing solutions can generate high-quality fully synthetic data that can totally substitute real data in the training of ML components. In contrast, they mix real with synthetic data, which acts only as data augmentation components, leading to privacy breaches as real data is used. In sharp contrast, in this work we propose a novel and deterministic way to measure the quality of the synthetic data produced by a GAN both with respect to the real data and to its performance when used for ML tasks. As a by-product, we present a heuristic that uses these metrics for selecting the best performing generator during GAN training, leading to a novel stopping criterion, which can be applied even when different types of synthetic data are to be used in the same ML task. We demonstrate the adequacy of our proposal by generating synthetic cryptomining attacks and normal traffic flow-based data using an enhanced version of a Wasserstein GAN. The results evidence that the generated synthetic network traffic can completely replace real data when training a ML-based cryptomining detector, obtaining similar performance and avoiding privacy violations, since real data is not used in the training of the ML-based detector.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\U5NXGP33\\Mozo et al_2022_Synthetic flow-based cryptomining attack generation through Generative.pdf}
}

@article{navidan2021GenerativeAdversarialNetworks,
  title = {Generative {{Adversarial Networks}} ({{GANs}}) in Networking: {{A}} Comprehensive Survey \& Evaluation},
  shorttitle = {Generative {{Adversarial Networks}} ({{GANs}}) in Networking},
  author = {Navidan, Hojjat and Moshiri, Parisa Fard and Nabati, Mohammad and Shahbazian, Reza and Ghorashi, Seyed Ali and Shah-Mansouri, Vahid and Windridge, David},
  date = {2021-07},
  journaltitle = {Computer Networks},
  shortjournal = {Computer Networks},
  volume = {194},
  pages = {108149},
  issn = {13891286},
  doi = {10.1016/j.comnet.2021.108149},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1389128621002139},
  urldate = {2022-07-10},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\HG3DZMYS\\Navidan et al_2021_Generative Adversarial Networks (GANs) in networking.pdf}
}

@misc{neunhoeffer2021PrivatePostGANBoostinga,
  title = {Private {{Post-GAN Boosting}}},
  author = {Neunhoeffer, Marcel and Wu, Zhiwei Steven and Dwork, Cynthia},
  date = {2021-03-25},
  number = {arXiv:2007.11934},
  eprint = {2007.11934},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2007.11934},
  url = {http://arxiv.org/abs/2007.11934},
  urldate = {2022-07-10},
  abstract = {Differentially private GANs have proven to be a promising approach for generating realistic synthetic data without compromising the privacy of individuals. Due to the privacy-protective noise introduced in the training, the convergence of GANs becomes even more elusive, which often leads to poor utility in the output generator at the end of training. We propose Private post-GAN boosting (Private PGB), a differentially private method that combines samples produced by the sequence of generators obtained during GAN training to create a high-quality synthetic dataset. To that end, our method leverages the Private Multiplicative Weights method (Hardt and Rothblum, 2010) to reweight generated samples. We evaluate Private PGB on two dimensional toy data, MNIST images, US Census data and a standard machine learning prediction task. Our experiments show that Private PGB improves upon a standard private GAN approach across a collection of quality measures. We also provide a non-private variant of PGB that improves the data quality of standard GAN training.},
  keywords = {02,Computer Science - Computers and Society,Computer Science - Cryptography and Security,Computer Science - Machine Learning,dp,gan,Private PGB,Private post-GAN,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\TXWJ3MBP\\Neunhoeffer et al_2021_Private Post-GAN Boosting.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\82JML3PN\\2007.html}
}

@online{nichol2021ImprovedDenoisingDiffusion,
  title = {Improved {{Denoising Diffusion Probabilistic Models}}},
  author = {Nichol, Alex and Dhariwal, Prafulla},
  date = {2021-02-18},
  number = {arXiv:2102.09672},
  eprint = {arXiv:2102.09672},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2102.09672},
  urldate = {2023-01-10},
  abstract = {Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code at https://github.com/openai/improved-diffusion},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\CTS6BVTY\\Nichol und Dhariwal - 2021 - Improved Denoising Diffusion Probabilistic Models.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\FIBUABX8\\Nichol_Dhariwal_2021_Improved Denoising Diffusion Probabilistic Models.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\84UJT73N\\2102.html}
}

@incollection{nikolenko2021SyntheticDataOutsidea,
  title = {Synthetic {{Data Outside Computer Vision}}},
  booktitle = {Synthetic {{Data}} for {{Deep Learning}}},
  author = {Nikolenko, Sergey I.},
  editor = {Nikolenko, Sergey I.},
  date = {2021},
  series = {Springer {{Optimization}} and {{Its Applications}}},
  pages = {217--226},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-75178-4_8},
  url = {https://doi.org/10.1007/978-3-030-75178-4_8},
  urldate = {2022-07-10},
  abstract = {While computer vision remains the main focus of synthetic data applications, other fields also begin to use synthetic datasets, with some directions entirely dependent on synthetic data. In this chapter, we survey some of these fields. Specifically, Section 8.1 discusses how structured synthetic data is used for fraud and intrusion detection and other applications in the form of network and/or system logs; in Section 8.2, we consider neural programming; Section 8.3 discusses synthetic data generation and use in bioinformatics, and Section 8.4 reviews the (admittedly limited) applications of synthetic data in natural language processing.},
  isbn = {978-3-030-75178-4},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ZMJ87YD3\\Nikolenko_2021_Synthetic Data Outside Computer Vision.pdf}
}

@inproceedings{NIPS2014_5ca3e9b1,
  title = {Generative Adversarial Nets},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K.Q.},
  date = {2014},
  volume = {27},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}
}

@article{niu2021ReviewAttentionMechanism,
  title = {A Review on the Attention Mechanism of Deep Learning},
  author = {Niu, Zhaoyang and Zhong, Guoqiang and Yu, Hui},
  date = {2021-09},
  journaltitle = {Neurocomputing},
  shortjournal = {Neurocomputing},
  volume = {452},
  pages = {48--62},
  issn = {09252312},
  doi = {10.1016/j.neucom.2021.03.091},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S092523122100477X},
  urldate = {2023-02-15},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\Z7AJLKFP\\Niu et al_2021_A review on the attention mechanism of deep learning.pdf}
}

@misc{obrien2018EvaluatingGenerativeAdversariala,
  title = {Evaluating {{Generative Adversarial Networks}} on {{Explicitly Parameterized Distributions}}},
  author = {O'Brien, Shayne and Groh, Matt and Dubey, Abhimanyu},
  date = {2018-12-27},
  number = {arXiv:1812.10782},
  eprint = {1812.10782},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1812.10782},
  url = {http://arxiv.org/abs/1812.10782},
  urldate = {2022-07-10},
  abstract = {The true distribution parameterizations of commonly used image datasets are inaccessible. Rather than designing metrics for feature spaces with unknown characteristics, we propose to measure GAN performance by evaluating on explicitly parameterized, synthetic data distributions. As a case study, we examine the performance of 16 GAN variants on six multivariate distributions of varying dimensionalities and training set sizes. In this learning environment, we observe that: GANs exhibit similar performance trends across dimensionalities; learning depends on the underlying distribution and its complexity; the number of training samples can have a large impact on performance; evaluation and relative comparisons are metric-dependent; diverse sets of hyperparameters can produce a "best" result; and some GANs are more robust to hyperparameter changes than others. These observations both corroborate findings of previous GAN evaluation studies and make novel contributions regarding the relationship between size, complexity, and GAN performance.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\UX7CDZJ3\\O'Brien et al_2018_Evaluating Generative Adversarial Networks on Explicitly Parameterized.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\PZ8XFGHS\\1812.html}
}

@inproceedings{optuna_2019,
  title = {Optuna: {{A}} next-Generation Hyperparameter Optimization Framework},
  booktitle = {Proceedings of the 25th {{ACM SIGKDD}} International Conference on Knowledge Discovery and Data Mining},
  author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  date = {2019}
}

@video{outlier2022DiffusionModelsPaper,
  title = {Diffusion {{Models}} | {{Paper Explanation}} | {{Math Explained}}},
  editor = {{Outlier}},
  date = {2022-06-06},
  url = {https://www.youtube.com/watch?v=HoKDTa5jHvg},
  urldate = {2023-01-16},
  editortype = {director}
}

@inproceedings{padhi2021TabularTransformersModeling,
  title = {Tabular {{Transformers}} for {{Modeling Multivariate Time Series}}},
  booktitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Padhi, Inkit and Schiff, Yair and Melnyk, Igor and Rigotti, Mattia and Mroueh, Youssef and Dognin, Pierre and Ross, Jerret and Nair, Ravi and Altman, Erik},
  date = {2021-06-06},
  pages = {3565--3569},
  publisher = {{IEEE}},
  location = {{Toronto, ON, Canada}},
  doi = {10.1109/ICASSP39728.2021.9414142},
  url = {https://ieeexplore.ieee.org/document/9414142/},
  urldate = {2022-08-09},
  eventtitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-72817-605-5},
  keywords = {01,Atmospheric modeling,BERT,Bit error rate,Data models,Feature extraction,GPT,Quantization (signal),tabular data,Tabular time series,Time series analysis,Training,Transformer},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\RH6GC4FM\\Padhi et al_2021_Tabular transformers for modeling multivariate time series.pdf}
}

@article{park2018DataSynthesisBased,
  title = {Data Synthesis Based on Generative Adversarial Networks},
  author = {Park, Noseong and Mohammadi, Mahmoud and Gorde, Kshitij and Jajodia, Sushil and Park, Hongkyu and Kim, Youngmin},
  date = {2018-06-01},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {11},
  number = {10},
  pages = {1071--1083},
  issn = {2150-8097},
  doi = {10.14778/3231751.3231757},
  url = {https://doi.org/10.14778/3231751.3231757},
  urldate = {2022-07-15},
  abstract = {Privacy is an important concern for our society where sharing data with partners or releasing data to the public is a frequent occurrence. Some of the techniques that are being used to achieve privacy are to remove identifiers, alter quasi-identifiers, and perturb values. Unfortunately, these approaches suffer from two limitations. First, it has been shown that private information can still be leaked if attackers possess some background knowledge or other information sources. Second, they do not take into account the adverse impact these methods will have on the utility of the released data. In this paper, we propose a method that meets both requirements. Our method, called table-GAN, uses generative adversarial networks (GANs) to synthesize fake tables that are statistically similar to the original table yet do not incur information leakage. We show that the machine learning models trained using our synthetic tables exhibit performance that is similar to that of models trained using the original table for unknown testing cases. We call this property model compatibility. We believe that anonymization/perturbation/synthesis methods without model compatibility are of little value. We used four real-world datasets from four different domains for our experiments and conducted indepth comparisons with state-of-the-art anonymization, perturbation, and generation techniques. Throughout our experiments, only our method consistently shows balance between privacy level and model compatibility.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\UD2JU6BE\\Park et al_2018_Data synthesis based on generative adversarial networks.pdf}
}

@online{patil2022StableDiffusionDiffusers,
  title = {Stable {{Diffusion}} with {{Diffusers}}},
  author = {Patil, Suraj and Cuenca, Pedro and Lambert, Nathan and von Platen, Patrick},
  options = {useprefix=true},
  date = {2022-08-22},
  url = {https://huggingface.co/blog/stable_diffusion},
  urldate = {2023-01-16},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\K59T58DR\\stable_diffusion.html}
}

@inproceedings{pei2022RequirementsEngineeringMachine,
  title = {Requirements {{Engineering}} for {{Machine Learning}}: {{A Review}} and {{Reflection}}},
  shorttitle = {Requirements {{Engineering}} for {{Machine Learning}}},
  booktitle = {2022 {{IEEE}} 30th {{International Requirements Engineering Conference Workshops}} ({{REW}})},
  author = {Pei, Zhongyi and Liu, Lin and Wang, Chen and Wang, Jianmin},
  date = {2022-08},
  pages = {166--175},
  publisher = {{IEEE}},
  location = {{Melbourne, Australia}},
  doi = {10.1109/REW56159.2022.00039},
  url = {https://ieeexplore.ieee.org/document/9920140/},
  urldate = {2023-03-06},
  abstract = {Today, many industrial processes are undergoing digital transformation, which often requires the integration of well-understood domain models and state-of-the-art machine learning technology in business processes. However, requirements elicitation and design decision making about when, where and how to embed various domain models and end-to-end machine learning techniques properly into a given business workflow requires further exploration. This paper aims to provide an overview of the requirements engineering process for machine learning applications in terms of cross domain collaborations. We first review the literature on requirements engineering for machine learning, and then go through the collaborative requirements analysis process step-by-step. An example case of industrial data-driven intelligence applications is also discussed in relation to the aforementioned steps.},
  eventtitle = {2022 {{IEEE}} 30th {{International Requirements Engineering Conference Workshops}} ({{REW}})},
  isbn = {978-1-66546-000-2},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\I3ITVHZ6\\Pei et al. - 2022 - Requirements Engineering for Machine Learning A R.pdf}
}

@misc{pereira2021AnalysisDeploymentModelsa,
  title = {An {{Analysis}} of the {{Deployment}} of {{Models Trained}} on {{Private Tabular Synthetic Data}}: {{Unexpected Surprises}}},
  shorttitle = {An {{Analysis}} of the {{Deployment}} of {{Models Trained}} on {{Private Tabular Synthetic Data}}},
  author = {Pereira, Mayana and Kshirsagar, Meghana and Mukherjee, Sumit and Dodhia, Rahul and Ferres, Juan Lavista},
  date = {2021-06-15},
  number = {arXiv:2106.10241},
  eprint = {2106.10241},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2106.10241},
  url = {http://arxiv.org/abs/2106.10241},
  urldate = {2022-07-10},
  abstract = {Diferentially private (DP) synthetic datasets are a powerful approach for training machine learning models while respecting the privacy of individual data providers. The effect of DP on the fairness of the resulting trained models is not yet well understood. In this contribution, we systematically study the effects of differentially private synthetic data generation on classification. We analyze disparities in model utility and bias caused by the synthetic dataset, measured through algorithmic fairness metrics. Our first set of results show that although there seems to be a clear negative correlation between privacy and utility (the more private, the less accurate) across all data synthesizers we evaluated, more privacy does not necessarily imply more bias. Additionally, we assess the effects of utilizing synthetic datasets for model training and model evaluation. We show that results obtained on synthetic data can misestimate the actual model performance when it is deployed on real data. We hence advocate on the need for defining proper testing protocols in scenarios where differentially private synthetic datasets are utilized for model training and evaluation.},
  keywords = {✔️,02,Computer Science - Computers and Society,Computer Science - Machine Learning,Differential Privacy,DP,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\N69MR7VZ\\Pereira et al_2021_An Analysis of the Deployment of Models Trained on Private Tabular Synthetic.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\JXCSPTWB\\2106.html}
}

@article{perez2022DataAugmentationMultivariate,
  title = {Data Augmentation through Multivariate Scenario Forecasting in {{Data Centers}} Using {{Generative Adversarial Networks}}},
  author = {Pérez, Jaime and Arroba, Patricia and Moya, José M.},
  date = {2022-04-29},
  journaltitle = {Applied Intelligence},
  shortjournal = {Appl Intell},
  issn = {0924-669X, 1573-7497},
  doi = {10.1007/s10489-022-03557-6},
  url = {https://link.springer.com/10.1007/s10489-022-03557-6},
  urldate = {2022-07-10},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\GGPTXP9R\\Pérez et al_2022_Data augmentation through multivariate scenario forecasting in Data Centers.pdf}
}

@inproceedings{peters2018DissectingContextualWord,
  title = {Dissecting {{Contextual Word Embeddings}}: {{Architecture}} and {{Representation}}},
  shorttitle = {Dissecting {{Contextual Word Embeddings}}},
  booktitle = {Proceedings of the 2018 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Peters, Matthew E. and Neumann, Mark and Zettlemoyer, Luke and Yih, Wen-tau},
  date = {2018-10},
  pages = {1499--1509},
  publisher = {{Association for Computational Linguistics}},
  location = {{Brussels, Belgium}},
  doi = {10.18653/v1/D18-1179},
  url = {https://aclanthology.org/D18-1179},
  urldate = {2023-02-09},
  abstract = {Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) influences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated.},
  eventtitle = {{{EMNLP}} 2018},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\E86GY2MC\\Peters et al_2018_Dissecting Contextual Word Embeddings.pdf}
}

@article{pilaluisa2022ContextualWordEmbeddings,
  title = {Contextual Word Embeddings for Tabular Data Search and Integration},
  author = {Pilaluisa, José and Tomás, David and Navarro-Colorado, Borja and Mazón, Jose-Norberto},
  date = {2022-11-30},
  journaltitle = {Neural Computing and Applications},
  shortjournal = {Neural Comput \& Applic},
  issn = {1433-3058},
  doi = {10.1007/s00521-022-08066-8},
  url = {https://doi.org/10.1007/s00521-022-08066-8},
  urldate = {2023-02-09},
  abstract = {This paper presents a new approach to retrieve and further integrate tabular datasets (collections of rows and columns) using union and join operations. In this work, both processes were carried out using a similarity measure based on contextual word embeddings, which allows finding semantically similar tables and overcome the recall problem of lexical approaches based on string similarity. This work is the first attempt to use contextual word embeddings in the whole pipeline of table search and integration, including for the first time their use in the join operation. A comprehensive analysis of their performance was carried out on both retrieving and integrating tabular datasets, comparing them with context-free models. Column headings and cell values were used as contextual information and their impact on each task was evaluated. The results revealed that contextual models significantly outperform context-free models and a traditional weighting schema in ad hoc table retrieval. In the data integration task, contextual models also improved the results on union operation compared to context-free approaches.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\IGBHBNJH\\Pilaluisa et al_2022_Contextual word embeddings for tabular data search and integration.pdf}
}

@misc{pinceti2021SyntheticTimeSeriesLoada,
  title = {Synthetic {{Time-Series Load Data}} via {{Conditional Generative Adversarial Networks}}},
  author = {Pinceti, Andrea and Sankar, Lalitha and Kosut, Oliver},
  date = {2021-07-07},
  number = {arXiv:2107.03545},
  eprint = {2107.03545},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2107.03545},
  url = {http://arxiv.org/abs/2107.03545},
  urldate = {2022-07-10},
  abstract = {A framework for the generation of synthetic time-series transmission-level load data is presented. Conditional generative adversarial networks are used to learn the patterns of a real dataset of hourly-sampled week-long load profiles and generate unique synthetic profiles on demand, based on the season and type of load required. Extensive testing of the generative model is performed to verify that the synthetic data fully captures the characteristics of real loads and that it can be used for downstream power system and/or machine learning applications.},
  keywords = {Electrical Engineering and Systems Science - Systems and Control},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LPZJM5WM\\Pinceti et al_2021_Synthetic Time-Series Load Data via Conditional Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\Q9Z95BYP\\2107.html}
}

@article{plaut2018PrincipalSubspacesPrincipal,
  title = {From {{Principal Subspaces}} to {{Principal Components}} with {{Linear Autoencoders}}},
  author = {Plaut, E.},
  date = {2018-04-26},
  journaltitle = {ArXiv},
  url = {https://www.semanticscholar.org/paper/From-Principal-Subspaces-to-Principal-Components-Plaut/3d4dc879166e902ede476a079684b9f5b5143e13},
  urldate = {2023-02-16},
  abstract = {The autoencoder is an effective unsupervised learning model which is widely used in deep learning. It is well known that an autoencoder with a single fully-connected hidden layer, a linear activation function and a squared error cost function trains weights that span the same subspace as the one spanned by the principal component loading vectors, but that they are not identical to the loading vectors. In this paper, we show how to recover the loading vectors from the autoencoder weights.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\3I63QMCJ\\Plaut_2018_From Principal Subspaces to Principal Components with Linear Autoencoders.pdf}
}

@article{pollman2014MercuryBioaccumulationFactors,
  title = {Mercury Bioaccumulation Factors and Spurious Correlations},
  author = {Pollman, Curtis D. and Axelrad, Donald M.},
  date = {2014-10-15},
  journaltitle = {Science of The Total Environment},
  shortjournal = {Science of The Total Environment},
  volume = {496},
  pages = {vi-xii},
  issn = {0048-9697},
  doi = {10.1016/j.scitotenv.2014.07.050},
  url = {https://www.sciencedirect.com/science/article/pii/S0048969714010791},
  abstract = {While bioaccumulation factors (BAF) – the ratio of biota contaminant concentrations (Cbiota) to aqueous phase contaminant concentrations (Cw) – are useful in evaluating the accumulation of mercury (Hg) and other contaminants for various trophic levels in aquatic ecosystems, reduction of the underlying relationship between Cbiota and Cw to a single ratio (BAF) has inherent risks, including spurious correlation. Despite a long and rich history of remonstrations in the literature, several very recent publications evaluating Hg-related BAFs have suffered from false conclusions based on spurious correlation, and thus it seems that periodic reminders of the causes and risks of these errors are required. Herein we cite examples and explanations for unsupported conclusions from publications where authors using BAF-Cw relationships fail to recognize the underlying statistical significance (or lack thereof) of direct relationships between Cw and Cbiota. This fundamental error leads to other problems, including ascribing mechanistic significance (e.g., mechanisms related to biota contaminant uptake) to “inverse” BAF-Cw relationships that reflect nothing more than regressing the log transformed inverse of Cw (i.e., negative log) against itself (i.e., positive log transformed), and using such regression models of BAF-Cw relationships that appear significant for predictive purposes, but are misleading. Spurious correlation arising in the analysis of BAF relationships can potentially appear in more subtle forms as well, including regressing variables such as dissolved organic carbon (DOC) that are correlated with Cw. We conclude that conducting a direct analysis by examining the relationship between Cbiota and Cw (or Cbiota and other variables) rather than evaluating a ratio (BAF) is less ambiguous and subject to error, more easily interpreted, and would lead to more supportable conclusions.},
  keywords = {Aquatic ecosystems,Everglades,Methylmercury,Synthetic data}
}

@inproceedings{prokhorenkova2018CatBoostUnbiasedBoosting,
  title = {{{CatBoost}}: Unbiased Boosting with Categorical Features},
  shorttitle = {{{CatBoost}}},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
  date = {2018-12-03},
  series = {{{NIPS}}'18},
  pages = {6639--6649},
  publisher = {{Curran Associates Inc.}},
  location = {{Red Hook, NY, USA}},
  abstract = {This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\I7ZC93LI\\Prokhorenkova et al_2018_CatBoost.pdf}
}

@online{QuantileTransformer,
  title = {{{QuantileTransformer}}},
  url = {https://scikit-learn/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html},
  urldate = {2023-03-22},
  abstract = {Examples using sklearn.preprocessing.QuantileTransformer: Partial Dependence and Individual Conditional Expectation Plots Partial Dependence and Individual Conditional Expectation Plots Effect of t...},
  langid = {english},
  organization = {{scikit-learn}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\87PY4FMD\\sklearn.preprocessing.QuantileTransformer.html}
}

@article{radfordImprovingLanguageUnderstanding,
  title = {Improving {{Language Understanding}} by {{Generative Pre-Training}}},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\HCL63R74\\Radford et al. - Improving Language Understanding by Generative Pre.pdf}
}

@inproceedings{rajabi2021FairnessAIAddressinga,
  title = {Towards {{Fairness}} in {{AI}}: {{Addressing Bias}} in {{Data Using GANs}}},
  shorttitle = {Towards {{Fairness}} in {{AI}}},
  booktitle = {{{HCI International}} 2021 - {{Late Breaking Papers}}: {{Multimodality}}, {{eXtended Reality}}, and {{Artificial Intelligence}}},
  author = {Rajabi, Amirarsalan and Garibay, Ozlem O.},
  editor = {Stephanidis, Constantine and Kurosu, Masaaki and Chen, Jessie Y. C. and Fragomeni, Gino and Streitz, Norbert and Konomi, Shin'ichi and Degen, Helmut and Ntoa, Stavroula},
  date = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {509--518},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-90963-5_39},
  abstract = {Can we trust machine learning models to make fair decisions? This question becomes more relevant as these algorithms become more pervasive in many aspects of our lives and our society. While the main objective of artificial intelligence (AI) algorithms is traditionally to increase accuracy, the AI community is gradually focusing more on evaluating and developing algorithms to ensure fairness. This work explores the usefulness of adversarial learning, explicitly generative adversarial networks (GAN), in addressing the problem of fairness. We show that the proposed model is able to produce synthetic tabular data to augment the original dataset in order to improve demographic parity, while maintaining data utility. In doing so, our work increases algorithmic fairness while maintaining accuracy.},
  isbn = {978-3-030-90963-5},
  langid = {english},
  keywords = {03,Artificial intelligence,Bias,Fairness,gan,Generative adversarial network,wasserstein},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FNJXQHZN\\Rajabi_Garibay_2021_Towards Fairness in AI.pdf}
}

@misc{rajabi2021TabFairGANFairTabulara,
  title = {{{TabFairGAN}}: {{Fair Tabular Data Generation}} with {{Generative Adversarial Networks}}},
  shorttitle = {{{TabFairGAN}}},
  author = {Rajabi, Amirarsalan and Garibay, Ozlem Ozmen},
  date = {2021-09-01},
  number = {arXiv:2109.00666},
  eprint = {2109.00666},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2109.00666},
  url = {http://arxiv.org/abs/2109.00666},
  urldate = {2022-07-10},
  abstract = {With the increasing reliance on automated decision making, the issue of algorithmic fairness has gained increasing importance. In this paper, we propose a Generative Adversarial Network for tabular data generation. The model includes two phases of training. In the first phase, the model is trained to accurately generate synthetic data similar to the reference dataset. In the second phase we modify the value function to add fairness constraint, and continue training the network to generate data that is both accurate and fair. We test our results in both cases of unconstrained, and constrained fair data generation. In the unconstrained case, i.e. when the model is only trained in the first phase and is only meant to generate accurate data following the same joint probability distribution of the real data, the results show that the model beats state-of-the-art GANs proposed in the literature to produce synthetic tabular data. Also, in the constrained case in which the first phase of training is followed by the second phase, we train the network and test it on four datasets studied in the fairness literature and compare our results with another state-of-the-art pre-processing method, and present the promising results that it achieves. Comparing to other studies utilizing GANs for fair data generation, our model is comparably more stable by using only one critic, and also by avoiding major problems of original GAN model, such as mode-dropping and non-convergence, by implementing a Wasserstein GAN.},
  keywords = {01,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,gan,tabular data,wasserstein},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\XDZSGA44\\Rajabi_Garibay_2021_TabFairGAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\DMR55GQY\\2109.html}
}

@article{RAY2020106679,
  title = {A Framework for Probabilistic Model-Based Engineering and Data Synthesis},
  author = {Ray, Douglas and Ramirez-Marquez, Jose},
  date = {2020},
  journaltitle = {Reliability Engineering \& System Safety},
  volume = {193},
  pages = {106679},
  issn = {0951-8320},
  doi = {10.1016/j.ress.2019.106679},
  url = {https://www.sciencedirect.com/science/article/pii/S0951832018312754},
  abstract = {Modern computing resources provide scientists, engineers, and system design teams the ability to study phenomena, such as system behavior, in a virtual setting. Computational modeling and simulation (M\&S) enables engineers to avoid many of the challenges encountered in traditional design engineering, including the design, manufacture, and testing of expensive prototypes prior to having an optimized design. However, the use of M\&S carries its own challenges, such as the computational time and resources required to execute effective studies, and uncertainties arising from simplifying assumptions inherent to computer models, which are intended to be an approximate representation of reality. In recent year advances have been made in a number of areas related to the efficient and reliable use of M\&S for system evaluations, including design \& analysis of computer experiments, uncertainty quantification, probabilistic analysis, response optimization, and data synthesis techniques. In this review paper, a general framework for systematically executing efficient M\&S studies at the component-level, product-level, system-level, and system-of-systems-level is described. A case study is used to demonstrate how statistical and probabilistic techniques can be integrated with M\&S to address those challenges inherent to model-based engineering, and how this aligns with the proposed workflow. The example is a gun-launch dynamics model of an artillery projectile developed by US Army engineers, and illustrates the application of this workflow in the study of subsystem system reliability, performance, and end-to-end system-level characterization.},
  keywords = {Calibration,Design of experiments (DOE),Deterministic computer experiments,Modeling and Simulation (M&S),Probabilistic optimization,Sensitivity analysis,Space filling designs,Statistical engineering,Trade space,Uncertainty Quantification (UQ),Validation,Verification}
}

@misc{razghandi2022VariationalAutoencoderGenerativea,
  title = {Variational {{Autoencoder Generative Adversarial Network}} for {{Synthetic Data Generation}} in {{Smart Home}}},
  author = {Razghandi, Mina and Zhou, Hao and Erol-Kantarci, Melike and Turgut, Damla},
  date = {2022-01-18},
  number = {arXiv:2201.07387},
  eprint = {2201.07387},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2201.07387},
  url = {http://arxiv.org/abs/2201.07387},
  urldate = {2022-07-10},
  abstract = {Data is the fuel of data science and machine learning techniques for smart grid applications, similar to many other fields. However, the availability of data can be an issue due to privacy concerns, data size, data quality, and so on. To this end, in this paper, we propose a Variational AutoEncoder Generative Adversarial Network (VAE-GAN) as a smart grid data generative model which is capable of learning various types of data distributions and generating plausible samples from the same distribution without performing any prior analysis on the data before the training phase.We compared the Kullback-Leibler (KL) divergence, maximum mean discrepancy (MMD), and Wasserstein distance between the synthetic data (electrical load and PV production) distribution generated by the proposed model, vanilla GAN network, and the real data distribution, to evaluate the performance of our model. Furthermore, we used five key statistical parameters to describe the smart grid data distribution and compared them between synthetic data generated by both models and real data. Experiments indicate that the proposed synthetic data generative model outperforms the vanilla GAN network. The distribution of VAE-GAN synthetic data is the most comparable to that of real data.},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\F6T6L2CR\\Razghandi et al_2022_Variational Autoencoder Generative Adversarial Network for Synthetic Data.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\FXYQE7QW\\2201.html}
}

@inproceedings{rombach2022HighResolutionImageSynthesis,
  title = {High-{{Resolution Image Synthesis}} with {{Latent Diffusion Models}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bjorn},
  date = {2022-06},
  pages = {10674--10685},
  publisher = {{IEEE}},
  location = {{New Orleans, LA, USA}},
  doi = {10.1109/CVPR52688.2022.01042},
  url = {https://ieeexplore.ieee.org/document/9878449/},
  urldate = {2023-03-02},
  abstract = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve new state of the art scores for image inpainting and class-conditional image synthesis and highly competitive performance on various tasks, including unconditional image generation, text-to-image synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs.},
  eventtitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66546-946-3},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JZF2GX5I\\Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffus.pdf}
}

@incollection{ronneberger2015UNetConvolutionalNetworks,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  booktitle = {Medical {{Image Computing}} and {{Computer-Assisted Intervention}} – {{MICCAI}} 2015},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
  date = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {9351},
  pages = {234--241},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-24574-4_28},
  url = {http://link.springer.com/10.1007/978-3-319-24574-4_28},
  urldate = {2023-01-16},
  isbn = {978-3-319-24573-7 978-3-319-24574-4},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\CINRJ8YB\\Ronneberger et al_2015_U-Net.pdf}
}

@article{rosenblatt1958PerceptronProbabilisticModel,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  shorttitle = {The Perceptron},
  author = {Rosenblatt, F.},
  date = {1958},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0042519},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
  urldate = {2023-02-14},
  langid = {english}
}

@incollection{rumelhart1986LearningInternalRepresentations,
  title = {Learning Internal Representations by Error Propagation},
  booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations},
  author = {Rumelhart, D. E. and Hinton, G. E. and Williams, R. J.},
  date = {1986-01-03},
  pages = {318--362},
  publisher = {{MIT Press}},
  location = {{Cambridge, MA, USA}},
  isbn = {978-0-262-68053-0}
}

@article{rumelhart1986LearningRepresentationsBackpropagating,
  title = {Learning Representations by Back-Propagating Errors},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  date = {1986-10},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/323533a0},
  url = {http://www.nature.com/articles/323533a0},
  urldate = {2023-02-14},
  langid = {english}
}

@inproceedings{saha2022EfficientApproachesDataa,
  title = {Efficient {{Approaches}} for {{Data Augmentation}} by {{Using Generative Adversarial Networks}}},
  booktitle = {Engineering {{Applications}} of {{Neural Networks}}},
  author = {Saha, Pretom Kumar and Logofatu, Doina},
  editor = {Iliadis, Lazaros and Jayne, Chrisina and Tefas, Anastasios and Pimenidis, Elias},
  date = {2022},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {386--399},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-031-08223-8_32},
  abstract = {In the present and future, data is the most valuable thing in the world. Therefore, it is now a challenge for everyone in every sector to work with data. Collecting data to predict or collecting data to analyze is a very valuable task. Moreover every new research, new machine learning method, and algorithms testing depends on a massive amount of different data. Furthermore, it is also a security issue for many fields to share actual data. It is always hard to find the perfect data set. It is not just about figuring out huge amounts of data. Many other data analysis processes need to be performed on that dataset to make it worthwhile. To overcome this problem, data augmentation is one of the suitable solutions. The idea behind data augmentation is to create a new dataset that depends on some existing dataset features. Generative Adversarial Networks (GANs) are a class of machine learning frameworks introduced by Ian Goodfellow in 2014. They are a game-like way to learn and generate new datasets. GANs have two parts, one is the generator, and the second is the discriminator. They play against each other to win the game. We will use our data set on the GAN model using some specific hyperparameter value and optimizer, which we will find out through our experiment. Finally, we will produce a CSV file with model-generated synthesis data and visualize the performance statistic of our model in the graph. This article will explain the different facts related to Data Augmentation, and GANs.},
  isbn = {978-3-031-08223-8},
  langid = {english},
  keywords = {Data augmentation,Generative Adversarial Networks,Tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JQGHJB5B\\Saha_Logofatu_2022_Efficient Approaches for Data Augmentation by Using Generative Adversarial.pdf}
}

@article{sardellitti2019GraphTopologyInference,
  title = {Graph {{Topology Inference Based}} on {{Sparsifying Transform Learning}}},
  author = {Sardellitti, Stefania and Barbarossa, Sergio and Lorenzo, Paolo Di},
  date = {2019-04-01},
  journaltitle = {IEEE Transactions on Signal Processing},
  shortjournal = {IEEE Trans. Signal Process.},
  volume = {67},
  number = {7},
  pages = {1712--1727},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2019.2896229},
  url = {https://ieeexplore.ieee.org/document/8629931/},
  urldate = {2022-07-10},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\2LBTPD4U\\Sardellitti et al_2019_Graph Topology Inference Based on Sparsifying Transform Learning.pdf}
}

@incollection{SCHAFFER202139,
  title = {Chapter 6 - {{Data}} Synthesis: {{Emerging}} Themes},
  booktitle = {Protecting and Promoting Client Rights},
  author = {Schaffer, Krystal},
  editor = {Schaffer, Krystal},
  date = {2021},
  pages = {39--50},
  publisher = {{Academic Press}},
  doi = {10.1016/B978-0-12-824426-5.00006-4},
  url = {https://www.sciencedirect.com/science/article/pii/B9780128244265000064},
  abstract = {This chapter outlines the method of data analysis employed and details the emerging themes, leading to identification of the final themes discussed later in the results chapter of this text book.},
  isbn = {978-0-12-824426-5},
  keywords = {04,and family law court principles,conditions and constraints,quantitative and mixed method studies,second-order themes,synthesis matrix tool,Systematic review of qualitative,third order themes:personal values,use of specialised knowledge}
}

@misc{schultz2022ConvexSpaceLearninga,
  title = {Convex Space Learning Improves Deep-Generative Oversampling for Tabular Imbalanced Classification on Smaller Datasets},
  author = {Schultz, Kristian and Bej, Saptarshi and Hahn, Waldemar and Wolfien, Markus and Srivastava, Prashant and Wolkenhauer, Olaf},
  date = {2022-06-20},
  number = {arXiv:2206.09812},
  eprint = {2206.09812},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2206.09812},
  url = {http://arxiv.org/abs/2206.09812},
  urldate = {2022-07-10},
  abstract = {Data is commonly stored in tabular format. Several fields of research (e.g., biomedical, fault/fraud detection), are prone to small imbalanced tabular data. Supervised Machine Learning on such data is often difficult due to class imbalance, adding further to the challenge. Synthetic data generation i.e. oversampling is a common remedy used to improve classifier performance. State-of-the-art linear interpolation approaches, such as LoRAS and ProWRAS can be used to generate synthetic samples from the convex space of the minority class to improve classifier performance in such cases. Generative Adversarial Networks (GANs) are common deep learning approaches for synthetic sample generation. Although GANs are widely used for synthetic image generation, their scope on tabular data in the context of imbalanced classification is not adequately explored. In this article, we show that existing deep generative models perform poorly compared to linear interpolation approaches generating synthetic samples from the convex space of the minority class, for imbalanced classification problems on tabular datasets of small size. We propose a deep generative model, ConvGeN combining the idea of convex space learning and deep generative models. ConVGeN learns the coefficients for the convex combinations of the minority class samples, such that the synthetic data is distinct enough from the majority class. We demonstrate that our proposed model ConvGeN improves imbalanced classification on such small datasets, as compared to existing deep generative models while being at par with the existing linear interpolation approaches. Moreover, we discuss how our model can be used for synthetic tabular data generation in general, even outside the scope of data imbalance, and thus, improves the overall applicability of convex space learning.},
  keywords = {03,Computer Science - Machine Learning,gans},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\GKWAAR4Q\\Schultz et al_2022_Convex space learning improves deep-generative oversampling for tabular.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\LTQIFJRM\\2206.html}
}

@article{scikit-learn,
  title = {Scikit-Learn: {{Machine}} Learning in {{Python}}},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  date = {2011},
  journaltitle = {Journal of Machine Learning Research},
  volume = {12},
  pages = {2825--2830}
}

@online{scikit-learnPreprocessingData,
  title = {6.3. {{Preprocessing}} Data},
  author = {Scikit-Learn},
  url = {https://scikit-learn/stable/modules/preprocessing.html},
  urldate = {2023-02-13},
  abstract = {The sklearn.preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream esti...},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\KFWA3FY5\\preprocessing.html}
}

@misc{seyfi2022GroupGANa,
  title = {Group {{GAN}}},
  author = {Seyfi, Ali and Rajotte, Jean-Francois and Ng, Raymond T.},
  date = {2022-05-26},
  number = {arXiv:2205.13741},
  eprint = {2205.13741},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.13741},
  url = {http://arxiv.org/abs/2205.13741},
  urldate = {2022-07-10},
  abstract = {Generating multivariate time series is a promising approach for sharing sensitive data in many medical, financial, and IoT applications. A common type of multivariate time series originates from a single source such as the biometric measurements from a medical patient. This leads to complex dynamical patterns between individual time series that are hard to learn by typical generation models such as GANs. There is valuable information in those patterns that machine learning models can use to better classify, predict or perform other downstream tasks. We propose a novel framework that takes time series' common origin into account and favors inter-channel relationship preservation. The two key points of our method are: 1) the individual time series are generated from a common point in latent space and 2) a central discriminator favors the preservation of inter-channel dynamics. We demonstrate empirically that our method helps preserve channel correlations and that our synthetic data performs very well downstream tasks with medical and financial data.},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\IRQYIC4I\\Seyfi et al_2022_Group GAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\98QXEDWE\\2205.html}
}

@article{Shafqat202211036,
  title = {A Hybrid {{GAN-Based}} Approach to Solve Imbalanced Data Problem in Recommendation Systems},
  author = {Shafqat, W. and Byun, Y.-C.},
  date = {2022},
  journaltitle = {IEEE access : practical innovations, open solutions},
  shortjournal = {IEEE Access},
  volume = {10},
  pages = {11036--11047},
  doi = {10.1109/ACCESS.2022.3141776},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123274801&doi=10.1109%2fACCESS.2022.3141776&partnerID=40&md5=330e9079712f5162d16675657cf362eb},
  abstract = {With the advent of information technology, the amount of online data generation has been massive. Recommendation systems have become an effective tool in filtering information and solving the problem of information overload. Machine learning algorithms to build these recommendation systems require well-balanced data in terms of class distribution, but real-world datasets are mostly imbalanced in nature. Imbalanced data imposes a classifier to focus more on the majority class, neglecting other classes of interests and thus hindering the predictive performance of any classification model. There exist many traditional techniques for oversampling minority classes. Still, generative adversarial networks (GAN) have been showing excellent results in generating realistic synthetic tabular data that keeps the probability distribution of the original data intact. In this paper, we propose a hybrid GAN approach to solve the data imbalance problem to enhance recommendation systems' performance. We implemented conditional Wasserstein GAN with gradient penalty to generate tabular data containing both numerical and categorical values. We also augmented auxiliary classifier loss to enforce the model to explicitly generate data belonging to the minority class. We designed the discriminator architecture with the concept of PacGAN to receive m-packed samples as input instead of a single input. This inclusion of the PacGAN architecture eliminated the mode collapse problem in our proposed model. We did a two-fold evaluation of our model. Firstly based on the quality of the generated data and secondly on how different recommendation models perform using the generated data compared to original data. © 2013 IEEE.},
  keywords = {✔️,02,categorical data,conditional GAN,Gan,no mode collapse,numeric data,PacGan,tabular data,wasserstein,Wasserstein GAN,WCGAN-GP-PacGAN},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\PNU7SDEG\\Shafqat_Byun_2022_A hybrid GAN-Based approach to solve imbalanced data problem in recommendation.pdf}
}

@article{sharafi2015StochasticOptimizationHybrid,
  title = {Stochastic Optimization of Hybrid Renewable Energy Systems Using Sampling Average Method},
  author = {Sharafi, Masoud and ElMekkawy, Tarek Y.},
  date = {2015-12-01},
  journaltitle = {Renewable and Sustainable Energy Reviews},
  shortjournal = {Renewable and Sustainable Energy Reviews},
  volume = {52},
  pages = {1668--1679},
  issn = {1364-0321},
  doi = {10.1016/j.rser.2015.08.010},
  url = {https://www.sciencedirect.com/science/article/pii/S1364032115008527},
  abstract = {The stochastic attribute of renewable energy sources and the variability of energy load is a preeminent barrier to design hybrid renewable energy systems. In this paper, a new methodology is advanced to incorporate the uncertainties associated with RE resources and load in sizing an HRES in the application of buildings with low to high renewable energy ratio (RER). Dynamic multi-objective particle swarm optimization (DMOPSO) algorithm, simulation module, and sampling average technique are used to approximate a Pareto front (PF) for an HRES design through a multi-objective optimization framework. The main aim of design is to simultaneously minimize total net present cost (NPC), maximize renewable energy ratio, and minimize fuel emission while satisfy a desirable level of loss of load probability (LLP). The existing randomness in wind speed, solar irradiation, ambient temperature, and energy load is considered using synthetically data generation and sampling average method. The performance of the model has been examined in a building located in Canada as the case study, in which RER of the building is increased by using renewable energy technologies. The generated PF by the stochastic approach is compared to a deterministic PF using well-known performance metrics. Finally, a sensitivity analysis is carried out where the economic characteristics of the model are varied.},
  keywords = {Hybrid renewable energy system,Near zero energy buildings,Stochastic multi-objective optimization}
}

@article{silva2014StatisticallyMotivatedFramework,
  title = {A Statistically Motivated Framework for Simulation of Stochastic Data Fusion Models Applied to Multimodal Neuroimaging},
  author = {Silva, Rogers F. and Plis, Sergey M. and Adalı, Tülay and Calhoun, Vince D.},
  date = {2014-11-15},
  journaltitle = {Multimodal Data Fusion},
  shortjournal = {NeuroImage},
  volume = {102},
  pages = {92--117},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2014.04.035},
  url = {https://www.sciencedirect.com/science/article/pii/S1053811914003048},
  abstract = {Multimodal fusion is becoming more common as it proves to be a powerful approach to identify complementary information from multimodal datasets. However, simulation of joint information is not straightforward. Published approaches mostly employ limited, provisional designs that often break the link between the model assumptions and the data for the sake of demonstrating properties of fusion techniques. This work introduces a new approach to synthetic data generation which allows full-compliance between data and model while still representing realistic spatiotemporal features in accordance with the current neuroimaging literature. The focus is on the simulation of joint information for the verification of stochastic linear models, particularly those used in multimodal data fusion of brain imaging data. Our first goal is to obtain a benchmark ground-truth in which estimation errors due to model mismatch are minimal or none. Then we move on to assess how estimation is affected by gradually increasing model discrepancies toward a more realistic dataset. The key aspect of our approach is that it permits complete control over the type and level of model mismatch, allowing for more educated inferences about the limitations and caveats of select stochastic linear models. As a result, impartial comparison of models is possible based on their performance in multiple different scenarios. Our proposed method uses the commonly overlooked theory of copulas to enable full control of the type and level of dependence/association between modalities, with no occurrence of spurious multimodal associations. Moreover, our approach allows for arbitrary single-modality marginal distributions for any fixed choice of dependence/association between multimodal features. Using our simulation framework, we can rigorously challenge the assumptions of several existing multimodal fusion approaches. Our study brings a new perspective to the problem of simulating multimodal data that can be used for ground-truth verification of various stochastic multimodal models available in the literature, and reveals some important aspects that are not captured or are overlooked by ad hoc simulations that lack a firm statistical motivation.},
  keywords = {Copula,Fusion,ICA,Multidimensional,Multimodal,Simulation,Stochastic}
}

@inproceedings{singh2021MeTGANMemoryEfficienta,
  title = {{{MeTGAN}}: {{Memory Efficient Tabular GAN}} for {{High Cardinality Categorical Datasets}}},
  shorttitle = {{{MeTGAN}}},
  booktitle = {Neural {{Information Processing}}},
  author = {Singh, Shreyansh and Kayathwal, Kanishka and Wadhwa, Hardik and Dhama, Gaurav},
  editor = {Mantoro, Teddy and Lee, Minho and Ayu, Media Anugerah and Wong, Kok Wai and Hidayanto, Achmad Nizar},
  date = {2021},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {519--527},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-92310-5_60},
  abstract = {Generative Adversarial Networks (GANs) have seen their use for generating synthetic data expand, from unstructured data like images to structured tabular data. One of the recently proposed models in the field of tabular data generation, CTGAN, demonstrated state-of-the-art performance on this task even in the presence of a high class imbalance in categorical columns or multiple modes in continuous columns. Many of the recently proposed methods have also derived ideas from CTGAN. However, training CTGAN requires a high memory footprint while dealing with high cardinality categorical columns in the dataset. In this paper, we propose MeTGAN, a memory-efficient version of CTGAN, which reduces memory usage by roughly 80\%, with a minimal effect on performance. MeTGAN uses sparse linear layers to overcome the memory bottlenecks of CTGAN. We compare the performance of MeTGAN with the other models on publicly available datasets. Quality of data generation, memory requirements, and the privacy guarantees of the models are the metrics considered in this study. The goal of this paper is also to draw the attention of the research community on the issue of the computational footprint of tabular data generation methods to enable them on larger datasets especially ones with high cardinality categorical variables.},
  isbn = {978-3-030-92310-5},
  langid = {english},
  keywords = {02,CTGAN,gan,Generative Adversarial Networks,MeTGAN,Privacy,Synthetic data generation,Tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\BJL73BSL\\Singh et al_2021_MeTGAN.pdf}
}

@article{skandarani2022GenerativeAdversarialNetworks,
  title = {Generative {{Adversarial Networks}} in {{Cardiology}}},
  author = {Skandarani, Youssef and Lalande, Alain and Afilalo, Jonathan and Jodoin, Pierre-Marc},
  date = {2022-02-01},
  journaltitle = {Canadian Journal of Cardiology},
  shortjournal = {Canadian Journal of Cardiology},
  volume = {38},
  number = {2},
  pages = {196--203},
  issn = {0828-282X},
  doi = {10.1016/j.cjca.2021.11.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0828282X21008606},
  abstract = {Generative adversarial networks (GANs) are state-of-the-art neural network models used to synthesise images and other data. GANs brought a considerable improvement to the quality of synthetic data, quickly becoming the standard for data-generation tasks. In this work, we summarise the applications of GANs in the field of cardiology, including generation of realistic cardiac images, electrocardiography signals, and synthetic electronic health records. The utility of GAN-generated data is discussed with respect to research, clinical care, and academia. And we present illustrative examples of our GAN-generated cardiac magnetic resonance and echocardiography images, showing the evolution in image quality across 6 different models, which have become almost indistinguishable from real images. Finally, we discuss future applications, such as modality translation or patient trajectory modelling. Moreover, we discuss the pending challenges that GANs need to overcome, namely, their training dynamics, the medical fidelity or the data regulations and ethics questions, to become integrated in cardiology workflows. Résumé Les réseaux antagonistes génératifs (RAG) sont des modèles de réseaux neuronaux de pointe utilisés pour synthétiser des images et d’autres données. Les RAG ont permis d’améliorer considérablement la qualité des données synthétiques, devenant ainsi rapidement la norme en matière de génération de données. Dans cet article, nous résumons les applications des RAG dans le domaine de la cardiologie, notamment la génération d’images cardiaques, de signaux d’électrocardiographie et de dossiers médicaux électroniques synthétiques réalistes. Nous abordons l’utilité des données fournies par les RAG sous l’angle de la recherche, des soins cliniques et des travaux universitaires. Nous présentons également des exemples d’images de résonance magnétique cardiaque et d’échocardiographie que nous avons obtenues au moyen de RAG pour illustrer l’évolution de la qualité des images à partir de six modèles différents, devenus quasiment impossibles à distinguer des images réelles. Enfin, nous abordons les applications futures, dont le transfert de modalités ou la modélisation de l'évolution de l'état clinique des patients. Par ailleurs, nous nous penchons sur certains aspects problématiques – à savoir la dynamique d’apprentissage, la fidélité médicale ou les questions de réglementation des données et d’éthique – auxquels il convient de remédier pour permettre l’intégration des RAG dans la pratique courante en cardiologie.}
}

@misc{smith2020ConditionalGANTimeseriesa,
  title = {Conditional {{GAN}} for Timeseries Generation},
  author = {Smith, Kaleb E. and Smith, Anthony O.},
  date = {2020-06-29},
  number = {arXiv:2006.16477},
  eprint = {2006.16477},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.16477},
  url = {http://arxiv.org/abs/2006.16477},
  urldate = {2022-07-10},
  abstract = {It is abundantly clear that time dependent data is a vital source of information in the world. The challenge has been for applications in machine learning to gain access to a considerable amount of quality data needed for algorithm development and analysis. Modeling synthetic data using a Generative Adversarial Network (GAN) has been at the heart of providing a viable solution. Our work focuses on one dimensional times series and explores the few shot approach, which is the ability of an algorithm to perform well with limited data. This work attempts to ease the frustration by proposing a new architecture, Time Series GAN (TSGAN), to model realistic time series data. We evaluate TSGAN on 70 data sets from a benchmark time series database. Our results demonstrate that TSGAN performs better than the competition both quantitatively using the Frechet Inception Score (FID) metric, and qualitatively when classification is used as the evaluation criteria.},
  keywords = {03,Computer Science - Machine Learning,gan,Statistics - Machine Learning,time series data,TSGAN},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FQQVIMPM\\Smith_Smith_2020_Conditional GAN for timeseries generation.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\TM7JWSQN\\2006.html}
}

@article{snoke2018GeneralSpecificUtility,
  title = {General and Specific Utility Measures for Synthetic Data},
  author = {Snoke, Joshua and Raab, Gillian M. and Nowok, Beata and Dibben, Chris and Slavkovic, Aleksandra},
  date = {2018-06},
  journaltitle = {Journal of the Royal Statistical Society. Series A: Statistics in Society},
  volume = {181},
  number = {3},
  pages = {663--688},
  issn = {0964-1998},
  doi = {10.1111/rssa.12358},
  url = {http://www.scopus.com/inward/record.url?scp=85043373928&partnerID=8YFLogxK},
  urldate = {2023-02-28},
  abstract = {Data holders can produce synthetic versions of data sets when concerns about potential disclosure restrict the availability of the original records. The paper is concerned with methods to judge whether such synthetic data have a distribution that is comparable with that of the original data: what we term general utility. We consider how general utility compares with specific utility: the similarity of results of analyses from the synthetic data and the original data. We adapt a previous general measure of data utility, the propensity score mean-squared error pMSE, to the specific case of synthetic data and derive its distribution for the case when the correct synthesis model is used to create the synthetic data. Our asymptotic results are confirmed by a simulation study. We also consider two specific utility measures, confidence interval overlap and standardized difference in summary statistics, which we compare with the general utility results. We present two contrasting examples of data syntheses: one illustrating synthetic data that is evaluated as being useful by both general and specific measures and the second where neither is the case. For the second case we show how the general utility measures can identify the deficiencies of the synthetic data and suggest how this can inform possible improvements to the synthesis method.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\GCJZRVCV\\Snoke et al_2018_General and specific utility measures for synthetic data.pdf}
}

@online{sohl-dickstein2015DeepUnsupervisedLearning,
  title = {Deep {{Unsupervised Learning}} Using {{Nonequilibrium Thermodynamics}}},
  author = {Sohl-Dickstein, Jascha and Weiss, Eric A. and Maheswaranathan, Niru and Ganguli, Surya},
  date = {2015-11-18},
  number = {arXiv:1503.03585},
  eprint = {arXiv:1503.03585},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1503.03585},
  urldate = {2023-01-09},
  abstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\XSPF2SXL\\Sohl-Dickstein et al_2015_Deep Unsupervised Learning using Nonequilibrium Thermodynamics.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\MSAD8SVX\\1503.html}
}

@article{solyman2021SyntheticDataNeural,
  title = {Synthetic Data with Neural Machine Translation for Automatic Correction in Arabic Grammar},
  author = {Solyman, Aiman and Zhenyu, Wang and Qian, Tao and Elhag, Arafat Abdulgader Mohammed and Toseef, Muhammad and Aleibeid, Zeinab},
  date = {2021-09-01},
  journaltitle = {Egyptian Informatics Journal},
  shortjournal = {Egyptian Informatics Journal},
  volume = {22},
  number = {3},
  pages = {303--315},
  issn = {1110-8665},
  doi = {10.1016/j.eij.2020.12.001},
  url = {https://www.sciencedirect.com/science/article/pii/S1110866520301602},
  abstract = {The automatic correction of grammar and spelling errors is important for students, second language learners, and some Natural Language Processing (NLP) tasks such as part of speech and text summarization. Recently, Neural Machine Translation (NMT) has been an out-performing and well-established model in the task of Grammar Error Correction (GEC). Arabic GEC is still growing because of some challenges, such as scarcity of training sets and the complexity of Arabic language. To overcome these issues, we introduced an unsupervised method to generate large-scale synthetic training data based on confusion function to increase the amount of training set. Furthermore, we introduced a supervised NMT model for AGEC called SCUT AGEC. SCUT AGEC is a convolutional sequence-to-sequence model consisting of nine encoder-decoder layers with attention mechanism. We applied fine-tuning to improve the performance and get more efficient results. Convolutional Neural Networks (CNN) gives our model ability to joint feature extraction and classification in one task and we proved that it is an efficient way to capture features of the local context. Moreover, it is easy to obtain long-term dependencies because of convolutional layers staking. Our proposed model becomes the first supervised AGEC system based on the convolutional sequence-to-sequence learning to outperforms the current state-of-the-art neural AGEC models.},
  keywords = {Arabic grammar error correction,Convolutional neural networks,Natural language processing}
}

@online{somepalli2021SAINTImprovedNeural,
  title = {{{SAINT}}: {{Improved Neural Networks}} for {{Tabular Data}} via {{Row Attention}} and {{Contrastive Pre-Training}}},
  shorttitle = {{{SAINT}}},
  author = {Somepalli, Gowthami and Goldblum, Micah and Schwarzschild, Avi and Bruss, C. Bayan and Goldstein, Tom},
  date = {2021-06-02},
  number = {arXiv:2106.01342},
  eprint = {arXiv:2106.01342},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2106.01342},
  urldate = {2023-01-31},
  abstract = {Tabular data underpins numerous high-impact applications of machine learning from fraud detection to genomics and healthcare. Classical approaches to solving tabular problems, such as gradient boosting and random forests, are widely used by practitioners. However, recent deep learning methods have achieved a degree of performance competitive with popular techniques. We devise a hybrid deep learning approach to solving tabular data problems. Our method, SAINT, performs attention over both rows and columns, and it includes an enhanced embedding method. We also study a new contrastive self-supervised pre-training method for use when labels are scarce. SAINT consistently improves performance over previous deep learning methods, and it even outperforms gradient boosting methods, including XGBoost, CatBoost, and LightGBM, on average over a variety of benchmark tasks.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\PAA4SD6E\\Somepalli et al_2021_SAINT.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\EVXMINDX\\2106.html}
}

@misc{srinivasan_time-series_2022,
  title = {Time-Series Transformer Generative Adversarial Networks},
  author = {Srinivasan, Padmanaba and Knottenbelt, William J.},
  date = {2022-05-23},
  eprint = {2205.11164},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.11164},
  url = {http://arxiv.org/abs/2205.11164},
  urldate = {2022-07-10},
  abstract = {Many real-world tasks are plagued by limitations on data: in some instances very little data is available and in others, data is protected by privacy enforcing regulations (e.g. GDPR). We consider limitations posed specifically on time-series data and present a model that can generate synthetic time-series which can be used in place of real data. A model that generates synthetic time-series data has two objectives: 1) to capture the stepwise conditional distribution of real sequences, and 2) to faithfully model the joint distribution of entire real sequences. Autoregressive models trained via maximum likelihood estimation can be used in a system where previous predictions are fed back in and used to predict future ones; in such models, errors can accrue over time. Furthermore, a plausible initial value is required making MLE based models not really generative. Many downstream tasks learn to model conditional distributions of the time-series, hence, synthetic data drawn from a generative model must satisfy 1) in addition to performing 2). We present TsT-GAN, a framework that capitalises on the Transformer architecture to satisfy the desiderata and compare its performance against five state-of-the-art models on five datasets and show that TsT-GAN achieves higher predictive performance on all datasets.},
  keywords = {Computer Science - Machine Learning}
}

@misc{srinivasan2022TimeseriesTransformerGenerativea,
  title = {Time-Series {{Transformer Generative Adversarial Networks}}},
  author = {Srinivasan, Padmanaba and Knottenbelt, William J.},
  date = {2022-05-23},
  number = {arXiv:2205.11164},
  eprint = {2205.11164},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.11164},
  url = {http://arxiv.org/abs/2205.11164},
  urldate = {2022-07-10},
  abstract = {Many real-world tasks are plagued by limitations on data: in some instances very little data is available and in others, data is protected by privacy enforcing regulations (e.g. GDPR). We consider limitations posed specifically on time-series data and present a model that can generate synthetic time-series which can be used in place of real data. A model that generates synthetic time-series data has two objectives: 1) to capture the stepwise conditional distribution of real sequences, and 2) to faithfully model the joint distribution of entire real sequences. Autoregressive models trained via maximum likelihood estimation can be used in a system where previous predictions are fed back in and used to predict future ones; in such models, errors can accrue over time. Furthermore, a plausible initial value is required making MLE based models not really generative. Many downstream tasks learn to model conditional distributions of the time-series, hence, synthetic data drawn from a generative model must satisfy 1) in addition to performing 2). We present TsT-GAN, a framework that capitalises on the Transformer architecture to satisfy the desiderata and compare its performance against five state-of-the-art models on five datasets and show that TsT-GAN achieves higher predictive performance on all datasets.},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\S5Z86G9Q\\Srinivasan_Knottenbelt_2022_Time-series Transformer Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\PLNH2XHJ\\2205.html}
}

@inproceedings{sun2019supertml,
  title = {Supertml: {{Two-dimensional}} Word Embedding for the Precognition on Structured Tabular Data},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF}} Conference on Computer Vision and Pattern Recognition Workshops},
  author = {Sun, Baohua and Yang, Lin and Zhang, Wenhan and Lin, Michael and Dong, Patrick and Young, Charles and Dong, Jason},
  date = {2019},
  pages = {0--0},
  added-at = {2021-04-25T01:24:46.000+0200},
  biburl = {https://www.bibsonomy.org/bibtex/29a03c0ecaacef712ea9d439084c2db40/becker},
  interhash = {58f776475c9d7d2c174aa0efb9943ec4},
  intrahash = {9a03c0ecaacef712ea9d439084c2db40},
  keywords = {citedby:scholar:count:6 citedby:scholar:timestamp:2021-4-24 cnn data network neural nn tabular},
  timestamp = {2021-05-07T05:03:32.000+0200}
}

@article{sun2020NewInterpretationsNormalization,
  title = {New {{Interpretations}} of {{Normalization Methods}} in {{Deep Learning}}},
  author = {Sun, Jiacheng and Cao, Xiangyong and Liang, Hanwen and Huang, Weiran and Chen, Zewei and Li, Zhenguo},
  date = {2020-04-03},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  shortjournal = {AAAI},
  volume = {34},
  number = {04},
  pages = {5875--5882},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v34i04.6046},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/6046},
  urldate = {2023-02-11},
  abstract = {In recent years, a variety of normalization methods have been proposed to help training neural networks, such as batch normalization (BN), layer normalization (LN), weight normalization (WN), group normalization (GN), etc. However, some necessary tools to analyze all these normalization methods are lacking. In this paper, we first propose a lemma to define some necessary tools. Then, we use these tools to make a deep analysis on popular normalization methods and obtain the following conclusions: 1) Most of the normalization methods can be interpreted in a unified framework, namely normalizing pre-activations or weights onto a sphere; 2) Since most of the existing normalization methods are scaling invariant, we can conduct optimization on a sphere with scaling symmetry removed, which can help to stabilize the training of network; 3) We prove that training with these normalization methods can make the norm of weights increase, which could cause adversarial vulnerability as it amplifies the attack. Finally, a series of experiments are conducted to verify these claims.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\5PGN788K\\Sun et al_2020_New Interpretations of Normalization Methods in Deep Learning.pdf}
}

@misc{sun2022ImprovingCorrelationCapturea,
  title = {Improving {{Correlation Capture}} in {{Generating Imbalanced Data}} Using {{Differentially Private Conditional GANs}}},
  author = {Sun, Chang and van Soest, Johan and Dumontier, Michel},
  options = {useprefix=true},
  date = {2022-06-28},
  number = {arXiv:2206.13787},
  eprint = {2206.13787},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2206.13787},
  url = {http://arxiv.org/abs/2206.13787},
  urldate = {2022-07-10},
  abstract = {Despite the remarkable success of Generative Adversarial Networks (GANs) on text, images, and videos, generating high-quality tabular data is still under development owing to some unique challenges such as capturing dependencies in imbalanced data, optimizing the quality of synthetic patient data while preserving privacy. In this paper, we propose DP-CGANS, a differentially private conditional GAN framework consisting of data transformation, sampling, conditioning, and networks training to generate realistic and privacy-preserving tabular data. DP-CGANS distinguishes categorical and continuous variables and transforms them to latent space separately. Then, we structure a conditional vector as an additional input to not only presents the minority class in the imbalanced data, but also capture the dependency between variables. We inject statistical noise to the gradients in the networking training process of DP-CGANS to provide a differential privacy guarantee. We extensively evaluate our model with state-of-the-art generative models on three public datasets and two real-world personal health datasets in terms of statistical similarity, machine learning performance, and privacy measurement. We demonstrate that our model outperforms other comparable models, especially in capturing dependency between variables. Finally, we present the balance between data utility and privacy in synthetic data generation considering the different data structure and characteristics of real-world datasets such as imbalance variables, abnormal distributions, and sparsity of data.},
  keywords = {02,categorical data,Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,conditional GAN,DP,DP-CGANS,E.0,gan,I.2,mixed data,numeric data,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\WWEQQ648\\Sun et al_2022_Improving Correlation Capture in Generating Imbalanced Data using.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\8YBNW6V7\\2206.html}
}

@book{SyntheticDataDeepa,
  title = {Synthetic {{Data}} for {{Deep Learning}}},
  url = {https://link.springer.com/book/10.1007/978-3-030-75178-4},
  urldate = {2022-07-10},
  abstract = {This first book about synthetic data highlights an important field in deep learning which is rapidly rising in popularity throughout machine learning.},
  langid = {english},
  keywords = {03},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\3ECH5R3X\\Synthetic Data for Deep Learning.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\NCNVCIRH\\978-3-030-75178-4.html}
}

@report{SystemsSoftwareEngineering,
  type = {standard},
  title = {Systems and Software Engineering - {{Systems}} and Software {{Quality Requirements}} and {{Evaluation}} ({{SQuaRE}}) - {{System}} and Software Quality Models},
  shorttitle = {{{ISO}}/{{IEC}} 25010},
  number = {ISO/IEC 25010:2011},
  institution = {{ISO}},
  url = {https://www.iso.org/standard/35733.html},
  urldate = {2023-03-06},
  abstract = {Systems and software engineering — Systems and software Quality Requirements and Evaluation (SQuaRE) — System and software quality models},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\G4ZNLLAZ\\35733.html}
}

@inproceedings{tashiro2021CSDIConditionalScorebased,
  title = {{{CSDI}}: {{Conditional Score-based Diffusion Models}} for {{Probabilistic Time Series Imputation}}},
  shorttitle = {{{CSDI}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Tashiro, Yusuke and Song, Jiaming and Song, Yang and Ermon, Stefano},
  date = {2021},
  volume = {34},
  pages = {24804--24816},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2021/hash/cfe8504bda37b575c70ee1a8276f3486-Abstract.html},
  urldate = {2023-03-03},
  abstract = {The imputation of missing values in time series has many applications in healthcare and finance. While autoregressive models are natural candidates for time series imputation, score-based diffusion models have recently outperformed existing counterparts including autoregressive models in many tasks such as image generation and audio synthesis, and would be promising for time series imputation. In this paper, we propose Conditional Score-based Diffusion model (CSDI), a novel time series imputation method that utilizes score-based diffusion models conditioned on observed data. Unlike existing score-based approaches, the conditional diffusion model is explicitly trained for imputation and can exploit correlations between observed values. On healthcare and environmental data, CSDI improves by 40-65\% over existing probabilistic imputation methods on popular performance metrics. In addition, deterministic imputation by CSDI reduces the error by 5-20\% compared to the state-of-the-art deterministic imputation methods. Furthermore, CSDI can also be applied to time series interpolation and probabilistic forecasting, and is competitive with existing baselines. The code is available at https://github.com/ermongroup/CSDI.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\34XZIILD\\Tashiro et al_2021_CSDI.pdf}
}

@misc{torfi2020CorGANCorrelationCapturingConvolutionala,
  title = {{{CorGAN}}: {{Correlation-Capturing Convolutional Generative Adversarial Networks}} for {{Generating Synthetic Healthcare Records}}},
  shorttitle = {{{CorGAN}}},
  author = {Torfi, Amirsina and Fox, Edward A.},
  date = {2020-03-04},
  number = {arXiv:2001.09346},
  eprint = {2001.09346},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2001.09346},
  url = {http://arxiv.org/abs/2001.09346},
  urldate = {2022-07-10},
  abstract = {Deep learning models have demonstrated high-quality performance in areas such as image classification and speech processing. However, creating a deep learning model using electronic health record (EHR) data, requires addressing particular privacy challenges that are unique to researchers in this domain. This matter focuses attention on generating realistic synthetic data while ensuring privacy. In this paper, we propose a novel framework called correlation-capturing Generative Adversarial Network (CorGAN), to generate synthetic healthcare records. In CorGAN we utilize Convolutional Neural Networks to capture the correlations between adjacent medical features in the data representation space by combining Convolutional Generative Adversarial Networks and Convolutional Autoencoders. To demonstrate the model fidelity, we show that CorGAN generates synthetic data with performance similar to that of real data in various Machine Learning settings such as classification and prediction. We also give a privacy assessment and report on statistical analysis regarding realistic characteristics of the synthetic data. The software of this work is open-source and is available at: https://github.com/astorfi/cor-gan.},
  keywords = {01,Autoencoder,CNN,Computer Science - Machine Learning,CorGAN,Healthcare,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\H2ER7YRF\\Torfi_Fox_2020_CorGAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\L7HZTMXA\\2001.html}
}

@article{torfi2022DifferentiallyPrivateSynthetic,
  title = {Differentially Private Synthetic Medical Data Generation Using Convolutional {{GANs}}},
  author = {Torfi, Amirsina and Fox, Edward A. and Reddy, Chandan K.},
  date = {2022-03},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {586},
  pages = {485--500},
  issn = {00200255},
  doi = {10.1016/j.ins.2021.12.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025521012391},
  urldate = {2022-07-10},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\EX9AHVKL\\Torfi et al_2022_Differentially private synthetic medical data generation using convolutional.pdf}
}

@article{torfi2022DifferentiallyPrivateSyntheticc,
  title = {Differentially {{Private Synthetic Medical Data Generation}} Using {{Convolutional GANs}}},
  author = {Torfi, Amirsina and Fox, Edward A. and Reddy, Chandan K.},
  date = {2022-03},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {586},
  eprint = {2012.11774},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {485--500},
  issn = {00200255},
  doi = {10.1016/j.ins.2021.12.018},
  url = {http://arxiv.org/abs/2012.11774},
  urldate = {2022-07-10},
  abstract = {Deep learning models have demonstrated superior performance in several application problems, such as image classification and speech processing. However, creating a deep learning model using health record data requires addressing certain privacy challenges that bring unique concerns to researchers working in this domain. One effective way to handle such private data issues is to generate realistic synthetic data that can provide practically acceptable data quality and correspondingly the model performance. To tackle this challenge, we develop a differentially private framework for synthetic data generation using R\textbackslash 'enyi differential privacy. Our approach builds on convolutional autoencoders and convolutional generative adversarial networks to preserve some of the critical characteristics of the generated synthetic data. In addition, our model can also capture the temporal information and feature correlations that might be present in the original data. We demonstrate that our model outperforms existing state-of-the-art models under the same privacy budget using several publicly available benchmark medical datasets in both supervised and unsupervised settings.},
  keywords = {02,Autoencoder,CNN,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,DP,gan,mixed data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\HY34JBLV\\Torfi et al_2022_Differentially Private Synthetic Medical Data Generation using Convolutional.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\TZSXV4QV\\2012.html}
}

@inproceedings{tritscher2020EvaluationPosthocXAIa,
  title = {Evaluation of {{Post-hoc XAI Approaches Through Synthetic Tabular Data}}},
  booktitle = {Foundations of {{Intelligent Systems}}},
  author = {Tritscher, Julian and Ring, Markus and Schlr, Daniel and Hettinger, Lena and Hotho, Andreas},
  editor = {Helic, Denis and Leitner, Gerhard and Stettinger, Martin and Felfernig, Alexander and Raś, Zbigniew W.},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {422--430},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-59491-6_40},
  abstract = {Evaluating the explanations given by post-hoc XAI approaches on tabular data is a challenging prospect, since the subjective judgement of explanations of tabular relations is non trivial in contrast to e.g. the judgement of image heatmap explanations. In order to quantify XAI performance on categorical tabular data, where feature relationships can often be described by Boolean functions, we propose an evaluation setting through generation of synthetic datasets. To create gold standard explanations, we present a definition of feature relevance in Boolean functions. In the proposed setting we evaluate eight state-of-the-art XAI approaches and gain novel insights into XAI performance on categorical tabular data. We find that the investigated approaches often fail to faithfully explain even basic relationships within categorical data.},
  isbn = {978-3-030-59491-6},
  langid = {english},
  keywords = {Evaluation,Explainable AI,Synthetic data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\554K62MD\\Tritscher et al_2020_Evaluation of Post-hoc XAI Approaches Through Synthetic Tabular Data.pdf}
}

@article{trivisonne2020ConstrainedStochasticState,
  title = {Constrained Stochastic State Estimation of Deformable {{1D}} Objects: {{Application}} to Single-View {{3D}} Reconstruction of Catheters with Radio-Opaque Markers},
  author = {Trivisonne, Raffaella and Kerrien, Erwan and Cotin, Stéphane},
  date = {2020-04-01},
  journaltitle = {Computerized Medical Imaging and Graphics},
  shortjournal = {Computerized Medical Imaging and Graphics},
  volume = {81},
  pages = {101702},
  issn = {0895-6111},
  doi = {10.1016/j.compmedimag.2020.101702},
  url = {https://www.sciencedirect.com/science/article/pii/S0895611120300057},
  abstract = {Minimally invasive fluoroscopy-based procedures are the gold standard for diagnosis and treatment of various pathologies of the cardiovascular system. This kind of procedures imply for the clinicians to infer the 3D shape of the device from 2D images, which is known to be an ill-posed problem. In this paper we present a method to reconstruct the 3D shape of the interventional device, with the aim of improving the navigation. The method combines a physics-based simulation with non-linear Bayesian filter. Whereas the physics-based model provides a prediction of the shape of the device navigating within the blood vessels (taking into account non-linear interactions between the catheter and the surrounding anatomy), an Unscented Kalman Filter is used to correct the navigation model using 2D image features as external observations. The proposed framework has been evaluated on both synthetic and real data, under different model parameterizations, filter parameters tuning and external observations data-sets. Comparing the reconstructed 3D shape with a known ground truth, for the synthetic data-set, we obtained average values for 3D Hausdorff Distance of 0.81±0.53mm, for the 3D mean distance at the segment of 0.37±0.17mm and an average 3D tip error of 0.24±0.13mm. For the real data-set,we obtained an average 3D Hausdorff distance of 1.74±0.77mm, a average 3D mean distance at the distal segment of 0.91±0.14mm, an average 3D error on the tip of 0.53±0.09mm. These results show the ability of our method to retrieve the 3D shape of the device, under a variety of filter parameterizations and challenging conditions: uncertainties on model parameterization, ambiguous views and non-linear complex phenomena such as stick and slip motions.},
  keywords = {Catheter reconstruction,Computer aided surgery,Constrained unscented Kalman filter,Endovascular intervention,Physics-based simulation}
}

@incollection{tsialiamanis2022GeneratingParametrisedStructural,
  title = {On {{Generating Parametrised Structural Data Using Conditional Generative Adversarial Networks}}},
  booktitle = {Data {{Science}} in {{Engineering}}, {{Volume}} 9},
  author = {Tsialiamanis, G. and Wagg, D. J. and Dervilis, N. and Worden, K.},
  editor = {Madarshahian, Ramin and Hemez, Francois},
  date = {2022},
  series = {Conference {{Proceedings}} of the {{Society}} for {{Experimental Mechanics Series}}},
  pages = {35--46},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-76004-5_6},
  url = {https://link.springer.com/10.1007/978-3-030-76004-5_6},
  urldate = {2022-07-10},
  isbn = {978-3-030-76003-8 978-3-030-76004-5},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\MVZWDX8E\\Tsialiamanis et al_2022_On Generating Parametrised Structural Data Using Conditional Generative.pdf}
}

@incollection{tsialiamanis2022GeneratingParametrisedStructuralc,
  title = {On Generating Parametrised Structural Data Using Conditional Generative Adversarial Networks},
  author = {Tsialiamanis, G. and Wagg, D. J. and Dervilis, N. and Worden, K.},
  date = {2022},
  eprint = {2203.01641},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {35--46},
  doi = {10.1007/978-3-030-76004-5_6},
  url = {http://arxiv.org/abs/2203.01641},
  urldate = {2022-07-10},
  abstract = {A powerful approach, and one of the most common ones in structural health monitoring (SHM), is to use data-driven models to make predictions and inferences about structures and their condition. Such methods almost exclusively rely on the quality of the data. Within the SHM discipline, data do not always suffice to build models with satisfactory accuracy for given tasks. Even worse, data may be completely missing from one's dataset, regarding the behaviour of a structure under different environmental conditions. In the current work, with a view to confronting such issues, the generation of artificial data using a variation of the generative adversarial network (GAN) algorithm, is used. The aforementioned variation is that of the conditional GAN or cGAN. The algorithm is not only used to generate artificial data, but also to learn transformations of manifolds according to some known parameters. Assuming that the structure's response is represented by points in a manifold, part of the space will be formed due to variations in external conditions affecting the structure. This idea proves efficient in SHM, as it is exploited to generate structural data for specific values of environmental coefficients. The scheme is applied here on a simulated structure which operates under different temperature and humidity conditions. The cGAN is trained on data for some discrete values of the temperature within some range, and is able to generate data for every temperature in this range with satisfactory accuracy. The novelty, compared to classic regression in similar problems, is that the cGAN allows unknown environmental parameters to affect the structure and can generate whole manifolds of data for every value of the known parameters, while the unknown ones vary within the generated manifolds.},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\UP5FHA5Q\\Tsialiamanis et al_2022_On generating parametrised structural data using conditional generative.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\9NJ5DG7R\\2203.html}
}

@inproceedings{vaswani2017AttentionAllYou,
  title = {Attention Is All You Need},
  booktitle = {Proceedings of the 31st {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
  date = {2017-12-04},
  series = {{{NIPS}}'17},
  pages = {6000--6010},
  publisher = {{Curran Associates Inc.}},
  location = {{Red Hook, NY, USA}},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  isbn = {978-1-5108-6096-4},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\MX6ZCHPH\\Vaswani et al_2017_Attention is all you need.pdf}
}

@online{vikancha-msft2022NCseriesAzureVirtual,
  title = {{{NC-series}} - {{Azure Virtual Machines}}},
  author = {vikancha- MSFT},
  options = {useprefix=true},
  date = {2022-12-21},
  url = {https://learn.microsoft.com/en-us/azure/virtual-machines/nc-series},
  urldate = {2023-03-13},
  abstract = {Specifications for the NC-series VMs.},
  langid = {american},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\SJD3UYE9\\nc-series.html}
}

@inproceedings{villamizar2021RequirementsEngineeringMachine,
  title = {Requirements {{Engineering}} for {{Machine Learning}}: {{A Systematic Mapping Study}}},
  shorttitle = {Requirements {{Engineering}} for {{Machine Learning}}},
  booktitle = {2021 47th {{Euromicro Conference}} on {{Software Engineering}} and {{Advanced Applications}} ({{SEAA}})},
  author = {Villamizar, Hugo and Escovedo, Tatiana and Kalinowski, Marcos},
  date = {2021-09},
  pages = {29--36},
  publisher = {{IEEE}},
  location = {{Palermo, Italy}},
  doi = {10.1109/SEAA53835.2021.00013},
  url = {https://ieeexplore.ieee.org/document/9582561/},
  urldate = {2023-03-06},
  eventtitle = {2021 47th {{Euromicro Conference}} on {{Software Engineering}} and {{Advanced Applications}} ({{SEAA}})},
  isbn = {978-1-66542-705-0},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FWJMW9LK\\Villamizar et al. - 2021 - Requirements Engineering for Machine Learning A S.pdf}
}

@online{vogelsang2019RequirementsEngineeringMachine,
  title = {Requirements {{Engineering}} for {{Machine Learning}}: {{Perspectives}} from {{Data Scientists}}},
  shorttitle = {Requirements {{Engineering}} for {{Machine Learning}}},
  author = {Vogelsang, Andreas and Borg, Markus},
  date = {2019-08-13},
  number = {arXiv:1908.04674},
  eprint = {arXiv:1908.04674},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1908.04674},
  urldate = {2023-03-06},
  abstract = {Machine learning (ML) is used increasingly in real-world applications. In this paper, we describe our ongoing endeavor to define characteristics and challenges unique to Requirements Engineering (RE) for ML-based systems. As a first step, we interviewed four data scientists to understand how ML experts approach elicitation, specification, and assurance of requirements and expectations. The results show that changes in the development paradigm, i.e., from coding to training, also demands changes in RE. We conclude that development of ML systems demands requirements engineers to: (1) understand ML performance measures to state good functional requirements, (2) be aware of new quality requirements such as explainability, freedom from discrimination, or specific legal requirements, and (3) integrate ML specifics in the RE process. Our study provides a first contribution towards an RE methodology for ML systems.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\BHBAHWDU\\Vogelsang_Borg_2019_Requirements Engineering for Machine Learning.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\YWAKQFA6\\1908.html}
}

@article{webster2002AnalyzingPrepareFuture,
  title = {Analyzing the {{Past}} to {{Prepare}} for the {{Future}}: {{Writing}} a {{Literature Review}}},
  shorttitle = {Analyzing the {{Past}} to {{Prepare}} for the {{Future}}},
  author = {Webster, Jane and Watson, Richard},
  date = {2002-06-01},
  journaltitle = {MIS Quarterly},
  shortjournal = {MIS Quarterly},
  volume = {26},
  doi = {10.2307/4132319},
  abstract = {A review of prior, relevant literature is an essential feature of any academic project. An effective review creates a firm foundation for advancing knowledge. It facilitates theory development, closes areas where a plethora of research exists, and uncovers areas where research is needed.}
}

@article{webster2002AnalyzingPrepareFuturea,
  title = {Analyzing the {{Past}} to {{Prepare}} for the {{Future}}: {{Writing}} a {{Literature Review}}},
  shorttitle = {Analyzing the {{Past}} to {{Prepare}} for the {{Future}}},
  author = {Webster, Jane and Watson, Richard},
  date = {2002-06-01},
  journaltitle = {MIS Quarterly},
  shortjournal = {MIS Quarterly},
  volume = {26},
  doi = {10.2307/4132319},
  abstract = {A review of prior, relevant literature is an essential feature of any academic project. An effective review creates a firm foundation for advancing knowledge. It facilitates theory development, closes areas where a plethora of research exists, and uncovers areas where research is needed.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\5ZTWRILD\\Webster_Watson_2002_Analyzing the Past to Prepare for the Future.pdf}
}

@article{websterGuestEditorialAnalyzing,
  title = {Guest {{Editorial}}:  {{Analyzing}} the {{Past}} to {{Prepare}} for the {{Future}}:  {{Writing}} a Literature {{Review}}},
  author = {Webster, Jane and Watson, Richard T},
  pages = {11},
  langid = {english}
}

@article{websterGuestEditorialAnalyzinga,
  title = {Guest {{Editorial}}:  {{Analyzing}} the {{Past}} to {{Prepare}} for the {{Future}}:  {{Writing}} a Literature {{Review}}},
  author = {Webster, Jane and Watson, Richard T},
  pages = {11},
  langid = {english}
}

@misc{wen2021CausalTGANGeneratingTabulara,
  title = {Causal-{{TGAN}}: {{Generating Tabular Data Using Causal Generative Adversarial Networks}}},
  shorttitle = {Causal-{{TGAN}}},
  author = {Wen, Bingyang and Colon, Luis Oliveros and Subbalakshmi, K. P. and Chandramouli, R.},
  date = {2021-04-21},
  number = {arXiv:2104.10680},
  eprint = {2104.10680},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2104.10680},
  url = {http://arxiv.org/abs/2104.10680},
  urldate = {2022-07-10},
  abstract = {Synthetic data generation becomes prevalent as a solution to privacy leakage and data shortage. Generative models are designed to generate a realistic synthetic dataset, which can precisely express the data distribution for the real dataset. The generative adversarial networks (GAN), which gain great success in the computer vision fields, are doubtlessly used for synthetic data generation. Though there are prior works that have demonstrated great progress, most of them learn the correlations in the data distributions rather than the true processes in which the datasets are naturally generated. Correlation is not reliable for it is a statistical technique that only tells linear dependencies and is easily affected by the dataset's bias. Causality, which encodes all underlying factors of how the real data be naturally generated, is more reliable than correlation. In this work, we propose a causal model named Causal Tabular Generative Neural Network (Causal-TGAN) to generate synthetic tabular data using the tabular data's causal information. Extensive experiments on both simulated datasets and real datasets demonstrate the better performance of our method when given the true causal graph and a comparable performance when using the estimated causal graph.},
  keywords = {✔️,01,Causal-TGAN,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,gan,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FI3499Z9\\Wen et al_2021_Causal-TGAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\AUFGDNHK\\2104.html}
}

@online{weng2018AutoencoderBetaVAE,
  title = {From {{Autoencoder}} to {{Beta-VAE}}},
  author = {Weng, Lilian},
  date = {2018-08-12T00:00:00+00:00},
  url = {https://lilianweng.github.io/posts/2018-08-12-vae/},
  urldate = {2023-01-16},
  abstract = {[Updated on 2019-07-18: add a section on VQ-VAE \& VQ-VAE-2.]  [Updated on 2019-07-26: add a section on TD-VAE.]  Autocoder is invented to reconstruct high-dimensional data using a neural network model with a narrow bottleneck layer in the middle (oops, this is probably not true for Variational Autoencoder, and we will investigate it in details in later sections). A nice byproduct is dimension reduction: the bottleneck layer captures a compressed latent encoding.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\U64TNP4S\\2018-08-12-vae.html}
}

@online{weng2021WhatAreDiffusion,
  title = {What Are {{Diffusion Models}}?},
  author = {Weng, Lilian},
  date = {2021-07-11T00:00:00+00:00},
  url = {https://lilianweng.github.io/posts/2021-07-11-diffusion-models/},
  urldate = {2023-01-16},
  abstract = {[Updated on 2021-09-19: Highly recommend this blog post on score-based generative modeling by Yang Song (author of several key papers in the references)]. [Updated on 2022-08-27: Added classifier-free guidance, GLIDE, unCLIP and Imagen. [Updated on 2022-08-31: Added latent diffusion model. So far, I’ve written about three types of generative models, GAN, VAE, and Flow-based models. They have shown great success in generating high-quality samples, but each has some limitations of its own.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\RI8UFCZR\\2021-07-11-diffusion-models.html}
}

@inproceedings{whiting2008CreatingRealisticScenariobased,
  title = {Creating Realistic, Scenario-Based Synthetic Data for Test and Evaluation of Information Analytics Software},
  booktitle = {Proceedings of the 2008 Conference on {{BEyond}} Time and Errors Novel {{evaLuation}} Methods for {{Information Visualization}} - {{BELIV}} '08},
  author = {Whiting, Mark A. and Haack, Jereme and Varley, Carrie},
  date = {2008},
  pages = {1},
  publisher = {{ACM Press}},
  location = {{Florence, Italy}},
  doi = {10.1145/1377966.1377977},
  url = {http://portal.acm.org/citation.cfm?doid=1377966.1377977},
  urldate = {2022-06-30},
  abstract = {We describe the Threat Stream Generator, a method and a toolset for creating realistic, synthetic test data for information analytics applications. Finding or creating useful test data sets is difficult for a team focused on creating solutions to information analysis problems. First, real data that might be considered good for testing analytic applications may not be available or may be classified. In the latter case, tool builders will not have the clearances needed to use, or even see, the data. Second, analysts’ time is scarce and obtaining the needed characteristics of real data from them to create a test data set is difficult. Finally, generating good test data is challenging. Commercial data generators are focused on large database testing, not information analytics tool testing. Our distinctive contribution is that we embed known ground truth in a test data set, so that tool developers and others will be able to determine the effectiveness of their software and how they are progressing in their support for information analysts. Our automated methods also significantly decrease data set development time. We review our approach to scenario development, threat insertion strategies, data set development, and data set evaluation. We also discuss our recent successes in using our data in open analytic competitions.},
  eventtitle = {The 2008 Conference},
  isbn = {978-1-60558-016-6},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\WP7HCWCF\\Whiting et al_2008_Creating realistic, scenario-based synthetic data for test and evaluation of.pdf}
}

@article{WOS:000346361600013,
  type = {Article},
  title = {Data Smearing: {{An}} Approach to Disclosure Limitation for Tabular Data},
  author = {Toth, Daniell},
  date = {2014-12},
  journaltitle = {JOURNAL OF OFFICIAL STATISTICS},
  volume = {30},
  number = {4},
  pages = {839--857},
  issn = {0282-423X},
  doi = {10.2478/JOS-2014-0050},
  abstract = {Statistical agencies often collect sensitive data for release to the public at aggregated levels in the form of tables. To protect confidential data, some cells are suppressed in the publicly released data. One problem with this method is that many cells of interest must be suppressed in order to protect a much smaller number of sensitive cells. Another problem is that the covariates used to aggregate and level of aggregation must be fixed before the data is released. Both of these restrictions can severely limit the utility of the data. We propose a new disclosure limitation method that replaces the full set of microdata with synthetic data for use in producing released data in tabular form. This synthetic data set is obtained by replacing each unit's values with a weighted average of sampled values from the surrounding area. The synthetic data is produced in a way to give asymptotically unbiased estimates for aggregate cells as the number of units in the cell increases. The method is applied to the U.S. Bureau of Labor Statistics Quarterly Census of Employment and Wages data, which is released to the public quarterly in tabular form and aggregated across varying scales of time, area, and economic sector.},
  affiliation = {Toth, D (Corresponding Author), US Bur Labor Stat, Off Survey Methods Res, Suite 1950, Washington, DC 20212 USA. US Bur Labor Stat, Off Survey Methods Res, Washington, DC 20212 USA.},
  author-email = {toth.daniell@bls.gov},
  da = {2022-07-10},
  doc-delivery-number = {AW6EG},
  keywords-plus = {MULTIPLE IMPUTATION; MODELS},
  research-areas = {Mathematical Methods In Social Sciences; Mathematics},
  times-cited = {2},
  unique-id = {WOS:000346361600013},
  keywords = {Cell suppression,confidentiality,contingency tables,multiple imputation,nearest neighbor,synthetic data}
}

@article{WOS:000469836900009,
  title = {{{GANobfuscator}}: {{Mitigating}} Information Leakage under {{GAN}} via Differential Privacy},
  author = {Xu, Chugui and Ren, Ju and Zhang, Deyu and Zhang, Yaoxue and Qin, Zhan and Ren, Kui},
  date = {2019-09},
  journaltitle = {IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY},
  volume = {14},
  number = {9},
  pages = {2358--2371},
  issn = {1556-6013},
  doi = {10.1109/TIFS.2019.2897874},
  abstract = {By learning generative models of semantic-rich data distributions from samples, generative adversarial network (GAN) has recently attracted intensive research interests due to its excellent empirical performance as a generative model. The model is used to estimate the underlying distribution of a dataset and randomly generate realistic samples according to their estimated distribution. However, GANs can easily remember training samples due to the high model complexity of deep networks. When GANs are applied to private or sensitive data, the concentration of distribution may divulge some critical information. It consequently requires new technological advances to mitigate the information leakage under GANs. To address this issue, we propose GANobfuscator, a differentially private GAN, which can achieve differential privacy under GANs by adding carefully designed noise to gradients during the learning procedure. With GANobfuscator, analysts are able to generate an unlimited amount of synthetic data for arbitrary analysis tasks without disclosing the privacy of training data. Moreover, we theoretically prove that GANobfuscator can provide strict privacy guarantee with differential privacy. In addition, we develop a gradient-pruning strategy for GANobfuscator to improve the scalability and stability of data training. Through extensive experimental evaluation on benchmark datasets, we demonstrate that GANobfuscator can produce high-quality generated data and retain desirable utility under practical privacy budgets.},
  keywords = {deep learning,differential privacy,generative adversarial network,Information leakage}
}

@article{WOS:000504778300062,
  title = {Conditional {{Wasserstein}} Generative Adversarial Network-Gradient Penalty-Based Approach to Alleviating Imbalanced Data Classification},
  author = {Zheng, Ming and Li, Tong and Zhu, Rui and Tang, Yahui and Tang, Mingjing and Lin, Leilei and Ma, Zifei},
  date = {2020-02},
  journaltitle = {INFORMATION SCIENCES},
  volume = {512},
  pages = {1009--1023},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2019.10.014},
  abstract = {In data mining, common classification algorithms cannot effectively learn from imbalanced data. Oversampling addresses this problem by creating data for the minority class in order to balance the class distribution before the model is trained. The Traditional oversampling approaches are based on Synthetic Minority Oversampling TEchnique (SMOTE), which focus on local information but generates insufficiently realistic data. In contrast, the Generative Adversarial Network (GAN) captures the true data distribution in order to generate data for the minority class. However, both approaches are problematic owing to mode collapse and unstable training. To overcome these problems, we propose Conditional Wasserstein GAN- Gradient Penalty (CWGAN-GP), a novel and efficient synthetic oversampling approach for imbalanced datasets, which can be constructed by adding auxiliary conditional information to the WGAN-GP. CWGAN-GP generates more realistic data and overcomes the aforementioned problems. Experiments on 15 different benchmarked datasets and two real imbalanced datasets empirically demonstrate that CWGAN-GP increases the quality of synthetic data; furthermore, our approach outperforms the other oversampling approaches based on three evaluation metrics (F-measure, G-mean, and the area under the receiver operating characteristic curve) for five classifiers. Friedman and Nemenyi post hoc statistical tests also confirm that CWGAN-GP is superior to the other oversampling approaches. (C) 2019 Elsevier Inc. All rights reserved.},
  keywords = {03,conditional GAN,CWGAN-GP,gan,GAN,Imbalanced learning,Oversampling approach,SMOTE,WGAN-GP},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\DJSGUU8J\\Zheng et al_2020_Conditional Wasserstein generative adversarial network-gradient penalty-based.pdf}
}

@article{WOS:000515892400001,
  title = {A Generative Adversarial Network-Based Method for Generating Negative Financial Samples},
  author = {Zhang, Zhaohui and Yang, Lijun and Chen, Ligong and Liu, Qiuwen and Meng, Ying and Wang, Pengwei and Li, Maozhen},
  date = {2020-02},
  journaltitle = {INTERNATIONAL JOURNAL OF DISTRIBUTED SENSOR NETWORKS},
  volume = {16},
  number = {2},
  issn = {1550-1477},
  doi = {10.1177/1550147720907053},
  abstract = {In financial anti-fraud field, negative samples are small and sparse with serious sample imbalanced problem. Generating negative samples consistent with original data to naturally solve imbalanced problem is a serious problem. This article proposes a new method to solve this problem. We introduce a new generation model, combined Generative Adversarial Network with Long Short-Term Memory network for one-dimensional negative financial samples. The characteristic association between transaction sequences can be learned by long short-term memory layer, and the generator covers real data distribution by the adversarial discriminator with time-sequence. Mapping data distribution to feature space is a common evaluation method of synthetic data; however, relationships between data attributes have been ignored in online transactions. We define a comprehensive evaluation method to evaluate the validity of generated samples from data distribution and attribute characteristics. Experimental results on real bank B2B transaction data show that the proposed model has higher overall ratings, which is 10\% higher than traditional generation models. Finally, well-trained model is used to generate negative samples and form new dataset. The classification results on new datasets show that precision and recall are all higher than baseline models. Our work has a certain practical value and provides a new idea to solve imbalanced problem in whatever fields.},
  keywords = {✔️,03,evaluation method,Generative adversarial network,long short-term memory network,lstm,negative financial samples,time series data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\VA93LDXV\\Zhang et al_2020_A generative adversarial network-based method for generating negative financial.pdf}
}

@article{WOS:000636425800003,
  title = {{{EEG}} Data Augmentation for Emotion Recognition with a Multiple Generator Conditional {{Wasserstein GAN}}},
  author = {Zhang, Aiming and Su, Lei and Zhang, Yin and Fu, Yunfa and Wu, Liping and Liang, Shengjin},
  journaltitle = {COMPLEX \& INTELLIGENT SYSTEMS},
  issn = {2199-4536},
  doi = {10.1007/s40747-021-00336-7},
  abstract = {EEG-based emotion recognition has attracted substantial attention from researchers due to its extensive application prospects, and substantial progress has been made in feature extraction and classification modelling from EEG data. However, insufficient high-quality training data are available for building EEG-based emotion recognition models via machine learning or deep learning methods. The artificial generation of high-quality data is an effective approach for overcoming this problem. In this paper, a multi-generator conditional Wasserstein GAN method is proposed for the generation of high-quality artificial that covers a more comprehensive distribution of real data through the use of various generators. Experimental results demonstrate that the artificial data that are generated by the proposed model can effectively improve the performance of emotion classification models that are based on EEG.},
  keywords = {03,conditional GAN,Data augmentation,EEG,Emotion recognition,gan,GAN,MG-CWGAN,multiple generator,numeric data,wasserstein},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\R6NP38V7\\Zhang et al_EEG data augmentation for emotion recognition with a multiple generator.pdf}
}

@article{WOS:000658393600004,
  title = {{{DP-GAN}}: {{Differentially}} Private Consecutive Data Publishing Using Generative Adversarial Nets},
  author = {Ho, Stella and Qu, Youyang and Gu, Bruce and Gao, Longxiang and Li, Jianxin and Xiang, Yong},
  date = {2021-07-01},
  journaltitle = {JOURNAL OF NETWORK AND COMPUTER APPLICATIONS},
  volume = {185},
  issn = {1084-8045},
  doi = {10.1016/j.jnca.2021.103066},
  abstract = {In the era of big data, increasingly massive volumes of data is generated and published consecutively for both research and commercial purposes. The potential value of sensitive information also attracts interest from adversaries and thereby arises public concern. Current research mostly focuses on privacy-preserving data publishing in a statistic manner rather than taking the dynamics and correlation of context into consideration. Motivated by this, we propose a novel idea that combining differential privacy and generative adversarial nets. Generative adversarial nets and its extensions are used to generate a synthetic dataset with indistinguishable statistic features while differential privacy guarantees a trade-off between privacy protection and data utility. By employing a min-max game with three players, we devise a deep generative model, namely DP-GAN model, for synthetic data generation while fulfilling the privacy constraints in a differentially private manner. Extensive simulation results on a real-world dataset testify the superiority of the proposed model in terms of privacy protection, data utility, and efficiency.},
  keywords = {02,Continual data release,Differential privacy,dp,DP-GAN,gan,Generative adversarial nets},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\P256GGIA\\Ho et al_2021_DP-GAN.pdf}
}

@article{WOS:000660647400001,
  title = {A Generative Adversarial Network ({{GAN}}) Technique for Internet of Medical Things Data},
  author = {Vaccari, Ivan and Orani, Vanessa and Paglialonga, Alessia and Cambiaso, Enrico and Mongelli, Maurizio},
  date = {2021-06},
  journaltitle = {SENSORS},
  volume = {21},
  number = {11},
  doi = {10.3390/s21113726},
  abstract = {The application of machine learning and artificial intelligence techniques in the medical world is growing, with a range of purposes: from the identification and prediction of possible diseases to patient monitoring and clinical decision support systems. Furthermore, the widespread use of remote monitoring medical devices, under the umbrella of the “Internet of Medical Things” (IoMT), has simplified the retrieval of patient information as they allow continuous monitoring and direct access to data by healthcare providers. However, due to possible issues in real-world settings, such as loss of connectivity, irregular use, misuse, or poor adherence to a monitoring program, the data collected might not be sufficient to implement accurate algorithms. For this reason, data augmentation techniques can be used to create synthetic datasets sufficiently large to train machine learning models. In this work, we apply the concept of generative adversarial networks (GANs) to perform a data augmentation from patient data obtained through IoMT sensors for Chronic Obstructive Pulmonary Disease (COPD) monitoring. We also apply an explainable AI algorithm to demonstrate the accuracy of the synthetic data by comparing it to the real data recorded by the sensors. The results obtained demonstrate how synthetic datasets created through a well-structured GAN are comparable with a real dataset, as validated by a novel approach based on machine learning.},
  keywords = {✔️,03,generative adversarial networks (GANs),healthcare,intelligible analytics,Internet of Medical Things (IoMT),machine learning,numeric data,remote monitoring,statistical validation},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\9UPNCXZV\\Vaccari et al_2021_A generative adversarial network (GAN) technique for internet of medical things.pdf}
}

@inproceedings{WOS:000683379205002,
  type = {Proceedings paper},
  title = {Chi(2) Generative Adversarial Network},
  booktitle = {{{INTERNATIONAL CONFERENCE ON MACHINE LEARNING}}, {{VOL}} 80},
  author = {Tao, Chenyang and Chen, Liqun and Henao, Ricardo and Feng, Jianfeng and Carin, Lawrence},
  editor = {Dy, J and Krause, A},
  date = {2018},
  series = {Proceedings of Machine Learning Research},
  volume = {80},
  issn = {2640-3498},
  abstract = {To assess the difference between real and synthetic data, Generative Adversarial Networks (GANs) are trained using a distribution discrepancy measure. Three widely employed measures are information-theoretic divergences, integral probability metrics, and Hilbert space discrepancy metrics. We elucidate the theoretical connections between these three popular GAN training criteria and propose a novel procedure, called chi(2)-GAN, that is conceptually simple, stable at training and resistant to mode collapse. Our procedure naturally generalizes to address the problem of simultaneous matching of multiple distributions. Further, we propose a resampling strategy that significantly improves sample quality, by repurposing the trained critic function via an importance weighting mechanism. Experiments show that the proposed procedure improves stability and convergence, and yields state-of-art results on a wide range of generative modeling tasks.},
  affiliation = {Tao, CY (Corresponding Author), Duke Univ, Elect \& Comp Engn, Durham, NC 27708 USA. Tao, Chenyang; Chen, Liqun; Henao, Ricardo; Carin, Lawrence, Duke Univ, Elect \& Comp Engn, Durham, NC 27708 USA. Feng, Jianfeng, Fudan Univ, ISTBI, Shanghai, Peoples R China.},
  author-email = {chenyang.tao@duke.edu},
  da = {2022-07-10},
  doc-delivery-number = {BS0MK},
  keywords-plus = {METRICS},
  research-areas = {Computer Science},
  times-cited = {0},
  unique-id = {WOS:000683379205002}
}

@article{WOS:000759503800001,
  title = {Synthetic Energy Data Generation Using Time Variant Generative Adversarial Network},
  author = {Asre, Shashank and Anwar, Adnan},
  date = {2022-02},
  journaltitle = {Electronicsweek},
  shortjournal = {ELECTRONICS},
  volume = {11},
  number = {3},
  doi = {10.3390/electronics11030355},
  abstract = {Energy consumption data is being used for improving the energy efficiency and minimizing the cost. However, obtaining energy consumption data has two major challenges: (i) data collection is very expensive, time-consuming, and (ii) security and privacy concern of the users which can be revealed from the actual data. In this research, we have addressed these challenges by using generative adversarial networks for generating energy consumption profile. We have successfully generated synthetic data which is similar to the real energy consumption data. On the basis of the recent research conducted on TimeGAN, we have implemented a framework for synthetic energy consumption data generation that could be useful in research, data analysis and create business solutions. The framework is implemented using the real-world energy dataset, consisting of energy consumption data of the year 2020 for the Australian states of Victoria, New South Wales, South Australia, Queensland and Tasmania. The results of implementation is evaluated using various performance measures and the results are showcased using visualizations along with Principal Component Analysis (PCA) and t-distributed stochastic neighbor embedding (TSNE) plots. Overall, experimental results show that Synthetic data generated using the proposed implementation possess very similar characteristics to the real dataset with high comparison accuracy.},
  keywords = {02,energy,energy dataset,GAN,privacy,smart grid,time series data,TimeGAN},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\MWSGFPZF\\Asre_Anwar_2022_Synthetic energy data generation using time variant generative adversarial.pdf}
}

@inproceedings{WOS:000764175401037,
  type = {Proceedings paper},
  title = {Visual Data Synthesis via {{GAN}} for Zero-Shot Video Classification},
  booktitle = {{{PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE}}},
  author = {Zhang, Chenrui and Peng, Yuxin},
  editor = {Lang, J},
  date = {2018},
  pages = {1128--1134},
  abstract = {Zero-Shot Learning (ZSL) in video classification is a promising research direction, which aims to tackle the challenge from explosive growth of video categories. Most existing methods exploit seen-to-unseen correlation via learning a projection between visual and semantic spaces. However, such projection-based paradigms cannot fully utilize the discriminative information implied in data distribution, and commonly suffer from the information degradation issue caused by “heterogeneity gap”. In this paper, we propose a visual data synthesis framework via GAN to address these problems. Specifically, both semantic knowledge and visual distribution are leveraged to synthesize video feature of unseen categories, and ZSL can be turned into typical supervised problem with the synthetic features. First, we propose multi-level semantic inference to boost video feature synthesis, which captures the discriminative information implied in joint visual-semantic distribution via feature-level and label-level semantic inference. Second, we propose Matching-aware Mutual Information Correlation to overcome information degradation issue, which captures seen-to-unseen correlation in matched and mismatched visual-semantic pairs by mutual information, providing the zero-shot synthesis procedure with robust guidance signals. Experimental results on four video datasets demonstrate that our approach can improve the zero-shot video classification performance significantly.},
  affiliation = {Peng, YX (Corresponding Author), Peking Univ, Inst Comp Sci \& Technol, Beijing 100871, Peoples R China. Zhang, Chenrui; Peng, Yuxin, Peking Univ, Inst Comp Sci \& Technol, Beijing 100871, Peoples R China.},
  author-email = {pengyuxin@pku.edu.cn},
  da = {2022-07-10},
  doc-delivery-number = {BS7MQ},
  isbn = {978-0-9992411-2-7},
  research-areas = {Computer Science},
  times-cited = {20},
  unique-id = {WOS:000764175401037}
}

@article{WOS:000775011300001,
  title = {A Comparative Study to Predict Bearing Degradation Using Discrete Wavelet Transform ({{DWT}}), Tabular Generative Adversarial Networks ({{TGAN}}) and Machine Learning Models},
  author = {Bhavsar, Keval and Vakharia, Vinay and Chaudhari, Rakesh and Vora, Jay and Pimenov, Danil Yurievich and Giasin, Khaled},
  date = {2022-03},
  journaltitle = {MACHINES},
  volume = {10},
  number = {3},
  doi = {10.3390/machines10030176},
  abstract = {Prognostics and health management (PHM) is a framework to identify damage prior to its occurrence which leads to the reduction of both maintenance costs and safety hazards. Based on the data collected in condition monitoring, the degradation of the part is predicted. Studies show that most failures are caused by faults in rolling element bearing, which highlights that a bearing is one of the most important mechanical components of any machine. Thus, it becomes important to monitor bearing degradation to make sure that it is utilized properly. Generally, machine learning (ML) or deep learning (DL) techniques are utilized to predict bearing degradation using a data-driven approach, where signals are captured from the machine. There should be a large amount of data to apply either ML or DL techniques, but it is difficult to collect that amount of data directly from any machine. In this study, health assessment is carried out using the correlation coefficient to divide the bearing life into two degradation stages. The raw signal is processed using discrete wavelet transform (DWT), where mutual information (MI) is used to rank and select the base wavelet, after which tabular generative adversarial networks (TGAN) are used to generate the artificial coefficients. Statistical features are calculated from the real data (DWT coefficients) and the artificial data (generated from TGAN). The constructed feature vector is then used as an input to train machine learning models, namely ensemble bagged tree (EBT) and Gaussian process regression with the squared exponential kernel function (SEGPR), to estimate bearing degradation conditions. Both the machine learning models were validated on the publicly available experimental data of FEMTO bearing. Obtained results showed that the developed EBT and SEGPR models accurately predicted the bearing degradation conditions with the average lowest RMSE value of 0.0045 and MAE value of 0.0037.},
  keywords = {bearing,bearing degradation,discrete wavelet transform,ensemble bagged tree,GAN,Gaussian process regression,prognostics and health management (PHM),TGAN}
}

@article{WOS:000776964700001,
  title = {{{MaWGAN}}: {{A}} Generative Adversarial Network to Create Synthetic Data from Datasets with Missing Data},
  author = {Poudevigne-Durance, Thomas and Jones, Owen Dafydd and Qin, Yipeng},
  date = {2022-03},
  journaltitle = {Electronicsweek},
  shortjournal = {ELECTRONICS},
  volume = {11},
  number = {6},
  doi = {10.3390/electronics11060837},
  abstract = {The creation of synthetic data are important for a range of applications, for example, to anonymise sensitive datasets or to increase the volume of data in a dataset. When the target dataset has missing data, then it is common to just discard incomplete observations, even though this necessarily means some loss of information. However, when the proportion of missing data are large, discarding incomplete observations may not leave enough data to accurately estimate their joint distribution. Thus, there is a need for data synthesis methods capable of using datasets with missing data, to improve accuracy and, in more extreme cases, to make data synthesis possible. To achieve this, we propose a novel generative adversarial network (GAN) called MaWGAN (for masked Wasserstein GAN), which creates synthetic data directly from datasets with missing values. As with existing GAN approaches, the MaWGAN synthetic data generator generates samples from the full joint distribution. We introduce a novel methodology for comparing the generator output with the original data that does not require us to discard incomplete observations, based on a modification of the Wasserstein distance and easily implemented using masks generated from the pattern of missing data in the original dataset. Numerical experiments are used to demonstrate the superior performance of MaWGAN compared to (a) discarding incomplete observations before using a GAN, and (b) imputing missing values (using the GAIN algorithm) before using a GAN.},
  keywords = {02,gan,generative adversarial network,masked wasserstein GAN,MaWGAN,missing data,synthetic data,wasserstein,Wasserstein distance},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\FIHPQL8Z\\Poudevigne-Durance et al_2022_MaWGAN.pdf}
}

@inproceedings{WOS:000790235800420,
  type = {Proceedings paper},
  title = {On Constructing Vessel Dataset Structure Using {{GAN-based}} Data Augmentation},
  booktitle = {{{12TH INTERNATIONAL CONFERENCE ON ICT CONVERGENCE}} ({{ICTC}} 2021): {{BEYOND THE PANDEMIC ERA WITH ICT CONVERGENCE INNOVATION}}},
  author = {Oh, Ah Reum and Lee, Jiwon and Moon, Sung-Won and Lee, Jung Soo and Nam, Do-Won and Yoo, Wonyoung},
  date = {2021},
  series = {International Conference on Information and Communication Technology Convergence},
  pages = {1700--1702},
  issn = {2162-1233},
  doi = {10.1109/ICTC52510.2021.9620827},
  abstract = {Conventional methods using classical image processing techniques is to limitedly augment basic data for extension of the dataset volume in deep learning network system. A new proposed approach using synthetic data by 3D virtual model and Generative Adversarial Networks (GAN) is able to resolve the lack of dataset adequately, and the performance of the dataset structure can be verified by a classification network model. The single and combined data groups with various types of images were constructed for the accuracy comparison of classification system, and it indicated that the proposal has an appropriate profit for improvement of the system. The composed dataset using data augmentation methods can be applied on both academic and industrial field which have little actual data for deep leaning network systems. Further work will aim to improve the quality of the data from GAN and find the relevant quantity of dataset according to data type.},
  affiliation = {Oh, AR (Corresponding Author), ETRI, Conten Informat Retrieval Res Sect, Daejeon, South Korea. Oh, Ah Reum; Lee, Jiwon; Moon, Sung-Won; Lee, Jung Soo; Nam, Do-Won; Yoo, Wonyoung, ETRI, Conten Informat Retrieval Res Sect, Daejeon, South Korea.},
  author-email = {arol116@etri.re.kr ez1005@etri.re.kr moonstarry@etri.re.kr jslee2365@etri.re.kr dwnam@etri.re.kr zero2@etri.re.kr},
  book-group-author = {IEEE},
  da = {2022-07-10},
  doc-delivery-number = {BT0NR},
  isbn = {978-1-66542-383-0},
  research-areas = {Engineering},
  times-cited = {0},
  unique-id = {WOS:000790235800420},
  keywords = {04,Data augmentation,Data construction,Generative adversarial network,Style-transferring},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LQG7VDJ3\\Oh et al_2021_On constructing vessel dataset structure using GAN-based data augmentation.pdf}
}

@inproceedings{wu2020AttentionbasedLearningMissing,
  title = {Attention-Based {{Learning}} for {{Missing Data Imputation}} in {{HoloClean}}},
  author = {Wu, Richard and Zhang, Aoqian and Ilyas, I. and Rekatsinas, Theodoros},
  date = {2020-03-15},
  url = {https://www.semanticscholar.org/paper/Attention-based-Learning-for-Missing-Data-in-Wu-Zhang/37adffffcdf12e16590b7dec7ed73a5a361b2c9c},
  urldate = {2023-01-19},
  abstract = {We study the problem of missing data imputation, a data validation task that machine learning researchers and practitioners confront regularly. We focus on mixed (discrete and continuous) data and AimNet, an attention-based learning network for missing data imputation in HoloClean, a state-of-the-art ML-based data cleaning framework. AimNet utilizes a variation of the dot product attention mechanism to learn structural properties of the mixed data distribution and relies on the learned structure to perform imputation. We perform an extensive experimental study over 14 real-world data sets to understand the role of attention and structure on data imputation. We find that the simple attention-based architecture of AimNet outperforms state-of-the-art baselines, such as ensemble tree models and deep learning architectures (e.g., generative adversarial networks), by up to 43\% in accuracy on discrete values and up to 26.7\% in normalized-RMS error on continuous values. A key finding of our study is that, by learning the structure of the underlying distribution, the attention mechanism can generalize better on systematically-missing data where imputation requires reasoning about functional relationships between attributes.},
  eventtitle = {Conference on {{Machine Learning}} and {{Systems}}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\EL48ENPY\\Wu et al. - Attention-based Learning for Missing Data Imputati.pdf}
}

@misc{wu2022MedicalScientificTabletoTexta,
  title = {Medical {{Scientific Table-to-Text Generation}} with {{Human-in-the-Loop}} under the {{Data Sparsity Constraint}}},
  author = {Wu, Heng-Yi and Zhang, Jingqing and Ive, Julia and Li, Tong and Tabari, Narges and Chen, Bingyuan and Gupta, Vibhor and Guo, Yike},
  date = {2022-05-24},
  number = {arXiv:2205.12368},
  eprint = {2205.12368},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.12368},
  url = {http://arxiv.org/abs/2205.12368},
  urldate = {2022-07-10},
  abstract = {Structured (tabular) data in the preclinical and clinical domains contains valuable information about individuals and an efficient table-to-text summarization system can drastically reduce manual efforts to condense this data into reports. However, in practice, the problem is heavily impeded by the data paucity, data sparsity and inability of the state-of-the-art natural language generation models (including T5, PEGASUS and GPT-Neo) to produce accurate and reliable outputs. In this paper, we propose a novel table-to-text approach and tackle these problems with a novel two-step architecture which is enhanced by auto-correction, copy mechanism and synthetic data augmentation. The study shows that the proposed approach selects salient biomedical entities and values from structured data with improved precision (up to 0.13 absolute increase) of copying the tabular values to generate coherent and accurate text for assay validation reports and toxicology reports. Moreover, we also demonstrate a light-weight adaptation of the proposed system to new datasets by fine-tuning with as little as 40\textbackslash\% training examples. The outputs of our model are validated by human experts in the Human-in-the-Loop scenario.},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\LVI9IVVH\\Wu et al_2022_Medical Scientific Table-to-Text Generation with Human-in-the-Loop under the.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\WIYUZXNW\\2205.html}
}

@online{xie2018DifferentiallyPrivateGenerative,
  title = {Differentially {{Private Generative Adversarial Network}}},
  author = {Xie, Liyang and Lin, Kaixiang and Wang, Shu and Wang, Fei and Zhou, Jiayu},
  date = {2018-02-19},
  number = {arXiv:1802.06739},
  eprint = {arXiv:1802.06739},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1802.06739},
  url = {http://arxiv.org/abs/1802.06739},
  urldate = {2023-02-27},
  abstract = {Generative Adversarial Network (GAN) and its variants have recently attracted intensive research interests due to their elegant theoretical foundation and excellent empirical performance as generative models. These tools provide a promising direction in the studies where data availability is limited. One common issue in GANs is that the density of the learned generative distribution could concentrate on the training data points, meaning that they can easily remember training samples due to the high model complexity of deep networks. This becomes a major concern when GANs are applied to private or sensitive data such as patient medical records, and the concentration of distribution may divulge critical patient information. To address this issue, in this paper we propose a differentially private GAN (DPGAN) model, in which we achieve differential privacy in GANs by adding carefully designed noise to gradients during the learning procedure. We provide rigorous proof for the privacy guarantee, as well as comprehensive empirical evidence to support our analysis, where we demonstrate that our method can generate high quality data points at a reasonable privacy level.},
  pubstate = {preprint},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\STGZS9AZ\\Xie et al_2018_Differentially Private Generative Adversarial Network.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\4DSFGMQR\\1802.html}
}

@online{xu2018SynthesizingTabularData,
  title = {Synthesizing {{Tabular Data}} Using {{Generative Adversarial Networks}}},
  author = {Xu, Lei and Veeramachaneni, Kalyan},
  date = {2018-11-27},
  number = {arXiv:1811.11264},
  eprint = {arXiv:1811.11264},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1811.11264},
  url = {http://arxiv.org/abs/1811.11264},
  urldate = {2022-07-16},
  abstract = {Generative adversarial networks (GANs) implicitly learn the probability distribution of a dataset and can draw samples from the distribution. This paper presents, Tabular GAN (TGAN), a generative adversarial network which can generate tabular data like medical or educational records. Using the power of deep neural networks, TGAN generates high-quality and fully synthetic tables while simultaneously generating discrete and continuous variables. When we evaluate our model on three datasets, we find that TGAN outperforms conventional statistical generative models in both capturing the correlation between columns and scaling up for large datasets.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\W4APEGYW\\Xu_Veeramachaneni_2018_Synthesizing Tabular Data using Generative Adversarial Networks.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\W7CRPDKL\\1811.html}
}

@inproceedings{xu2019ModelingTabularData,
  title = {Modeling {{Tabular}} Data Using {{Conditional GAN}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
  date = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2019/hash/254ed7d2de3b23ab10936522dd547b78-Abstract.html},
  urldate = {2022-07-15},
  abstract = {Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design CTGAN, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. CTGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.},
  keywords = {01,CTGAN,gan,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\XTRNJRP4\\Xu et al_2019_Modeling Tabular data using Conditional GAN.pdf}
}

@article{YANG2022108241,
  title = {Data Synthesis Method Preserving Correlation of Features},
  author = {Yang, Wonseok and Nam, Woochul},
  date = {2022},
  journaltitle = {Pattern Recognition},
  volume = {122},
  pages = {108241},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2021.108241},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320321004222},
  abstract = {Abundant data are essential for improving the performance of machine learning algorithms. Thus, if only limited data are available, data synthesis can be used to enlarge datasets. Data synthesis methods based on the covariance matrix are useful because of their fast data synthesis capabilities. However, artificial datasets generated via classical techniques show statistical discrepancies when compared to original datasets. To address this problem, we developed a new data synthesis method that preserves the correlation (between features) observed in the original dataset. This preservation was realized by considering not only the correlation but also the random noises used in data synthesis process. This method was applied to various biosignals (i.e., electrocortiography, electromyogram, and electrocardiogram), wherein data points are insufficient. Several classifiers (i.e., convolutional neural network, support vector machine, and k-nearest neighbor) were used to verify that the classification accuracy can be improved by the proposed data synthesis method.},
  keywords = {05,Artificial dataset,Correlation,Data synthesis,Random noise}
}

@inproceedings{yoon2020VIMEExtendingSuccess,
  title = {{{VIME}}: {{Extending}} the {{Success}} of {{Self-}} and {{Semi-supervised Learning}} to {{Tabular Domain}}},
  shorttitle = {{{VIME}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Yoon, Jinsung and Zhang, Yao and Jordon, James and van der Schaar, Mihaela},
  options = {useprefix=true},
  date = {2020},
  volume = {33},
  pages = {11033--11043},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/hash/7d97667a3e056acab9aaf653807b4a03-Abstract.html},
  urldate = {2023-01-30},
  abstract = {Self- and semi-supervised learning frameworks have made significant progress in training machine learning models with limited labeled data in image and language domains. These methods heavily rely on the unique structure in the domain datasets (such as spatial relationships in images or semantic relationships in language). They are not adaptable to general tabular data which does not have the same explicit structure as image and language data. In this paper, we fill this gap by proposing novel self- and semi-supervised learning frameworks for tabular data, which we refer to collectively as VIME (Value Imputation and Mask Estimation). We create a novel pretext task of estimating mask vectors from corrupted tabular data in addition to the reconstruction pretext task for self-supervised learning. We also introduce a novel tabular data augmentation method for self- and semi-supervised learning frameworks. In experiments, we evaluate the proposed framework in multiple tabular datasets from various application domains, such as genomics and clinical data. VIME exceeds state-of-the-art performance in comparison to the existing baseline methods.},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\9P88978X\\Yoon et al_2020_VIME.pdf}
}

@article{yuan2020SpatialReasoningMechanism,
  title = {Spatial Reasoning Mechanism to Enable Automated Adaptive Trajectory Planning in Ground Penetrating Radar Survey},
  author = {Yuan, Chenxi and Cai, Hubo},
  date = {2020-06-01},
  journaltitle = {Automation in Construction},
  shortjournal = {Automation in Construction},
  volume = {114},
  pages = {103157},
  issn = {0926-5805},
  doi = {10.1016/j.autcon.2020.103157},
  url = {https://www.sciencedirect.com/science/article/pii/S0926580518312585},
  abstract = {Lack of accurate and complete utility records is a root cause of utility strikes that occur on average once every minute in the United States, leading to hundreds of deaths and billions of dollars in financial losses. Ground-penetrating radar (GPR) has emerged as a promising tool to detect, locate, and measure underground pipes. Many algorithms have been devised to process GPR scans to determine pipe location and burying depth. Their accuracy depends on the relative angles between the GPR survey trajectory and the buried pipes. Perpendicular-to-pipe scanning yields the highest detectability, and along-pipe scanning yields the highest planimetric and depth accuracy. However, the challenge in practice is to maintain such ideal angles while not knowing the exact orientation of the pipes. This paper devises a novel spatial reasoning mechanism to enable the automation of GPR survey trajectory planning and adjustment based on ill-shaped and incomplete GPR signatures to achieve ideal angles in real time. The spatial reasoning mechanism provides trajectory adjustment suggestions based on the connection between the GPR signatures extracted from GPR scans and the relative angles between the GPR trajectory and underground pipes. The adjustment process continues until the GPR signatures from synthetic data under ideal angles and from field survey converge, and further adjustment no longer improves the results. Both indoor and field experiments have been conducted for validation. The results show that the newly developed method is capable of guiding the adjustment process in real time to achieve ideal angles and collect high-quality GPR data, leading to a more accurate estimation of pipe locations and burying depths. It has the great potential to support the operation of robotic unmanned ground vehicles (UGV) or unmanned aircraft system (UAS) to fully automate the GPR field survey.},
  keywords = {GPR survey,Spatial reasoning,Trajectory planning,Underground pipes,Utility strike}
}

@online{zach2022WhatLongTail,
  title = {What Is a {{Long Tail Distribution}}? ({{Definition}} \& {{Example}})},
  shorttitle = {What Is a {{Long Tail Distribution}}?},
  author = {Zach},
  date = {2022-05-20T15:50:27+00:00},
  url = {https://www.statology.org/long-tail-distribution/},
  urldate = {2023-01-16},
  abstract = {This tutorial provides an explanation of long tail distributions, including a definition and several examples.},
  langid = {american},
  organization = {{Statology}},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\L8TG6DTH\\long-tail-distribution.html}
}

@thesis{zbinden2022ImplementingExperimentingDiffusion,
  type = {mathesis},
  title = {Implementing and {{Experimenting}} with {{Diffusion Models}} for {{Text-to-Image Generation}}},
  author = {Zbinden, Robin},
  date = {2022-09-22},
  eprint = {2209.10948},
  eprinttype = {arxiv},
  eprintclass = {cs},
  institution = {{École Polytechnique Fédérale de Lausanne}},
  location = {{Lausanne, Switzerland}},
  url = {http://arxiv.org/abs/2209.10948},
  urldate = {2023-02-26},
  abstract = {Taking advantage of the many recent advances in deep learning, text-to-image generative models currently have the merit of attracting the general public attention. Two of these models, DALL-E 2 and Imagen, have demonstrated that highly photorealistic images could be generated from a simple textual description of an image. Based on a novel approach for image generation called diffusion models, text-to-image models enable the production of many different types of high resolution images, where human imagination is the only limit. However, these models require exceptionally large amounts of computational resources to train, as well as handling huge datasets collected from the internet. In addition, neither the codebase nor the models have been released. It consequently prevents the AI community from experimenting with these cutting-edge models, making the reproduction of their results complicated, if not impossible. In this thesis, we aim to contribute by firstly reviewing the different approaches and techniques used by these models, and then by proposing our own implementation of a text-to-image model. Highly based on DALL-E 2, we introduce several slight modifications to tackle the high computational cost induced. We thus have the opportunity to experiment in order to understand what these models are capable of, especially in a low resource regime. In particular, we provide additional and analyses deeper than the ones performed by the authors of DALL-E 2, including ablation studies. Besides, diffusion models use so-called guidance methods to help the generating process. We introduce a new guidance method which can be used in conjunction with other guidance methods to improve image quality. Finally, the images generated by our model are of reasonably good quality, without having to sustain the significant training costs of state-of-the-art text-to-image models.},
  pagetotal = {63},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\WRB8M4UR\\Zbinden_2022_Implementing and Experimenting with Diffusion Models for Text-to-Image.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\BDPPEW39\\2209.html}
}

@article{zhang2017PrivBayesPrivateData,
  title = {{{PrivBayes}}: {{Private Data Release}} via {{Bayesian Networks}}},
  shorttitle = {{{PrivBayes}}},
  author = {Zhang, Jun and Cormode, Graham and Procopiuc, Cecilia M. and Srivastava, Divesh and Xiao, Xiaokui},
  date = {2017-10-27},
  journaltitle = {ACM Transactions on Database Systems},
  shortjournal = {ACM Trans. Database Syst.},
  volume = {42},
  number = {4},
  pages = {25:1--25:41},
  issn = {0362-5915},
  doi = {10.1145/3134428},
  url = {https://doi.org/10.1145/3134428},
  urldate = {2023-03-02},
  abstract = {Privacy-preserving data publishing is an important problem that has been the focus of extensive study. The state-of-the-art solution for this problem is differential privacy, which offers a strong degree of privacy protection without making restrictive assumptions about the adversary. Existing techniques using differential privacy, however, cannot effectively handle the publication of high-dimensional data. In particular, when the input dataset contains a large number of attributes, existing methods require injecting a prohibitive amount of noise compared to the signal in the data, which renders the published data next to useless. To address the deficiency of the existing methods, this paper presents PrivBayes, a differentially private method for releasing high-dimensional data. Given a dataset D, PrivBayes first constructs a Bayesian network N, which (i) provides a succinct model of the correlations among the attributes in D and (ii) allows us to approximate the distribution of data in D using a set P of low-dimensional marginals of D. After that, PrivBayes injects noise into each marginal in P to ensure differential privacy and then uses the noisy marginals and the Bayesian network to construct an approximation of the data distribution in D. Finally, PrivBayes samples tuples from the approximate distribution to construct a synthetic dataset, and then releases the synthetic data. Intuitively, PrivBayes circumvents the curse of dimensionality, as it injects noise into the low-dimensional marginals in P instead of the high-dimensional dataset D. Private construction of Bayesian networks turns out to be significantly challenging, and we introduce a novel approach that uses a surrogate function for mutual information to build the model more accurately. We experimentally evaluate PrivBayes on real data and demonstrate that it significantly outperforms existing solutions in terms of accuracy.},
  keywords = {bayesian network,Differential privacy,synthetic data generation},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\C9C2B2CW\\Zhang et al_2017_PrivBayes.pdf}
}

@inproceedings{zhang2018GenerativeAdversarialNetwork,
  title = {Generative {{Adversarial Network}} for {{Synthetic Time Series Data Generation}} in {{Smart Grids}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Communications}}, {{Control}}, and {{Computing Technologies}} for {{Smart Grids}} ({{SmartGridComm}})},
  author = {Zhang, Chi and Kuppannagari, Sanmukh R. and Kannan, Rajgopal and Prasanna, Viktor K.},
  date = {2018-10},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Aalborg}},
  doi = {10.1109/SmartGridComm.2018.8587464},
  url = {https://ieeexplore.ieee.org/document/8587464/},
  urldate = {2022-06-30},
  abstract = {The availability of fine grained time series data is a pre-requisite for research in smart-grids. While data for transmission systems is relatively easily obtainable, issues related to data collection, security and privacy hinder the widespread public availability/accessibility of such datasets at the distribution system level. This has prevented the larger research community from effectively applying sophisticated machine learning algorithms to significantly improve the distribution-level accuracy of predictions and increase the efficiency of grid operations.},
  eventtitle = {2018 {{IEEE International Conference}} on {{Communications}}, {{Control}}, and {{Computing Technologies}} for {{Smart Grids}} ({{SmartGridComm}})},
  isbn = {978-1-5386-7954-8},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\IXGGR9DD\\Zhang et al_2018_Generative Adversarial Network for Synthetic Time Series Data Generation in.pdf}
}

@inproceedings{zhang2021GANBLRTabularData,
  title = {{{GANBLR}}: {{A Tabular Data Generation Model}}},
  shorttitle = {{{GANBLR}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Zhang, Yishuo and Zaidi, Nayyar A. and Zhou, Jiahui and Li, Gang},
  date = {2021-12},
  pages = {181--190},
  publisher = {{IEEE}},
  location = {{Auckland, New Zealand}},
  doi = {10.1109/ICDM51629.2021.00103},
  url = {https://ieeexplore.ieee.org/document/9679177/},
  urldate = {2022-08-04},
  eventtitle = {2021 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  isbn = {978-1-66542-398-4},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\F26HH664\\Zhang et al_2021_GANBLR.pdf}
}

@article{zhang2022NovelEdgeComputing,
  title = {A {{Novel Edge Computing Architecture Based}} on {{Adaptive Stratified Sampling}}},
  author = {Zhang, De-gan and Ni, Chen-hao and Zhang, Jie and Zhang, Ting and Yang, Peng and Wang, Jia-xu and Yan, Hao-ran},
  date = {2022-02-01},
  journaltitle = {Computer Communications},
  shortjournal = {Computer Communications},
  volume = {183},
  pages = {121--135},
  issn = {0140-3664},
  doi = {10.1016/j.comcom.2021.11.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0140366421004412},
  abstract = {With the development of the Internet of Things technology, the current amount of data generated by the Internet of Things system is increasing, and these data are continuously transmitted to the data center. The data processing and analysis of the traditional Internet of Things system are inefficient and cannot handle such a large number of data streams. In addition, the IoT smart device has a resource-limited feature, which cannot be ignored when analyzing data. This paper proposes a new architecture ApproxECIoT (Approximate Edge Computing Internet of Things, ApproxECIoT) suitable for real-time data stream processing of the Internet of Things. It implements a self-adjusting stratified sampling algorithm to process real-time data streams. The algorithm adjusts the size of the sample stratums according to the variance of each stratum while maintaining the given memory budget. This is beneficial to improve the accuracy of the calculation results when resources are limited. Finally, the experimental analysis was performed using synthetic datasets and real-world datasets, the results show that ApproxECIoT can still obtain high-accuracy calculation results when using memory resources similar to simple random sampling. In the case of synthetic data streams, when the sampling ratio is 10\%, compared with CalculIoT, the accuracy loss of ApproxECIoT is reduced by 89.6\%; compared with SRS, the accuracy loss of ApprxoECIoT is reduced by 99.8\%. In the case of using the real data stream of the wireless sensor network, the performance of ApproxECIoT is not the best, but as the sampling ratio increases, the accuracy loss of ApproxECIoT decreases more than other frameworks.},
  keywords = {Approximate Computing,Data analysis,Edge Computing,IoT,Real-time data stream processing}
}

@inproceedings{zhao2021CTABGANEffectiveTable,
  title = {{{CTAB-GAN}}: {{Effective Table Data Synthesizing}}},
  shorttitle = {{{CTAB-GAN}}},
  booktitle = {Proceedings of {{The}} 13th {{Asian Conference}} on {{Machine Learning}}},
  author = {Zhao, Zilong and Kunar, Aditya and Birke, Robert and Chen, Lydia Y.},
  date = {2021-11-28},
  pages = {97--112},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v157/zhao21a.html},
  urldate = {2023-01-16},
  abstract = {While data sharing is crucial for knowledge development, privacy concerns and strict regulation (e.g., European General Data Protection Regulation (GDPR)) unfortunately limit its full effectiveness. Synthetic tabular data emerges as an alternative to enable data sharing while fulfilling regulatory and privacy constraints. The state-of-the-art tabular data synthesizers draw methodologies from Generative Adversarial Networks (GAN) and address two main data types in industry, i.e., continuous and categorical. In this paper, we develop CTAB-GAN, a novel conditional table GAN architecture that can effectively model diverse data types, including a mix of continuous and categorical variables. Moreover, we address data imbalance and long tail issues, i.e., certain variables have drastic frequency differences across large values. To achieve those aims, we first introduce the information loss, classification loss and generator loss to the conditional GAN. Secondly, we design a novel conditional vector, which efficiently encodes the mixed data type and skewed distribution of data variable. We extensively evaluate CTAB-GAN with the state of the art GANs that generate synthetic tables, in terms of data similarity and analysis utility. The results on five datasets show that the synthetic data of CTAB-GAN remarkably resembles the real data for all three types of variables and results into higher accuracy for five machine learning algorithms, by up to 17\%.},
  eventtitle = {Asian {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\ED6XL3CR\\Zhao et al_2021_CTAB-GAN.pdf}
}

@inproceedings{zhao2021CTABGANEffectiveTablea,
  title = {{{CTAB-GAN}}: {{Effective Table Data Synthesizing}}},
  shorttitle = {{{CTAB-GAN}}},
  booktitle = {Proceedings of {{The}} 13th {{Asian Conference}} on {{Machine Learning}}},
  author = {Zhao, Zilong and Kunar, Aditya and Van der Scheer, Hiek and Birke, Robert and Chen, Lydia Y.},
  date = {2021-05-31},
  pages = {97--112},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v157/zhao21a.html},
  urldate = {2023-01-16},
  abstract = {While data sharing is crucial for knowledge development, privacy concerns and strict regulation (e.g., European General Data Protection Regulation (GDPR)) unfortunately limit its full effectiveness. Synthetic tabular data emerges as an alternative to enable data sharing while fulfilling regulatory and privacy constraints. The state-of-the-art tabular data synthesizers draw methodologies from generative Adversarial Networks (GAN) and address two main data types in the industry, i.e., continuous and categorical. In this paper, we develop CTAB-GAN, a novel conditional table GAN architecture that can effectively model diverse data types, including a mix of continuous and categorical variables. Moreover, we address data imbalance and long-tail issues, i.e., certain variables have drastic frequency differences across large values. To achieve those aims, we first introduce the information loss and classification loss to the conditional GAN. Secondly, we design a novel conditional vector, which efficiently encodes the mixed data type and skewed distribution of data variable. We extensively evaluate CTAB-GAN with the state of the art GANs that generate synthetic tables, in terms of data similarity and analysis utility. The results on five datasets show that the synthetic data of CTAB-GAN remarkably resembles the real data for all three types of variables and results into higher accuracy for five machine learning algorithms, by up to 17\%.},
  eventtitle = {Asian {{Conference}} on {{Machine Learning}}},
  keywords = {01,Computer Science - Machine Learning,conditional GAN,CTAB-GAN,gan,I.2.m,mixed data,tabular data},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\AMNG2WFE\\Zhao et al_2021_CTAB-GAN.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\W8WGVG7I\\Zhao et al_2022_CTAB-GAN+.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\UMNCTSEE\\2102.html}
}

@inproceedings{zhao2022CTABGANEnhancingTabular,
  title = {{{CTAB-GAN}}+: {{Enhancing Tabular Data Synthesis}}},
  shorttitle = {{{CTAB-GAN}}+},
  author = {Zhao, Zilong and Kunar, Aditya and Birke, Robert and Chen, Lydia Y.},
  date = {2022-04-01},
  eprint = {2204.00401},
  eprinttype = {arxiv},
  eprintclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2204.00401},
  urldate = {2022-07-04},
  abstract = {While data sharing is crucial for knowledge development, privacy concerns and strict regulation (e.g., European General Data Protection Regulation (GDPR)) limit its full effectiveness. Synthetic tabular data emerges as alternative to enable data sharing while fulfilling regulatory and privacy constraints. State-of-the-art tabular data synthesizers draw methodologies from Generative Adversarial Networks (GAN). As GANs improve the synthesized data increasingly resemble the real data risking to leak privacy. Differential privacy (DP) provides theoretical guarantees on privacy loss but degrades data utility. Striking the best trade-off remains yet a challenging research question. We propose CTAB-GAN+ a novel conditional tabular GAN. CTAB-GAN+ improves upon state-of-the-art by (i) adding downstream losses to conditional GANs for higher utility synthetic data in both classification and regression domains; (ii) using Wasserstein loss with gradient penalty for better training convergence; (iii) introducing novel encoders targeting mixed continuous-categorical variables and variables with unbalanced or skewed data; and (iv) training with DP stochastic gradient descent to impose strict privacy guarantees. We extensively evaluate CTAB-GAN+ on data similarity and analysis utility against state-of-the-art tabular GANs. The results show that CTAB-GAN+ synthesizes privacy-preserving data with at least 48.16\% higher utility across multiple datasets and learning tasks under different privacy budgets.},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\II2SXQQU\\Zhao et al_2022_CTAB-GAN+.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\8HXP4S8N\\2204.html}
}

@misc{zheng2020CreationSyntheticNetworkeda,
  title = {Creation of {{Synthetic Networked PMU Data}}: {{A Generative Adversarial Network Approach}}},
  shorttitle = {Creation of {{Synthetic Networked PMU Data}}},
  author = {Zheng, Xiangtian and Wang, Bin and Kalathil, Dileep and Xie, Le},
  date = {2020-04-06},
  number = {arXiv:1908.08180},
  eprint = {1908.08180},
  eprinttype = {arxiv},
  eprintclass = {eess},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1908.08180},
  url = {http://arxiv.org/abs/1908.08180},
  urldate = {2022-07-10},
  abstract = {This paper introduces a machine learning-based approach to synthetically creating realistic phasor measurement unit (PMU) data streams of multiple transient types. In contrast to the existing literature of transient simulation-based data generation methods, we propose a generative adversarial network (GAN) based approach to learning directly from the historical data and simultaneously reproduce multiple PMU data streams. The synthetic PMU data streams reflect meaningful dynamic characteristics which observe first principles such as Kirchhoff's laws. The efficacy of this approach is demonstrated by numerical studies on the IEEE 39-bus system. We validate the fidelity and flexibility of the synthetic data via statistical resemblance and modal analysis approaches. Finally we illustrate a practical application scenario for the usage of the synthetic PMU data, i.e. leverage the synthetic data to improve the performance of the event classification algorithms.},
  keywords = {04,Electrical Engineering and Systems Science - Signal Processing,gan},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\KSIMEV8F\\Zheng et al_2020_Creation of Synthetic Networked PMU Data.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\PQDDEG7X\\1908.html}
}

@online{zheng2022DiffusionModelsMissing,
  title = {Diffusion Models for Missing Value Imputation in Tabular Data},
  author = {Zheng, Shuhan and Charoenphakdee, Nontawat},
  date = {2022-10-31},
  number = {arXiv:2210.17128},
  eprint = {arXiv:2210.17128},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/2210.17128},
  urldate = {2022-11-16},
  abstract = {Missing value imputation in machine learning is the task of estimating the missing values in the dataset accurately using available information. In this task, several deep generative modeling methods have been proposed and demonstrated their usefulness, e.g., generative adversarial imputation networks. Recently, diffusion models have gained popularity because of their effectiveness in the generative modeling task in images, texts, audio, etc. To our knowledge, less attention has been paid to the investigation of the effectiveness of diffusion models for missing value imputation in tabular data. Based on recent development of diffusion models for time-series data imputation, we propose a diffusion model approach called “Conditional Score-based Diffusion Models for Tabular data” (CSDI\_T). To effectively handle categorical variables and numerical variables simultaneously, we investigate three techniques: one-hot encoding, analog bits encoding, and feature tokenization. Experimental results on benchmark datasets demonstrated the effectiveness of CSDI\_T compared with well-known existing methods, and also emphasized the importance of the categorical embedding techniques.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\DQG54EWX\\Zheng und Charoenphakdee - 2022 - Diffusion models for missing value imputation in t.pdf}
}

@article{zhou2022RootCauseDiagnosis,
  title = {Root Cause Diagnosis in Multivariate Time Series Based on Modified Temporal Convolution and Multi-Head Self-Attention},
  author = {Zhou, Yujie and Xu, Ke and He, Fei},
  date = {2022-09},
  journaltitle = {Journal of Process Control},
  shortjournal = {Journal of Process Control},
  volume = {117},
  pages = {14--25},
  issn = {09591524},
  doi = {10.1016/j.jprocont.2022.06.014},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959152422001214},
  urldate = {2022-08-30},
  langid = {english}
}

@article{zhu2021ConvertingTabularData,
  title = {Converting Tabular Data into Images for Deep Learning with Convolutional Neural Networks},
  author = {Zhu, Yitan and Brettin, Thomas and Xia, Fangfang and Partin, Alexander and Shukla, Maulik and Yoo, Hyunseung and Evrard, Yvonne A. and Doroshow, James H. and Stevens, Rick L.},
  date = {2021-05-31},
  journaltitle = {Scientific Reports},
  volume = {11},
  number = {1},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-90923-y},
  url = {https://www.osti.gov/pages/biblio/1785302},
  urldate = {2023-02-09},
  abstract = {AbstractConvolutional neural networks (CNNs) have been successfully used in many applications where important information about data is embedded in the order of features, such as speech and imaging. However, most tabular data do not assume a spatial relationship between features, and thus are unsuitable for modeling using CNNs. To meet this challenge, we develop a novel algorithm, image generator for tabular data (IGTD), to transform tabular data into images by assigning features to pixel positions so that similar features are close to each other in the image. The algorithm searches for an optimized assignment by minimizing the difference between the ranking of distances between features and the ranking of distances between their assigned pixels in the image. We apply IGTD to transform gene expression profiles of cancer cell lines (CCLs) and molecular descriptors of drugs into their respective image representations. Compared with existing transformation methods, IGTD generates compact image representations with better preservation of feature neighborhood structure. Evaluated on benchmark drug screening datasets, CNNs trained on IGTD image representations of CCLs and drugs exhibit a better performance of predicting anti-cancer drug response than both CNNs trained on alternative image representations and prediction models trained on the original tabular data.},
  langid = {english},
  file = {C\:\\Users\\SvenG\\Zotero\\storage\\JD6VZHL2\\Zhu et al_2021_Converting tabular data into images for deep learning with convolutional neural.pdf;C\:\\Users\\SvenG\\Zotero\\storage\\8C97F66I\\1785302.html}
}

@preamble{ "\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi " }
