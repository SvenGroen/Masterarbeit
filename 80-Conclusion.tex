\chapter{Conclusion and Future Work}
\label{ch:conclusion}

\section{Conclusion}
\label{ch:conclusion_}

This thesis investigates the effect of different tabular processing mechanisms on diffusion-based tabular data synthesis.
An already existing tabular data generation pipeline has been extended to implement different tabular encoding and decoding strategies easily.
The pipeline of TabDDPM \cite{kotelnikov2022TabDDPMModellingTabular} was extended by two tabular processing mechanisms that encode the tabular data before the training and revert the data back after sampling synthetic data.
The extended pipeline was evaluated using a CatBoost-based machine learning efficacy evaluation, a TabSynDex metric, and visualization of the synthetic data.
The TabSynDex metric comprises five sub-metrics that capture different similarity aspects of the synthetic data.
Several observations could be made from the executed experiments.
Firstly, the results in terms of machine learning efficacy stated by the authors of the TabDDPM pipeline could be reproduced \cite{kotelnikov2022TabDDPMModellingTabular}.
Thanks to the addition of the TabSynDex metrics, it has been shown that TabDDPM superior performance against a set of non-diffusion baseline \glspl{model} also extends to the TabSynDex similarity metrics.

Adding a \acrfull{ft} processing mechanism into the TabDDPM generation pipeline transforms the tabular data in such a way,
that the diffusion \gls{model} was not able to generate any meaningful data, which could be seen in the visual result.
Adopting a more complex encoding-decoding strategy from \cite{zhao2022CTABGANEnhancingTabular}, which uses a \acrfull{bgm},
improved TabDDPM's generative capabilities in producing synthetic data that is useful in machine-learning scenarios.
Hence, it could be shown that changing the tabular data format greatly affects the diffusion \gls{model}'s generative capability, in a negative (for the \gls{ft} approach) and positive way (for the \gls{bgm} approach).

Furthermore, the importance of hyperparameter tuning for diffusion \glspl{model} was highlighted.
Diffusion \glspl{model} tuned towards the TabSynDex similarity score greatly improved several of the TabSynDex metrics.
In the performed experiments, diffusion \glspl{model} have been the first \glspl{model} to achieve a non-zero \gls{pmse} score, which other current state-of-art \glspl{model} have not been capable of.
Hence, diffusion \glspl{model} are better at producing synthetic data that is more non-differentiable from the real data \cite{chundawat2022UniversalMetricRobust} compared to tested non-diffusion \glspl{model}.
Further experiments showed how changing the data normalization strategy can, on the one hand, increase metric results but, on the other hand, worsen important dataset characteristics, displayed in the visual results.
This insight underlines the importance of a visual evaluation by comparing the plots of synthetic and real dataset characteristics to estimate the quality of the produced synthetic data properly.
From all performed experiments, it can be concluded that diffusion-based tabular data synthesis is superior to the synthesis of other \gls{model} types, such as \glspl{gan} or \glspl{vae}.
Moreover, diffusion \glspl{model} have not only shown overall better metric and visual results, but they are also more flexible, as a hyperparameter tuning already affects the outcome of the metrics greatly.
Even though TabDDPM$^{s}_{m}$ achieved the highest overall similarity score, it is not able to reproduce the underlying characteristics of the real data, which could be seen in several of the comparative visualizations presented in this thesis.
TabDDPM$^{s}_{m}$ lacks the ability to properly recreate important characteristics of the real data, such as column distributions (\Autoref{fig:age}) or the real datasets principal components (\Autoref{fig:pca_diffusion}).
This was not the case for TabDDPM-BGM$^{s}_{[q|m]}$ \glspl{model}, which achieved only slightly worse similarity scores but better capture the underlying characteristics of the real data, as indicated by the visual plots in this thesis.
As a consequence, the TabDDPM-BGM$^{s}_{[q|m]}$ variants should be considered as the best overall \glspl{model} of this thesis.
Nevertheless, potential users should alter the \gls{model} pipeline design depending on the use case of the synthetic data, since TabDDPM-BGM$^{s}_m$ produced the best correlation score, TabDDPM-BGM$^{ml}_q$ the best machine learning efficacy scores and TabDDPM-BGM$^{s}_q$ the best basic statistical values and \gls{pmse} results.
\newpage

\section{Future Work}
\label{ch:results-futureWork}

As implementing diffusion \glspl{model} for synthesizing tabular data represents a relatively innovative approach with limited research to date, numerous promising pathways for future investigations exist.
Firstly, to overcome the limitations presented in \Autoref{ch:results-limitations}, a more extensive set of datasets is required to confirm the results observed in this thesis.
More datasets with diverse characteristics to generalize the findings and identify potential sources of variation or bias.

Moreover, incorporating a variety of metrics with diverse perspectives is essential for evaluating the performance and trade-offs of distinct tabular data generation methods.
This is particularly relevant for privacy-related metrics, as recent research suggests that diffusion \glspl{model} may not effectively protect privacy and allow to extract training data samples \cite{carlini2023ExtractingTrainingData}.

Furthermore, as the definition of synthetic tabular data generation in \Autoref{sec: synthetic tabular data generation} stated, the synthetic data $T_{syn}$ is usually created by training the generator on $T_{train}$ and comparing $T_{syn}$ with $T_{test}$.
The quality of $T_{syn}$ naturally depends on the quality of $T_{train}$ and, most importantly, how representative the $T_{train}$-split is from the overall joint distribution (the combination of $T_{train}$ and $T_{test}$).
Hence, future research could investigate the impact different train-test-splits potentially have on the quality of $T_{syn}$.
This could be achieved by testing different train-test-splits of the same dataset and comparing the quality of the generated $T_{syn}$ across the different splits.
Additionally, most evaluation techniques heavily rely on the comparison of $T_{syn}$ with $T_{test}$.
In this context, the comparison of $T_{syn}$ with $T_{train}$ might provide valuable insights as well.

Moreover, it is likely that diffusion \glspl{model} can be further improved through several changes.
First, the hyperparameter search space could be broader, such that more hyperparameter variations are explored.
Second, the neural network itself could be replaced by a more sophisticated one.
The proposed network by \cite{kotelnikov2022TabDDPMModellingTabular}, which predicts the noise in the reverse process, follows a simple architecture.
In the image generation domain, a more complex U-Net \cite{ronneberger2015UNetConvolutionalNetworks} architecture with attention mechanisms at different layers was proposed \cite{dhariwal2021DiffusionModelsBeat}.
\textcite{dhariwal2021DiffusionModelsBeat} showed that such changes led to a better generation quality.
Hence, it is possible that similar changes to the \gls{model}'s architecture would lead to better generative capabilities.
Other changes could be made towards further improving the loss function.
It might be worth investigating whether some adversarial loss could be implemented, similar to \gls{gan} \glspl{model}.
For example, an adversarial network could be tasked to tell apart which noise (the noise that will be removed from the noised image) was predicted by the neural network and which was the actual noise.
This information could be used to further enhance the capability of the diffusion network to remove noise from $x_{t}$ to get to $x_{t-1}$.
Lastly, depending on the results of a detailed privacy evaluation, introducing differential privacy \cite{dwork2011DifferentialPrivacy} into the diffusion \gls{model} might be worth investigating, which has been done extensively in the \gls{gan} domain \cite{jordon2018PATEGANGeneratingSynthetic,9054559, kunar2021DTGANDifferentialPrivatea, torfi2022DifferentiallyPrivateSynthetic}.

Regarding the tabular processor mechanism, several changes and different techniques could be implemented to improve the overall generation pipeline.
Currently, the tabular processor mechanism is fully separated from the diffusion processes.
Fully incorporating the tabular processor into the neural network architecture for some mechanisms would allow a gradient flow through the processing mechanism.
This would be especially interesting for embedding mechanisms, as they could learn in this way to create a meaningful representation of the data.
Alternatively, a pre-training mechanism for the tabular processor could be possible so that embedding layers can learn meaningful representations before the actual tabular data synthesis starts.

There exist several different tabular processor techniques that could be worth investigating.
For example, the \glspl{model} TABBIE \cite{iida2021TABBIEPretrainedRepresentations} and TURL \cite{deng2021TURLTableUnderstanding} show different ways to create
meaningful-context aware representations of tabular data.
Future researchers could adapt their work and use the pretrained embeddings created by these \glspl{model} to encode the tabular data before processing it in the diffusion pipeline.
One of the biggest challenges here is to correctly revert the data back into its original data format after it has been synthesized.
A possible solution for this could be training a decoder module, as in \cite{rombach2022HighResolutionImageSynthesis}, adapting an encoder-decoder architecture.
This decoder could be trained explicitly towards reverting the previously encoded data back into its human-readable format.
In this solution, the tabular processing inverse function is not implemented directly by the developer, but it is learned through a neural network.

As one can see, many possible research directions exist for diffusion-based tabular data synthesis.
Future research should first focus on removing the possible limitations of this thesis through a more elaborate experimental setup with more datasets.
Here, potential privacy issues are required to be investigated.
Depending on the results, architectural changes and additional tabular processing mechanisms are worth investigating.